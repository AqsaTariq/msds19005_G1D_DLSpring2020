{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN_dropout_DGraphDTA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Mm_psbG2K6g4",
        "j67nvw6Wb-bR",
        "oYTVP7Q7gWVr",
        "wQOUmC2gbDw7",
        "TBXlZYyscB70",
        "UcEOzDr5eRxG",
        "17AeReChf384",
        "8OcLBaFy4z3Z"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm_psbG2K6g4",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXlAv28ZK_dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7fa1019c-cfdc-4f2e-db14-edf9012737fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X5rwimj2eViU",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_max_pool as gmp, global_add_pool as gap,global_mean_pool as gep,global_sort_pool\n",
        "from torch_geometric.utils import dropout_adj\n",
        "\n",
        "\n",
        "# GCN based model\n",
        "class GNNNet(torch.nn.Module):\n",
        "    def __init__(self, n_output=1, num_features_pro=54, num_features_mol=78, output_dim=128, dropout=0.2):\n",
        "        super(GNNNet, self).__init__()\n",
        "\n",
        "        print('GNNNet Loaded')\n",
        "        self.n_output = n_output\n",
        "        self.mol_conv1 = GCNConv(num_features_mol, num_features_mol)\n",
        "        self.mol_conv2 = GCNConv(num_features_mol, num_features_mol * 2)\n",
        "        self.mol_conv3 = GCNConv(num_features_mol * 2, num_features_mol * 4)\n",
        "       \n",
        "        self.mol_fc_g1 = torch.nn.Linear(num_features_mol * 4, 1024)\n",
        "        self.mol_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
        "\n",
        "        self.pro_conv1 = GCNConv(num_features_pro, num_features_pro)\n",
        "        self.pro_conv2 = GCNConv(num_features_pro, num_features_pro * 2)\n",
        "        self.pro_conv3 = GCNConv(num_features_pro * 2, num_features_pro * 4)\n",
        "       \n",
        "        self.pro_fc_g1 = torch.nn.Linear(num_features_pro * 4, 1024)\n",
        "        self.pro_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(2 * output_dim, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.out = nn.Linear(512, self.n_output)\n",
        "\n",
        "    def forward(self, data_mol, data_pro):\n",
        "        \n",
        "        # get molecule graph input\n",
        "        mol_x, mol_edge_index, mol_batch = data_mol.x, data_mol.edge_index, data_mol.batch\n",
        "        \n",
        "        # get protein input\n",
        "        target_x, target_edge_index, target_batch = data_pro.x, data_pro.edge_index, data_pro.batch\n",
        "\n",
        "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
        "        x = self.mol_conv1(mol_x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
        "        x = self.mol_conv2(x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
        "        x = self.mol_conv3(x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = gep(x, mol_batch)  # global pooling\n",
        "\n",
        "        # flatten\n",
        "        x = self.relu(self.mol_fc_g1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.mol_fc_g2(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        \n",
        "        target_edge_index_, _ = dropout_adj(target_edge_index, training=self.training, p=0.5)\n",
        "        xt = self.pro_conv1(target_x, target_edge_index_)\n",
        "        xt = self.relu(xt)\n",
        "\n",
        "        target_edge_index_, _ = dropout_adj(target_edge_index, training=self.training, p=0.5)\n",
        "        xt = self.pro_conv2(xt, target_edge_index_)\n",
        "        xt = self.relu(xt)\n",
        "\n",
        "        target_edge_index_, _ = dropout_adj(target_edge_index, training=self.training, p=0.5)\n",
        "        xt = self.pro_conv3(xt, target_edge_index_)\n",
        "        xt = self.relu(xt)\n",
        "\n",
        "        xt = gep(xt, target_batch)  # global pooling\n",
        "\n",
        "        # flatten\n",
        "        xt = self.relu(self.pro_fc_g1(xt))\n",
        "        xt = self.dropout(xt)\n",
        "        xt = self.pro_fc_g2(xt)\n",
        "        xt = self.dropout(xt)\n",
        "\n",
        "        xc = torch.cat((x, xt), 1)\n",
        "\n",
        "        # add some dense layers\n",
        "        xc = self.fc1(xc)\n",
        "        xc = self.relu(xc)\n",
        "        xc = self.dropout(xc)\n",
        "        xc = self.fc2(xc)\n",
        "        xc = self.relu(xc)\n",
        "        xc = self.dropout(xc)\n",
        "        out = self.out(xc)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j67nvw6Wb-bR",
        "colab_type": "text"
      },
      "source": [
        "## Downloading Preprocessed Data for Protein Contact Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ym8nVVZjW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fac9a6f-524f-48e1-ffd5-56a016a11ec1"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1rqAopf_IaH3jzFkwXObQ4i-6bUUwizCv\n",
        "!unzip data.zip\n",
        "!cp -r /content/data/davis/aln /content/DGraphDTA/data/davis\n",
        "!cp -r /content/data/davis/pconsc4 /content/DGraphDTA/data/davis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rqAopf_IaH3jzFkwXObQ4i-6bUUwizCv\n",
            "To: /content/data.zip\n",
            "2.87GB [00:40, 71.0MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/davis/\n",
            "   creating: data/davis/aln/\n",
            "  inflating: data/davis/aln/AAK1.aln  \n",
            "  inflating: data/davis/aln/ABL1(E255K).aln  \n",
            "  inflating: data/davis/aln/ABL1(F317I).aln  \n",
            "  inflating: data/davis/aln/ABL1(F317I)p.aln  \n",
            "  inflating: data/davis/aln/ABL1(F317L).aln  \n",
            "  inflating: data/davis/aln/ABL1(F317L)p.aln  \n",
            "  inflating: data/davis/aln/ABL1(H396P).aln  \n",
            "  inflating: data/davis/aln/ABL1(H396P)p.aln  \n",
            "  inflating: data/davis/aln/ABL1(M351T).aln  \n",
            "  inflating: data/davis/aln/ABL1(Q252H).aln  \n",
            "  inflating: data/davis/aln/ABL1(Q252H)p.aln  \n",
            "  inflating: data/davis/aln/ABL1(T315I).aln  \n",
            "  inflating: data/davis/aln/ABL1(T315I)p.aln  \n",
            "  inflating: data/davis/aln/ABL1(Y253F).aln  \n",
            "  inflating: data/davis/aln/ABL1.aln  \n",
            "  inflating: data/davis/aln/ABL1p.aln  \n",
            "  inflating: data/davis/aln/ABL2.aln  \n",
            "  inflating: data/davis/aln/ACVR1.aln  \n",
            "  inflating: data/davis/aln/ACVR1B.aln  \n",
            "  inflating: data/davis/aln/ACVR2A.aln  \n",
            "  inflating: data/davis/aln/ACVR2B.aln  \n",
            "  inflating: data/davis/aln/ACVRL1.aln  \n",
            "  inflating: data/davis/aln/ADCK3.aln  \n",
            "  inflating: data/davis/aln/ADCK4.aln  \n",
            "  inflating: data/davis/aln/AKT1.aln  \n",
            "  inflating: data/davis/aln/AKT2.aln  \n",
            "  inflating: data/davis/aln/AKT3.aln  \n",
            "  inflating: data/davis/aln/ALK.aln  \n",
            "  inflating: data/davis/aln/AMPK-alpha1.aln  \n",
            "  inflating: data/davis/aln/AMPK-alpha2.aln  \n",
            "  inflating: data/davis/aln/ANKK1.aln  \n",
            "  inflating: data/davis/aln/ARK5.aln  \n",
            "  inflating: data/davis/aln/ASK1.aln  \n",
            "  inflating: data/davis/aln/ASK2.aln  \n",
            "  inflating: data/davis/aln/AURKA.aln  \n",
            "  inflating: data/davis/aln/AURKB.aln  \n",
            "  inflating: data/davis/aln/AURKC.aln  \n",
            "  inflating: data/davis/aln/AXL.aln  \n",
            "  inflating: data/davis/aln/BIKE.aln  \n",
            "  inflating: data/davis/aln/BLK.aln  \n",
            "  inflating: data/davis/aln/BMPR1A.aln  \n",
            "  inflating: data/davis/aln/BMPR1B.aln  \n",
            "  inflating: data/davis/aln/BMPR2.aln  \n",
            "  inflating: data/davis/aln/BMX.aln  \n",
            "  inflating: data/davis/aln/BRAF(V600E).aln  \n",
            "  inflating: data/davis/aln/BRAF.aln  \n",
            "  inflating: data/davis/aln/BRK.aln  \n",
            "  inflating: data/davis/aln/BRSK1.aln  \n",
            "  inflating: data/davis/aln/BRSK2.aln  \n",
            "  inflating: data/davis/aln/BTK.aln  \n",
            "  inflating: data/davis/aln/CAMK1.aln  \n",
            "  inflating: data/davis/aln/CAMK1D.aln  \n",
            "  inflating: data/davis/aln/CAMK1G.aln  \n",
            "  inflating: data/davis/aln/CAMK2A.aln  \n",
            "  inflating: data/davis/aln/CAMK2B.aln  \n",
            "  inflating: data/davis/aln/CAMK2D.aln  \n",
            "  inflating: data/davis/aln/CAMK2G.aln  \n",
            "  inflating: data/davis/aln/CAMK4.aln  \n",
            "  inflating: data/davis/aln/CAMKK1.aln  \n",
            "  inflating: data/davis/aln/CAMKK2.aln  \n",
            "  inflating: data/davis/aln/CASK.aln  \n",
            "  inflating: data/davis/aln/CDC2L1.aln  \n",
            "  inflating: data/davis/aln/CDC2L2.aln  \n",
            "  inflating: data/davis/aln/CDC2L5.aln  \n",
            "  inflating: data/davis/aln/CDK11.aln  \n",
            "  inflating: data/davis/aln/CDK2.aln  \n",
            "  inflating: data/davis/aln/CDK3.aln  \n",
            "  inflating: data/davis/aln/CDK4-cyclinD1.aln  \n",
            "  inflating: data/davis/aln/CDK4-cyclinD3.aln  \n",
            "  inflating: data/davis/aln/CDK5.aln  \n",
            "  inflating: data/davis/aln/CDK7.aln  \n",
            "  inflating: data/davis/aln/CDK8.aln  \n",
            "  inflating: data/davis/aln/CDK9.aln  \n",
            "  inflating: data/davis/aln/CDKL1.aln  \n",
            "  inflating: data/davis/aln/CDKL2.aln  \n",
            "  inflating: data/davis/aln/CDKL3.aln  \n",
            "  inflating: data/davis/aln/CDKL5.aln  \n",
            "  inflating: data/davis/aln/CHEK1.aln  \n",
            "  inflating: data/davis/aln/CHEK2.aln  \n",
            "  inflating: data/davis/aln/CIT.aln  \n",
            "  inflating: data/davis/aln/CLK1.aln  \n",
            "  inflating: data/davis/aln/CLK2.aln  \n",
            "  inflating: data/davis/aln/CLK3.aln  \n",
            "  inflating: data/davis/aln/CLK4.aln  \n",
            "  inflating: data/davis/aln/CSF1R.aln  \n",
            "  inflating: data/davis/aln/CSK.aln  \n",
            "  inflating: data/davis/aln/CSNK1A1.aln  \n",
            "  inflating: data/davis/aln/CSNK1A1L.aln  \n",
            "  inflating: data/davis/aln/CSNK1D.aln  \n",
            "  inflating: data/davis/aln/CSNK1E.aln  \n",
            "  inflating: data/davis/aln/CSNK1G1.aln  \n",
            "  inflating: data/davis/aln/CSNK1G2.aln  \n",
            "  inflating: data/davis/aln/CSNK1G3.aln  \n",
            "  inflating: data/davis/aln/CSNK2A1.aln  \n",
            "  inflating: data/davis/aln/CSNK2A2.aln  \n",
            "  inflating: data/davis/aln/CTK.aln  \n",
            "  inflating: data/davis/aln/DAPK1.aln  \n",
            "  inflating: data/davis/aln/DAPK2.aln  \n",
            "  inflating: data/davis/aln/DAPK3.aln  \n",
            "  inflating: data/davis/aln/DCAMKL1.aln  \n",
            "  inflating: data/davis/aln/DCAMKL2.aln  \n",
            "  inflating: data/davis/aln/DCAMKL3.aln  \n",
            "  inflating: data/davis/aln/DDR1.aln  \n",
            "  inflating: data/davis/aln/DDR2.aln  \n",
            "  inflating: data/davis/aln/DLK.aln  \n",
            "  inflating: data/davis/aln/DMPK.aln  \n",
            "  inflating: data/davis/aln/DMPK2.aln  \n",
            "  inflating: data/davis/aln/DRAK1.aln  \n",
            "  inflating: data/davis/aln/DRAK2.aln  \n",
            "  inflating: data/davis/aln/DYRK1A.aln  \n",
            "  inflating: data/davis/aln/DYRK1B.aln  \n",
            "  inflating: data/davis/aln/DYRK2.aln  \n",
            "  inflating: data/davis/aln/EGFR(E746A750del).aln  \n",
            "  inflating: data/davis/aln/EGFR(G719C).aln  \n",
            "  inflating: data/davis/aln/EGFR(G719S).aln  \n",
            "  inflating: data/davis/aln/EGFR(L747E749del).aln  \n",
            "  inflating: data/davis/aln/EGFR(L747S752del).aln  \n",
            "  inflating: data/davis/aln/EGFR(L747T751del).aln  \n",
            "  inflating: data/davis/aln/EGFR(L858R).aln  \n",
            "  inflating: data/davis/aln/EGFR(L858RT790M).aln  \n",
            "  inflating: data/davis/aln/EGFR(L861Q).aln  \n",
            "  inflating: data/davis/aln/EGFR(S752I759del).aln  \n",
            "  inflating: data/davis/aln/EGFR(T790M).aln  \n",
            "  inflating: data/davis/aln/EGFR.aln  \n",
            "  inflating: data/davis/aln/EIF2AK1.aln  \n",
            "  inflating: data/davis/aln/EPHA1.aln  \n",
            "  inflating: data/davis/aln/EPHA2.aln  \n",
            "  inflating: data/davis/aln/EPHA3.aln  \n",
            "  inflating: data/davis/aln/EPHA4.aln  \n",
            "  inflating: data/davis/aln/EPHA5.aln  \n",
            "  inflating: data/davis/aln/EPHA6.aln  \n",
            "  inflating: data/davis/aln/EPHA7.aln  \n",
            "  inflating: data/davis/aln/EPHA8.aln  \n",
            "  inflating: data/davis/aln/EPHB1.aln  \n",
            "  inflating: data/davis/aln/EPHB2.aln  \n",
            "  inflating: data/davis/aln/EPHB3.aln  \n",
            "  inflating: data/davis/aln/EPHB4.aln  \n",
            "  inflating: data/davis/aln/EPHB6.aln  \n",
            "  inflating: data/davis/aln/ERBB2.aln  \n",
            "  inflating: data/davis/aln/ERBB3.aln  \n",
            "  inflating: data/davis/aln/ERBB4.aln  \n",
            "  inflating: data/davis/aln/ERK1.aln  \n",
            "  inflating: data/davis/aln/ERK2.aln  \n",
            "  inflating: data/davis/aln/ERK3.aln  \n",
            "  inflating: data/davis/aln/ERK4.aln  \n",
            "  inflating: data/davis/aln/ERK5.aln  \n",
            "  inflating: data/davis/aln/ERK8.aln  \n",
            "  inflating: data/davis/aln/ERN1.aln  \n",
            "  inflating: data/davis/aln/FAK.aln  \n",
            "  inflating: data/davis/aln/FER.aln  \n",
            "  inflating: data/davis/aln/FES.aln  \n",
            "  inflating: data/davis/aln/FGFR1.aln  \n",
            "  inflating: data/davis/aln/FGFR2.aln  \n",
            "  inflating: data/davis/aln/FGFR3(G697C).aln  \n",
            "  inflating: data/davis/aln/FGFR3.aln  \n",
            "  inflating: data/davis/aln/FGFR4.aln  \n",
            "  inflating: data/davis/aln/FGR.aln  \n",
            "  inflating: data/davis/aln/FLT1.aln  \n",
            "  inflating: data/davis/aln/FLT3(D835H).aln  \n",
            "  inflating: data/davis/aln/FLT3(D835Y).aln  \n",
            "  inflating: data/davis/aln/FLT3(ITD).aln  \n",
            "  inflating: data/davis/aln/FLT3(K663Q).aln  \n",
            "  inflating: data/davis/aln/FLT3(N841I).aln  \n",
            "  inflating: data/davis/aln/FLT3(R834Q).aln  \n",
            "  inflating: data/davis/aln/FLT3.aln  \n",
            "  inflating: data/davis/aln/FLT4.aln  \n",
            "  inflating: data/davis/aln/FRK.aln  \n",
            "  inflating: data/davis/aln/FYN.aln  \n",
            "  inflating: data/davis/aln/GAK.aln  \n",
            "  inflating: data/davis/aln/GCN2(KinDom2S808G).aln  \n",
            "  inflating: data/davis/aln/GRK1.aln  \n",
            "  inflating: data/davis/aln/GRK4.aln  \n",
            "  inflating: data/davis/aln/GRK7.aln  \n",
            "  inflating: data/davis/aln/GSK3A.aln  \n",
            "  inflating: data/davis/aln/GSK3B.aln  \n",
            "  inflating: data/davis/aln/HCK.aln  \n",
            "  inflating: data/davis/aln/HIPK1.aln  \n",
            "  inflating: data/davis/aln/HIPK2.aln  \n",
            "  inflating: data/davis/aln/HIPK3.aln  \n",
            "  inflating: data/davis/aln/HIPK4.aln  \n",
            "  inflating: data/davis/aln/HPK1.aln  \n",
            "  inflating: data/davis/aln/HUNK.aln  \n",
            "  inflating: data/davis/aln/ICK.aln  \n",
            "  inflating: data/davis/aln/IGF1R.aln  \n",
            "  inflating: data/davis/aln/IKK-alpha.aln  \n",
            "  inflating: data/davis/aln/IKK-beta.aln  \n",
            "  inflating: data/davis/aln/IKK-epsilon.aln  \n",
            "  inflating: data/davis/aln/INSR.aln  \n",
            "  inflating: data/davis/aln/INSRR.aln  \n",
            "  inflating: data/davis/aln/IRAK1.aln  \n",
            "  inflating: data/davis/aln/IRAK3.aln  \n",
            "  inflating: data/davis/aln/IRAK4.aln  \n",
            "  inflating: data/davis/aln/ITK.aln  \n",
            "  inflating: data/davis/aln/JAK1(JH1domain-catalytic).aln  \n",
            "  inflating: data/davis/aln/JAK1(JH2domain-pseudokinase).aln  \n",
            "  inflating: data/davis/aln/JAK2(JH1domain-catalytic).aln  \n",
            "  inflating: data/davis/aln/JAK3(JH1domain-catalytic).aln  \n",
            "  inflating: data/davis/aln/JNK1.aln  \n",
            "  inflating: data/davis/aln/JNK2.aln  \n",
            "  inflating: data/davis/aln/JNK3.aln  \n",
            "  inflating: data/davis/aln/KIT(A829P).aln  \n",
            "  inflating: data/davis/aln/KIT(D816H).aln  \n",
            "  inflating: data/davis/aln/KIT(D816V).aln  \n",
            "  inflating: data/davis/aln/KIT(L576P).aln  \n",
            "  inflating: data/davis/aln/KIT(V559D).aln  \n",
            "  inflating: data/davis/aln/KIT(V559D-T670I).aln  \n",
            "  inflating: data/davis/aln/KIT(V559D-V654A).aln  \n",
            "  inflating: data/davis/aln/KIT.aln  \n",
            "  inflating: data/davis/aln/LATS1.aln  \n",
            "  inflating: data/davis/aln/LATS2.aln  \n",
            "  inflating: data/davis/aln/LCK.aln  \n",
            "  inflating: data/davis/aln/LIMK1.aln  \n",
            "  inflating: data/davis/aln/LIMK2.aln  \n",
            "  inflating: data/davis/aln/LKB1.aln  \n",
            "  inflating: data/davis/aln/LOK.aln  \n",
            "  inflating: data/davis/aln/LRRK2(G2019S).aln  \n",
            "  inflating: data/davis/aln/LRRK2.aln  \n",
            "  inflating: data/davis/aln/LTK.aln  \n",
            "  inflating: data/davis/aln/LYN.aln  \n",
            "  inflating: data/davis/aln/LZK.aln  \n",
            "  inflating: data/davis/aln/MAK.aln  \n",
            "  inflating: data/davis/aln/MAP3K1.aln  \n",
            "  inflating: data/davis/aln/MAP3K15.aln  \n",
            "  inflating: data/davis/aln/MAP3K2.aln  \n",
            "  inflating: data/davis/aln/MAP3K3.aln  \n",
            "  inflating: data/davis/aln/MAP3K4.aln  \n",
            "  inflating: data/davis/aln/MAP4K2.aln  \n",
            "  inflating: data/davis/aln/MAP4K3.aln  \n",
            "  inflating: data/davis/aln/MAP4K4.aln  \n",
            "  inflating: data/davis/aln/MAP4K5.aln  \n",
            "  inflating: data/davis/aln/MAPKAPK2.aln  \n",
            "  inflating: data/davis/aln/MAPKAPK5.aln  \n",
            "  inflating: data/davis/aln/MARK1.aln  \n",
            "  inflating: data/davis/aln/MARK2.aln  \n",
            "  inflating: data/davis/aln/MARK3.aln  \n",
            "  inflating: data/davis/aln/MARK4.aln  \n",
            "  inflating: data/davis/aln/MAST1.aln  \n",
            "  inflating: data/davis/aln/MEK1.aln  \n",
            "  inflating: data/davis/aln/MEK2.aln  \n",
            "  inflating: data/davis/aln/MEK3.aln  \n",
            "  inflating: data/davis/aln/MEK4.aln  \n",
            "  inflating: data/davis/aln/MEK5.aln  \n",
            "  inflating: data/davis/aln/MEK6.aln  \n",
            "  inflating: data/davis/aln/MELK.aln  \n",
            "  inflating: data/davis/aln/MERTK.aln  \n",
            "  inflating: data/davis/aln/MET(M1250T).aln  \n",
            "  inflating: data/davis/aln/MET(Y1235D).aln  \n",
            "  inflating: data/davis/aln/MET.aln  \n",
            "  inflating: data/davis/aln/MINK.aln  \n",
            "  inflating: data/davis/aln/MKK7.aln  \n",
            "  inflating: data/davis/aln/MKNK1.aln  \n",
            "  inflating: data/davis/aln/MKNK2.aln  \n",
            "  inflating: data/davis/aln/MLCK.aln  \n",
            "  inflating: data/davis/aln/MLK1.aln  \n",
            "  inflating: data/davis/aln/MLK2.aln  \n",
            "  inflating: data/davis/aln/MLK3.aln  \n",
            "  inflating: data/davis/aln/MRCKA.aln  \n",
            "  inflating: data/davis/aln/MRCKB.aln  \n",
            "  inflating: data/davis/aln/MST1.aln  \n",
            "  inflating: data/davis/aln/MST1R.aln  \n",
            "  inflating: data/davis/aln/MST2.aln  \n",
            "  inflating: data/davis/aln/MST3.aln  \n",
            "  inflating: data/davis/aln/MST4.aln  \n",
            "  inflating: data/davis/aln/MTOR.aln  \n",
            "  inflating: data/davis/aln/MUSK.aln  \n",
            "  inflating: data/davis/aln/MYLK.aln  \n",
            "  inflating: data/davis/aln/MYLK2.aln  \n",
            "  inflating: data/davis/aln/MYLK4.aln  \n",
            "  inflating: data/davis/aln/MYO3A.aln  \n",
            "  inflating: data/davis/aln/MYO3B.aln  \n",
            "  inflating: data/davis/aln/NDR1.aln  \n",
            "  inflating: data/davis/aln/NDR2.aln  \n",
            "  inflating: data/davis/aln/NEK1.aln  \n",
            "  inflating: data/davis/aln/NEK11.aln  \n",
            "  inflating: data/davis/aln/NEK2.aln  \n",
            "  inflating: data/davis/aln/NEK3.aln  \n",
            "  inflating: data/davis/aln/NEK4.aln  \n",
            "  inflating: data/davis/aln/NEK5.aln  \n",
            "  inflating: data/davis/aln/NEK6.aln  \n",
            "  inflating: data/davis/aln/NEK7.aln  \n",
            "  inflating: data/davis/aln/NEK9.aln  \n",
            "  inflating: data/davis/aln/NIM1.aln  \n",
            "  inflating: data/davis/aln/NLK.aln  \n",
            "  inflating: data/davis/aln/OSR1.aln  \n",
            "  inflating: data/davis/aln/PAK1.aln  \n",
            "  inflating: data/davis/aln/PAK2.aln  \n",
            "  inflating: data/davis/aln/PAK3.aln  \n",
            "  inflating: data/davis/aln/PAK4.aln  \n",
            "  inflating: data/davis/aln/PAK6.aln  \n",
            "  inflating: data/davis/aln/PAK7.aln  \n",
            "  inflating: data/davis/aln/PCTK1.aln  \n",
            "  inflating: data/davis/aln/PCTK2.aln  \n",
            "  inflating: data/davis/aln/PCTK3.aln  \n",
            "  inflating: data/davis/aln/PDGFRA.aln  \n",
            "  inflating: data/davis/aln/PDGFRB.aln  \n",
            "  inflating: data/davis/aln/PDPK1.aln  \n",
            "  inflating: data/davis/aln/PFCDPK1(Pfalciparum).aln  \n",
            "  inflating: data/davis/aln/PFPK5(Pfalciparum).aln  \n",
            "  inflating: data/davis/aln/PFTAIRE2.aln  \n",
            "  inflating: data/davis/aln/PFTK1.aln  \n",
            "  inflating: data/davis/aln/PHKG1.aln  \n",
            "  inflating: data/davis/aln/PHKG2.aln  \n",
            "  inflating: data/davis/aln/PIK3C2B.aln  \n",
            "  inflating: data/davis/aln/PIK3C2G.aln  \n",
            "  inflating: data/davis/aln/PIK3CA(C420R).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(E542K).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(E545A).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(E545K).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(H1047L).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(H1047Y).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(I800L).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(M1043I).aln  \n",
            "  inflating: data/davis/aln/PIK3CA(Q546K).aln  \n",
            "  inflating: data/davis/aln/PIK3CA.aln  \n",
            "  inflating: data/davis/aln/PIK3CB.aln  \n",
            "  inflating: data/davis/aln/PIK3CD.aln  \n",
            "  inflating: data/davis/aln/PIK3CG.aln  \n",
            "  inflating: data/davis/aln/PIK4CB.aln  \n",
            "  inflating: data/davis/aln/PIM1.aln  \n",
            "  inflating: data/davis/aln/PIM2.aln  \n",
            "  inflating: data/davis/aln/PIM3.aln  \n",
            "  inflating: data/davis/aln/PIP5K1A.aln  \n",
            "  inflating: data/davis/aln/PIP5K1C.aln  \n",
            "  inflating: data/davis/aln/PIP5K2B.aln  \n",
            "  inflating: data/davis/aln/PIP5K2C.aln  \n",
            "  inflating: data/davis/aln/PKAC-alpha.aln  \n",
            "  inflating: data/davis/aln/PKAC-beta.aln  \n",
            "  inflating: data/davis/aln/PKMYT1.aln  \n",
            "  inflating: data/davis/aln/PKN1.aln  \n",
            "  inflating: data/davis/aln/PKN2.aln  \n",
            "  inflating: data/davis/aln/PKNB(Mtuberculosis).aln  \n",
            "  inflating: data/davis/aln/PLK1.aln  \n",
            "  inflating: data/davis/aln/PLK2.aln  \n",
            "  inflating: data/davis/aln/PLK3.aln  \n",
            "  inflating: data/davis/aln/PLK4.aln  \n",
            "  inflating: data/davis/aln/PRKCD.aln  \n",
            "  inflating: data/davis/aln/PRKCE.aln  \n",
            "  inflating: data/davis/aln/PRKCH.aln  \n",
            "  inflating: data/davis/aln/PRKCI.aln  \n",
            "  inflating: data/davis/aln/PRKCQ.aln  \n",
            "  inflating: data/davis/aln/PRKD1.aln  \n",
            "  inflating: data/davis/aln/PRKD2.aln  \n",
            "  inflating: data/davis/aln/PRKD3.aln  \n",
            "  inflating: data/davis/aln/PRKG1.aln  \n",
            "  inflating: data/davis/aln/PRKG2.aln  \n",
            "  inflating: data/davis/aln/PRKR.aln  \n",
            "  inflating: data/davis/aln/PRKX.aln  \n",
            "  inflating: data/davis/aln/PRP4.aln  \n",
            "  inflating: data/davis/aln/PYK2.aln  \n",
            "  inflating: data/davis/aln/QSK.aln  \n",
            "  inflating: data/davis/aln/RAF1.aln  \n",
            "  inflating: data/davis/aln/RET(M918T).aln  \n",
            "  inflating: data/davis/aln/RET(V804L).aln  \n",
            "  inflating: data/davis/aln/RET(V804M).aln  \n",
            "  inflating: data/davis/aln/RET.aln  \n",
            "  inflating: data/davis/aln/RIOK1.aln  \n",
            "  inflating: data/davis/aln/RIOK2.aln  \n",
            "  inflating: data/davis/aln/RIOK3.aln  \n",
            "  inflating: data/davis/aln/RIPK1.aln  \n",
            "  inflating: data/davis/aln/RIPK2.aln  \n",
            "  inflating: data/davis/aln/RIPK4.aln  \n",
            "  inflating: data/davis/aln/RIPK5.aln  \n",
            "  inflating: data/davis/aln/ROCK1.aln  \n",
            "  inflating: data/davis/aln/ROCK2.aln  \n",
            "  inflating: data/davis/aln/ROS1.aln  \n",
            "  inflating: data/davis/aln/RPS6KA4(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RPS6KA4(KinDom.2-C-terminal).aln  \n",
            "  inflating: data/davis/aln/RPS6KA5(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RPS6KA5(KinDom.2-C-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK1(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK1(KinDom.2-C-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK2(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK3(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK3(KinDom.2-C-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK4(KinDom.1-N-terminal).aln  \n",
            "  inflating: data/davis/aln/RSK4(KinDom.2-C-terminal).aln  \n",
            "  inflating: data/davis/aln/S6K1.aln  \n",
            "  inflating: data/davis/aln/SBK1.aln  \n",
            "  inflating: data/davis/aln/SGK3.aln  \n",
            "  inflating: data/davis/aln/SIK.aln  \n",
            "  inflating: data/davis/aln/SIK2.aln  \n",
            "  inflating: data/davis/aln/SLK.aln  \n",
            "  inflating: data/davis/aln/SNARK.aln  \n",
            "  inflating: data/davis/aln/SNRK.aln  \n",
            "  inflating: data/davis/aln/SRC.aln  \n",
            "  inflating: data/davis/aln/SRMS.aln  \n",
            "  inflating: data/davis/aln/SRPK1.aln  \n",
            "  inflating: data/davis/aln/SRPK2.aln  \n",
            "  inflating: data/davis/aln/SRPK3.aln  \n",
            "  inflating: data/davis/aln/STK16.aln  \n",
            "  inflating: data/davis/aln/STK33.aln  \n",
            "  inflating: data/davis/aln/STK35.aln  \n",
            "  inflating: data/davis/aln/STK36.aln  \n",
            "  inflating: data/davis/aln/STK39.aln  \n",
            "  inflating: data/davis/aln/SYK.aln  \n",
            "  inflating: data/davis/aln/SgK110.aln  \n",
            "  inflating: data/davis/aln/TAK1.aln  \n",
            "  inflating: data/davis/aln/TAOK1.aln  \n",
            "  inflating: data/davis/aln/TAOK2.aln  \n",
            "  inflating: data/davis/aln/TAOK3.aln  \n",
            "  inflating: data/davis/aln/TBK1.aln  \n",
            "  inflating: data/davis/aln/TEC.aln  \n",
            "  inflating: data/davis/aln/TESK1.aln  \n",
            "  inflating: data/davis/aln/TGFBR1.aln  \n",
            "  inflating: data/davis/aln/TGFBR2.aln  \n",
            "  inflating: data/davis/aln/TIE1.aln  \n",
            "  inflating: data/davis/aln/TIE2.aln  \n",
            "  inflating: data/davis/aln/TLK1.aln  \n",
            "  inflating: data/davis/aln/TLK2.aln  \n",
            "  inflating: data/davis/aln/TNIK.aln  \n",
            "  inflating: data/davis/aln/TNK1.aln  \n",
            "  inflating: data/davis/aln/TNK2.aln  \n",
            "  inflating: data/davis/aln/TNNI3K.aln  \n",
            "  inflating: data/davis/aln/TRKA.aln  \n",
            "  inflating: data/davis/aln/TRKB.aln  \n",
            "  inflating: data/davis/aln/TRKC.aln  \n",
            "  inflating: data/davis/aln/TRPM6.aln  \n",
            "  inflating: data/davis/aln/TSSK1B.aln  \n",
            "  inflating: data/davis/aln/TTK.aln  \n",
            "  inflating: data/davis/aln/TXK.aln  \n",
            "  inflating: data/davis/aln/TYK2(JH1domain-catalytic).aln  \n",
            "  inflating: data/davis/aln/TYK2(JH2domain-pseudokinase).aln  \n",
            "  inflating: data/davis/aln/TYRO3.aln  \n",
            "  inflating: data/davis/aln/ULK1.aln  \n",
            "  inflating: data/davis/aln/ULK2.aln  \n",
            "  inflating: data/davis/aln/ULK3.aln  \n",
            "  inflating: data/davis/aln/VEGFR2.aln  \n",
            "  inflating: data/davis/aln/VRK2.aln  \n",
            "  inflating: data/davis/aln/WEE1.aln  \n",
            "  inflating: data/davis/aln/WEE2.aln  \n",
            "  inflating: data/davis/aln/YANK1.aln  \n",
            "  inflating: data/davis/aln/YANK2.aln  \n",
            "  inflating: data/davis/aln/YANK3.aln  \n",
            "  inflating: data/davis/aln/YES.aln  \n",
            "  inflating: data/davis/aln/YSK1.aln  \n",
            "  inflating: data/davis/aln/YSK4.aln  \n",
            "  inflating: data/davis/aln/ZAK.aln  \n",
            "  inflating: data/davis/aln/ZAP70.aln  \n",
            "  inflating: data/davis/aln/p38-alpha.aln  \n",
            "  inflating: data/davis/aln/p38-beta.aln  \n",
            "  inflating: data/davis/aln/p38-delta.aln  \n",
            "  inflating: data/davis/aln/p38-gamma.aln  \n",
            "   creating: data/davis/pconsc4/\n",
            "  inflating: data/davis/pconsc4/AAK1.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(E255K).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(F317I).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(F317I)p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(F317L).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(F317L)p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(H396P).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(H396P)p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(M351T).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(Q252H).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(Q252H)p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(T315I).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(T315I)p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1(Y253F).npy  \n",
            "  inflating: data/davis/pconsc4/ABL1.npy  \n",
            "  inflating: data/davis/pconsc4/ABL1p.npy  \n",
            "  inflating: data/davis/pconsc4/ABL2.npy  \n",
            "  inflating: data/davis/pconsc4/ACVR1.npy  \n",
            "  inflating: data/davis/pconsc4/ACVR1B.npy  \n",
            "  inflating: data/davis/pconsc4/ACVR2A.npy  \n",
            "  inflating: data/davis/pconsc4/ACVR2B.npy  \n",
            "  inflating: data/davis/pconsc4/ACVRL1.npy  \n",
            "  inflating: data/davis/pconsc4/ADCK3.npy  \n",
            "  inflating: data/davis/pconsc4/ADCK4.npy  \n",
            "  inflating: data/davis/pconsc4/AKT1.npy  \n",
            "  inflating: data/davis/pconsc4/AKT2.npy  \n",
            "  inflating: data/davis/pconsc4/AKT3.npy  \n",
            "  inflating: data/davis/pconsc4/ALK.npy  \n",
            "  inflating: data/davis/pconsc4/AMPK-alpha1.npy  \n",
            "  inflating: data/davis/pconsc4/AMPK-alpha2.npy  \n",
            "  inflating: data/davis/pconsc4/ANKK1.npy  \n",
            "  inflating: data/davis/pconsc4/ARK5.npy  \n",
            "  inflating: data/davis/pconsc4/ASK1.npy  \n",
            "  inflating: data/davis/pconsc4/ASK2.npy  \n",
            "  inflating: data/davis/pconsc4/AURKA.npy  \n",
            "  inflating: data/davis/pconsc4/AURKB.npy  \n",
            "  inflating: data/davis/pconsc4/AURKC.npy  \n",
            "  inflating: data/davis/pconsc4/AXL.npy  \n",
            "  inflating: data/davis/pconsc4/BIKE.npy  \n",
            "  inflating: data/davis/pconsc4/BLK.npy  \n",
            "  inflating: data/davis/pconsc4/BMPR1A.npy  \n",
            "  inflating: data/davis/pconsc4/BMPR1B.npy  \n",
            "  inflating: data/davis/pconsc4/BMPR2.npy  \n",
            "  inflating: data/davis/pconsc4/BMX.npy  \n",
            "  inflating: data/davis/pconsc4/BRAF(V600E).npy  \n",
            "  inflating: data/davis/pconsc4/BRAF.npy  \n",
            "  inflating: data/davis/pconsc4/BRK.npy  \n",
            "  inflating: data/davis/pconsc4/BRSK1.npy  \n",
            "  inflating: data/davis/pconsc4/BRSK2.npy  \n",
            "  inflating: data/davis/pconsc4/BTK.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK1.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK1D.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK1G.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK2A.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK2B.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK2D.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK2G.npy  \n",
            "  inflating: data/davis/pconsc4/CAMK4.npy  \n",
            "  inflating: data/davis/pconsc4/CAMKK1.npy  \n",
            "  inflating: data/davis/pconsc4/CAMKK2.npy  \n",
            "  inflating: data/davis/pconsc4/CASK.npy  \n",
            "  inflating: data/davis/pconsc4/CDC2L1.npy  \n",
            "  inflating: data/davis/pconsc4/CDC2L2.npy  \n",
            "  inflating: data/davis/pconsc4/CDC2L5.npy  \n",
            "  inflating: data/davis/pconsc4/CDK11.npy  \n",
            "  inflating: data/davis/pconsc4/CDK2.npy  \n",
            "  inflating: data/davis/pconsc4/CDK3.npy  \n",
            "  inflating: data/davis/pconsc4/CDK4-cyclinD1.npy  \n",
            "  inflating: data/davis/pconsc4/CDK4-cyclinD3.npy  \n",
            "  inflating: data/davis/pconsc4/CDK5.npy  \n",
            "  inflating: data/davis/pconsc4/CDK7.npy  \n",
            "  inflating: data/davis/pconsc4/CDK8.npy  \n",
            "  inflating: data/davis/pconsc4/CDK9.npy  \n",
            "  inflating: data/davis/pconsc4/CDKL1.npy  \n",
            "  inflating: data/davis/pconsc4/CDKL2.npy  \n",
            "  inflating: data/davis/pconsc4/CDKL3.npy  \n",
            "  inflating: data/davis/pconsc4/CDKL5.npy  \n",
            "  inflating: data/davis/pconsc4/CHEK1.npy  \n",
            "  inflating: data/davis/pconsc4/CHEK2.npy  \n",
            "  inflating: data/davis/pconsc4/CIT.npy  \n",
            "  inflating: data/davis/pconsc4/CLK1.npy  \n",
            "  inflating: data/davis/pconsc4/CLK2.npy  \n",
            "  inflating: data/davis/pconsc4/CLK3.npy  \n",
            "  inflating: data/davis/pconsc4/CLK4.npy  \n",
            "  inflating: data/davis/pconsc4/CSF1R.npy  \n",
            "  inflating: data/davis/pconsc4/CSK.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1A1.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1A1L.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1D.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1E.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1G1.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1G2.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK1G3.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK2A1.npy  \n",
            "  inflating: data/davis/pconsc4/CSNK2A2.npy  \n",
            "  inflating: data/davis/pconsc4/CTK.npy  \n",
            "  inflating: data/davis/pconsc4/DAPK1.npy  \n",
            "  inflating: data/davis/pconsc4/DAPK2.npy  \n",
            "  inflating: data/davis/pconsc4/DAPK3.npy  \n",
            "  inflating: data/davis/pconsc4/DCAMKL1.npy  \n",
            "  inflating: data/davis/pconsc4/DCAMKL2.npy  \n",
            "  inflating: data/davis/pconsc4/DCAMKL3.npy  \n",
            "  inflating: data/davis/pconsc4/DDR1.npy  \n",
            "  inflating: data/davis/pconsc4/DDR2.npy  \n",
            "  inflating: data/davis/pconsc4/DLK.npy  \n",
            "  inflating: data/davis/pconsc4/DMPK.npy  \n",
            "  inflating: data/davis/pconsc4/DMPK2.npy  \n",
            "  inflating: data/davis/pconsc4/DRAK1.npy  \n",
            "  inflating: data/davis/pconsc4/DRAK2.npy  \n",
            "  inflating: data/davis/pconsc4/DYRK1A.npy  \n",
            "  inflating: data/davis/pconsc4/DYRK1B.npy  \n",
            "  inflating: data/davis/pconsc4/DYRK2.npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(E746A750del).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(G719C).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(G719S).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L747E749del).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L747S752del).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L747T751del).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L858R).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L858RT790M).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(L861Q).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(S752I759del).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR(T790M).npy  \n",
            "  inflating: data/davis/pconsc4/EGFR.npy  \n",
            "  inflating: data/davis/pconsc4/EIF2AK1.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA1.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA2.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA3.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA4.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA5.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA6.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA7.npy  \n",
            "  inflating: data/davis/pconsc4/EPHA8.npy  \n",
            "  inflating: data/davis/pconsc4/EPHB1.npy  \n",
            "  inflating: data/davis/pconsc4/EPHB2.npy  \n",
            "  inflating: data/davis/pconsc4/EPHB3.npy  \n",
            "  inflating: data/davis/pconsc4/EPHB4.npy  \n",
            "  inflating: data/davis/pconsc4/EPHB6.npy  \n",
            "  inflating: data/davis/pconsc4/ERBB2.npy  \n",
            "  inflating: data/davis/pconsc4/ERBB3.npy  \n",
            "  inflating: data/davis/pconsc4/ERBB4.npy  \n",
            "  inflating: data/davis/pconsc4/ERK1.npy  \n",
            "  inflating: data/davis/pconsc4/ERK2.npy  \n",
            "  inflating: data/davis/pconsc4/ERK3.npy  \n",
            "  inflating: data/davis/pconsc4/ERK4.npy  \n",
            "  inflating: data/davis/pconsc4/ERK5.npy  \n",
            "  inflating: data/davis/pconsc4/ERK8.npy  \n",
            "  inflating: data/davis/pconsc4/ERN1.npy  \n",
            "  inflating: data/davis/pconsc4/FAK.npy  \n",
            "  inflating: data/davis/pconsc4/FER.npy  \n",
            "  inflating: data/davis/pconsc4/FES.npy  \n",
            "  inflating: data/davis/pconsc4/FGFR1.npy  \n",
            "  inflating: data/davis/pconsc4/FGFR2.npy  \n",
            "  inflating: data/davis/pconsc4/FGFR3(G697C).npy  \n",
            "  inflating: data/davis/pconsc4/FGFR3.npy  \n",
            "  inflating: data/davis/pconsc4/FGFR4.npy  \n",
            "  inflating: data/davis/pconsc4/FGR.npy  \n",
            "  inflating: data/davis/pconsc4/FLT1.npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(D835H).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(D835Y).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(ITD).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(K663Q).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(N841I).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3(R834Q).npy  \n",
            "  inflating: data/davis/pconsc4/FLT3.npy  \n",
            "  inflating: data/davis/pconsc4/FLT4.npy  \n",
            "  inflating: data/davis/pconsc4/FRK.npy  \n",
            "  inflating: data/davis/pconsc4/FYN.npy  \n",
            "  inflating: data/davis/pconsc4/GAK.npy  \n",
            "  inflating: data/davis/pconsc4/GCN2(KinDom2S808G).npy  \n",
            "  inflating: data/davis/pconsc4/GRK1.npy  \n",
            "  inflating: data/davis/pconsc4/GRK4.npy  \n",
            "  inflating: data/davis/pconsc4/GRK7.npy  \n",
            "  inflating: data/davis/pconsc4/GSK3A.npy  \n",
            "  inflating: data/davis/pconsc4/GSK3B.npy  \n",
            "  inflating: data/davis/pconsc4/HCK.npy  \n",
            "  inflating: data/davis/pconsc4/HIPK1.npy  \n",
            "  inflating: data/davis/pconsc4/HIPK2.npy  \n",
            "  inflating: data/davis/pconsc4/HIPK3.npy  \n",
            "  inflating: data/davis/pconsc4/HIPK4.npy  \n",
            "  inflating: data/davis/pconsc4/HPK1.npy  \n",
            "  inflating: data/davis/pconsc4/HUNK.npy  \n",
            "  inflating: data/davis/pconsc4/ICK.npy  \n",
            "  inflating: data/davis/pconsc4/IGF1R.npy  \n",
            "  inflating: data/davis/pconsc4/IKK-alpha.npy  \n",
            "  inflating: data/davis/pconsc4/IKK-beta.npy  \n",
            "  inflating: data/davis/pconsc4/IKK-epsilon.npy  \n",
            "  inflating: data/davis/pconsc4/INSR.npy  \n",
            "  inflating: data/davis/pconsc4/INSRR.npy  \n",
            "  inflating: data/davis/pconsc4/IRAK1.npy  \n",
            "  inflating: data/davis/pconsc4/IRAK3.npy  \n",
            "  inflating: data/davis/pconsc4/IRAK4.npy  \n",
            "  inflating: data/davis/pconsc4/ITK.npy  \n",
            "  inflating: data/davis/pconsc4/JAK1(JH1domain-catalytic).npy  \n",
            "  inflating: data/davis/pconsc4/JAK1(JH2domain-pseudokinase).npy  \n",
            "  inflating: data/davis/pconsc4/JAK2(JH1domain-catalytic).npy  \n",
            "  inflating: data/davis/pconsc4/JAK3(JH1domain-catalytic).npy  \n",
            "  inflating: data/davis/pconsc4/JNK1.npy  \n",
            "  inflating: data/davis/pconsc4/JNK2.npy  \n",
            "  inflating: data/davis/pconsc4/JNK3.npy  \n",
            "  inflating: data/davis/pconsc4/KIT(A829P).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(D816H).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(D816V).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(L576P).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(V559D).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(V559D-T670I).npy  \n",
            "  inflating: data/davis/pconsc4/KIT(V559D-V654A).npy  \n",
            "  inflating: data/davis/pconsc4/KIT.npy  \n",
            "  inflating: data/davis/pconsc4/LATS1.npy  \n",
            "  inflating: data/davis/pconsc4/LATS2.npy  \n",
            "  inflating: data/davis/pconsc4/LCK.npy  \n",
            "  inflating: data/davis/pconsc4/LIMK1.npy  \n",
            "  inflating: data/davis/pconsc4/LIMK2.npy  \n",
            "  inflating: data/davis/pconsc4/LKB1.npy  \n",
            "  inflating: data/davis/pconsc4/LOK.npy  \n",
            "  inflating: data/davis/pconsc4/LRRK2(G2019S).npy  \n",
            "  inflating: data/davis/pconsc4/LRRK2.npy  \n",
            "  inflating: data/davis/pconsc4/LTK.npy  \n",
            "  inflating: data/davis/pconsc4/LYN.npy  \n",
            "  inflating: data/davis/pconsc4/LZK.npy  \n",
            "  inflating: data/davis/pconsc4/MAK.npy  \n",
            "  inflating: data/davis/pconsc4/MAP3K1.npy  \n",
            "  inflating: data/davis/pconsc4/MAP3K15.npy  \n",
            "  inflating: data/davis/pconsc4/MAP3K2.npy  \n",
            "  inflating: data/davis/pconsc4/MAP3K3.npy  \n",
            "  inflating: data/davis/pconsc4/MAP3K4.npy  \n",
            "  inflating: data/davis/pconsc4/MAP4K2.npy  \n",
            "  inflating: data/davis/pconsc4/MAP4K3.npy  \n",
            "  inflating: data/davis/pconsc4/MAP4K4.npy  \n",
            "  inflating: data/davis/pconsc4/MAP4K5.npy  \n",
            "  inflating: data/davis/pconsc4/MAPKAPK2.npy  \n",
            "  inflating: data/davis/pconsc4/MAPKAPK5.npy  \n",
            "  inflating: data/davis/pconsc4/MARK1.npy  \n",
            "  inflating: data/davis/pconsc4/MARK2.npy  \n",
            "  inflating: data/davis/pconsc4/MARK3.npy  \n",
            "  inflating: data/davis/pconsc4/MARK4.npy  \n",
            "  inflating: data/davis/pconsc4/MAST1.npy  \n",
            "  inflating: data/davis/pconsc4/MEK1.npy  \n",
            "  inflating: data/davis/pconsc4/MEK2.npy  \n",
            "  inflating: data/davis/pconsc4/MEK3.npy  \n",
            "  inflating: data/davis/pconsc4/MEK4.npy  \n",
            "  inflating: data/davis/pconsc4/MEK5.npy  \n",
            "  inflating: data/davis/pconsc4/MEK6.npy  \n",
            "  inflating: data/davis/pconsc4/MELK.npy  \n",
            "  inflating: data/davis/pconsc4/MERTK.npy  \n",
            "  inflating: data/davis/pconsc4/MET(M1250T).npy  \n",
            "  inflating: data/davis/pconsc4/MET(Y1235D).npy  \n",
            "  inflating: data/davis/pconsc4/MET.npy  \n",
            "  inflating: data/davis/pconsc4/MINK.npy  \n",
            "  inflating: data/davis/pconsc4/MKK7.npy  \n",
            "  inflating: data/davis/pconsc4/MKNK1.npy  \n",
            "  inflating: data/davis/pconsc4/MKNK2.npy  \n",
            "  inflating: data/davis/pconsc4/MLCK.npy  \n",
            "  inflating: data/davis/pconsc4/MLK1.npy  \n",
            "  inflating: data/davis/pconsc4/MLK2.npy  \n",
            "  inflating: data/davis/pconsc4/MLK3.npy  \n",
            "  inflating: data/davis/pconsc4/MRCKA.npy  \n",
            "  inflating: data/davis/pconsc4/MRCKB.npy  \n",
            "  inflating: data/davis/pconsc4/MST1.npy  \n",
            "  inflating: data/davis/pconsc4/MST1R.npy  \n",
            "  inflating: data/davis/pconsc4/MST2.npy  \n",
            "  inflating: data/davis/pconsc4/MST3.npy  \n",
            "  inflating: data/davis/pconsc4/MST4.npy  \n",
            "  inflating: data/davis/pconsc4/MTOR.npy  \n",
            "  inflating: data/davis/pconsc4/MUSK.npy  \n",
            "  inflating: data/davis/pconsc4/MYLK.npy  \n",
            "  inflating: data/davis/pconsc4/MYLK2.npy  \n",
            "  inflating: data/davis/pconsc4/MYLK4.npy  \n",
            "  inflating: data/davis/pconsc4/MYO3A.npy  \n",
            "  inflating: data/davis/pconsc4/MYO3B.npy  \n",
            "  inflating: data/davis/pconsc4/NDR1.npy  \n",
            "  inflating: data/davis/pconsc4/NDR2.npy  \n",
            "  inflating: data/davis/pconsc4/NEK1.npy  \n",
            "  inflating: data/davis/pconsc4/NEK11.npy  \n",
            "  inflating: data/davis/pconsc4/NEK2.npy  \n",
            "  inflating: data/davis/pconsc4/NEK3.npy  \n",
            "  inflating: data/davis/pconsc4/NEK4.npy  \n",
            "  inflating: data/davis/pconsc4/NEK5.npy  \n",
            "  inflating: data/davis/pconsc4/NEK6.npy  \n",
            "  inflating: data/davis/pconsc4/NEK7.npy  \n",
            "  inflating: data/davis/pconsc4/NEK9.npy  \n",
            "  inflating: data/davis/pconsc4/NIM1.npy  \n",
            "  inflating: data/davis/pconsc4/NLK.npy  \n",
            "  inflating: data/davis/pconsc4/OSR1.npy  \n",
            "  inflating: data/davis/pconsc4/PAK1.npy  \n",
            "  inflating: data/davis/pconsc4/PAK2.npy  \n",
            "  inflating: data/davis/pconsc4/PAK3.npy  \n",
            "  inflating: data/davis/pconsc4/PAK4.npy  \n",
            "  inflating: data/davis/pconsc4/PAK6.npy  \n",
            "  inflating: data/davis/pconsc4/PAK7.npy  \n",
            "  inflating: data/davis/pconsc4/PCTK1.npy  \n",
            "  inflating: data/davis/pconsc4/PCTK2.npy  \n",
            "  inflating: data/davis/pconsc4/PCTK3.npy  \n",
            "  inflating: data/davis/pconsc4/PDGFRA.npy  \n",
            "  inflating: data/davis/pconsc4/PDGFRB.npy  \n",
            "  inflating: data/davis/pconsc4/PDPK1.npy  \n",
            "  inflating: data/davis/pconsc4/PFCDPK1(Pfalciparum).npy  \n",
            "  inflating: data/davis/pconsc4/PFPK5(Pfalciparum).npy  \n",
            "  inflating: data/davis/pconsc4/PFTAIRE2.npy  \n",
            "  inflating: data/davis/pconsc4/PFTK1.npy  \n",
            "  inflating: data/davis/pconsc4/PHKG1.npy  \n",
            "  inflating: data/davis/pconsc4/PHKG2.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3C2B.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3C2G.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(C420R).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(E542K).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(E545A).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(E545K).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(H1047L).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(H1047Y).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(I800L).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(M1043I).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA(Q546K).npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CA.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CB.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CD.npy  \n",
            "  inflating: data/davis/pconsc4/PIK3CG.npy  \n",
            "  inflating: data/davis/pconsc4/PIK4CB.npy  \n",
            "  inflating: data/davis/pconsc4/PIM1.npy  \n",
            "  inflating: data/davis/pconsc4/PIM2.npy  \n",
            "  inflating: data/davis/pconsc4/PIM3.npy  \n",
            "  inflating: data/davis/pconsc4/PIP5K1A.npy  \n",
            "  inflating: data/davis/pconsc4/PIP5K1C.npy  \n",
            "  inflating: data/davis/pconsc4/PIP5K2B.npy  \n",
            "  inflating: data/davis/pconsc4/PIP5K2C.npy  \n",
            "  inflating: data/davis/pconsc4/PKAC-alpha.npy  \n",
            "  inflating: data/davis/pconsc4/PKAC-beta.npy  \n",
            "  inflating: data/davis/pconsc4/PKMYT1.npy  \n",
            "  inflating: data/davis/pconsc4/PKN1.npy  \n",
            "  inflating: data/davis/pconsc4/PKN2.npy  \n",
            "  inflating: data/davis/pconsc4/PKNB(Mtuberculosis).npy  \n",
            "  inflating: data/davis/pconsc4/PLK1.npy  \n",
            "  inflating: data/davis/pconsc4/PLK2.npy  \n",
            "  inflating: data/davis/pconsc4/PLK3.npy  \n",
            "  inflating: data/davis/pconsc4/PLK4.npy  \n",
            "  inflating: data/davis/pconsc4/PRKCD.npy  \n",
            "  inflating: data/davis/pconsc4/PRKCE.npy  \n",
            "  inflating: data/davis/pconsc4/PRKCH.npy  \n",
            "  inflating: data/davis/pconsc4/PRKCI.npy  \n",
            "  inflating: data/davis/pconsc4/PRKCQ.npy  \n",
            "  inflating: data/davis/pconsc4/PRKD1.npy  \n",
            "  inflating: data/davis/pconsc4/PRKD2.npy  \n",
            "  inflating: data/davis/pconsc4/PRKD3.npy  \n",
            "  inflating: data/davis/pconsc4/PRKG1.npy  \n",
            "  inflating: data/davis/pconsc4/PRKG2.npy  \n",
            "  inflating: data/davis/pconsc4/PRKR.npy  \n",
            "  inflating: data/davis/pconsc4/PRKX.npy  \n",
            "  inflating: data/davis/pconsc4/PRP4.npy  \n",
            "  inflating: data/davis/pconsc4/PYK2.npy  \n",
            "  inflating: data/davis/pconsc4/QSK.npy  \n",
            "  inflating: data/davis/pconsc4/RAF1.npy  \n",
            "  inflating: data/davis/pconsc4/RET(M918T).npy  \n",
            "  inflating: data/davis/pconsc4/RET(V804L).npy  \n",
            "  inflating: data/davis/pconsc4/RET(V804M).npy  \n",
            "  inflating: data/davis/pconsc4/RET.npy  \n",
            "  inflating: data/davis/pconsc4/RIOK1.npy  \n",
            "  inflating: data/davis/pconsc4/RIOK2.npy  \n",
            "  inflating: data/davis/pconsc4/RIOK3.npy  \n",
            "  inflating: data/davis/pconsc4/RIPK1.npy  \n",
            "  inflating: data/davis/pconsc4/RIPK2.npy  \n",
            "  inflating: data/davis/pconsc4/RIPK4.npy  \n",
            "  inflating: data/davis/pconsc4/RIPK5.npy  \n",
            "  inflating: data/davis/pconsc4/ROCK1.npy  \n",
            "  inflating: data/davis/pconsc4/ROCK2.npy  \n",
            "  inflating: data/davis/pconsc4/ROS1.npy  \n",
            "  inflating: data/davis/pconsc4/RPS6KA4(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RPS6KA4(KinDom.2-C-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RPS6KA5(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RPS6KA5(KinDom.2-C-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK1(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK1(KinDom.2-C-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK2(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK3(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK3(KinDom.2-C-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK4(KinDom.1-N-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/RSK4(KinDom.2-C-terminal).npy  \n",
            "  inflating: data/davis/pconsc4/S6K1.npy  \n",
            "  inflating: data/davis/pconsc4/SBK1.npy  \n",
            "  inflating: data/davis/pconsc4/SGK3.npy  \n",
            "  inflating: data/davis/pconsc4/SIK.npy  \n",
            "  inflating: data/davis/pconsc4/SIK2.npy  \n",
            "  inflating: data/davis/pconsc4/SLK.npy  \n",
            "  inflating: data/davis/pconsc4/SNARK.npy  \n",
            "  inflating: data/davis/pconsc4/SNRK.npy  \n",
            "  inflating: data/davis/pconsc4/SRC.npy  \n",
            "  inflating: data/davis/pconsc4/SRMS.npy  \n",
            "  inflating: data/davis/pconsc4/SRPK1.npy  \n",
            "  inflating: data/davis/pconsc4/SRPK2.npy  \n",
            "  inflating: data/davis/pconsc4/SRPK3.npy  \n",
            "  inflating: data/davis/pconsc4/STK16.npy  \n",
            "  inflating: data/davis/pconsc4/STK33.npy  \n",
            "  inflating: data/davis/pconsc4/STK35.npy  \n",
            "  inflating: data/davis/pconsc4/STK36.npy  \n",
            "  inflating: data/davis/pconsc4/STK39.npy  \n",
            "  inflating: data/davis/pconsc4/SYK.npy  \n",
            "  inflating: data/davis/pconsc4/SgK110.npy  \n",
            "  inflating: data/davis/pconsc4/TAK1.npy  \n",
            "  inflating: data/davis/pconsc4/TAOK1.npy  \n",
            "  inflating: data/davis/pconsc4/TAOK2.npy  \n",
            "  inflating: data/davis/pconsc4/TAOK3.npy  \n",
            "  inflating: data/davis/pconsc4/TBK1.npy  \n",
            "  inflating: data/davis/pconsc4/TEC.npy  \n",
            "  inflating: data/davis/pconsc4/TESK1.npy  \n",
            "  inflating: data/davis/pconsc4/TGFBR1.npy  \n",
            "  inflating: data/davis/pconsc4/TGFBR2.npy  \n",
            "  inflating: data/davis/pconsc4/TIE1.npy  \n",
            "  inflating: data/davis/pconsc4/TIE2.npy  \n",
            "  inflating: data/davis/pconsc4/TLK1.npy  \n",
            "  inflating: data/davis/pconsc4/TLK2.npy  \n",
            "  inflating: data/davis/pconsc4/TNIK.npy  \n",
            "  inflating: data/davis/pconsc4/TNK1.npy  \n",
            "  inflating: data/davis/pconsc4/TNK2.npy  \n",
            "  inflating: data/davis/pconsc4/TNNI3K.npy  \n",
            "  inflating: data/davis/pconsc4/TRKA.npy  \n",
            "  inflating: data/davis/pconsc4/TRKB.npy  \n",
            "  inflating: data/davis/pconsc4/TRKC.npy  \n",
            "  inflating: data/davis/pconsc4/TRPM6.npy  \n",
            "  inflating: data/davis/pconsc4/TSSK1B.npy  \n",
            "  inflating: data/davis/pconsc4/TTK.npy  \n",
            "  inflating: data/davis/pconsc4/TXK.npy  \n",
            "  inflating: data/davis/pconsc4/TYK2(JH1domain-catalytic).npy  \n",
            "  inflating: data/davis/pconsc4/TYK2(JH2domain-pseudokinase).npy  \n",
            "  inflating: data/davis/pconsc4/TYRO3.npy  \n",
            "  inflating: data/davis/pconsc4/ULK1.npy  \n",
            "  inflating: data/davis/pconsc4/ULK2.npy  \n",
            "  inflating: data/davis/pconsc4/ULK3.npy  \n",
            "  inflating: data/davis/pconsc4/VEGFR2.npy  \n",
            "  inflating: data/davis/pconsc4/VRK2.npy  \n",
            "  inflating: data/davis/pconsc4/WEE1.npy  \n",
            "  inflating: data/davis/pconsc4/WEE2.npy  \n",
            "  inflating: data/davis/pconsc4/YANK1.npy  \n",
            "  inflating: data/davis/pconsc4/YANK2.npy  \n",
            "  inflating: data/davis/pconsc4/YANK3.npy  \n",
            "  inflating: data/davis/pconsc4/YES.npy  \n",
            "  inflating: data/davis/pconsc4/YSK1.npy  \n",
            "  inflating: data/davis/pconsc4/YSK4.npy  \n",
            "  inflating: data/davis/pconsc4/ZAK.npy  \n",
            "  inflating: data/davis/pconsc4/ZAP70.npy  \n",
            "  inflating: data/davis/pconsc4/p38-alpha.npy  \n",
            "  inflating: data/davis/pconsc4/p38-beta.npy  \n",
            "  inflating: data/davis/pconsc4/p38-delta.npy  \n",
            "  inflating: data/davis/pconsc4/p38-gamma.npy  \n",
            "   creating: data/kiba/\n",
            "   creating: data/kiba/aln/\n",
            "  inflating: data/kiba/aln/O00141.aln  \n",
            "  inflating: data/kiba/aln/O00311.aln  \n",
            "  inflating: data/kiba/aln/O00329.aln  \n",
            "  inflating: data/kiba/aln/O00418.aln  \n",
            "  inflating: data/kiba/aln/O00444.aln  \n",
            "  inflating: data/kiba/aln/O14757.aln  \n",
            "  inflating: data/kiba/aln/O14920.aln  \n",
            "  inflating: data/kiba/aln/O14965.aln  \n",
            "  inflating: data/kiba/aln/O15075.aln  \n",
            "  inflating: data/kiba/aln/O15111.aln  \n",
            "  inflating: data/kiba/aln/O15264.aln  \n",
            "  inflating: data/kiba/aln/O15530.aln  \n",
            "  inflating: data/kiba/aln/O43293.aln  \n",
            "  inflating: data/kiba/aln/O43741.aln  \n",
            "  inflating: data/kiba/aln/O43781.aln  \n",
            "  inflating: data/kiba/aln/O60285.aln  \n",
            "  inflating: data/kiba/aln/O60674.aln  \n",
            "  inflating: data/kiba/aln/O75116.aln  \n",
            "  inflating: data/kiba/aln/O75582.aln  \n",
            "  inflating: data/kiba/aln/O75676.aln  \n",
            "  inflating: data/kiba/aln/O94806.aln  \n",
            "  inflating: data/kiba/aln/O95819.aln  \n",
            "  inflating: data/kiba/aln/O96013.aln  \n",
            "  inflating: data/kiba/aln/O96017.aln  \n",
            "  inflating: data/kiba/aln/P00519.aln  \n",
            "  inflating: data/kiba/aln/P00533.aln  \n",
            "  inflating: data/kiba/aln/P04049.aln  \n",
            "  inflating: data/kiba/aln/P04626.aln  \n",
            "  inflating: data/kiba/aln/P04629.aln  \n",
            "  inflating: data/kiba/aln/P05129.aln  \n",
            "  inflating: data/kiba/aln/P05771.aln  \n",
            "  inflating: data/kiba/aln/P06213.aln  \n",
            "  inflating: data/kiba/aln/P06239.aln  \n",
            "  inflating: data/kiba/aln/P06241.aln  \n",
            "  inflating: data/kiba/aln/P06493.aln  \n",
            "  inflating: data/kiba/aln/P07332.aln  \n",
            "  inflating: data/kiba/aln/P07333.aln  \n",
            "  inflating: data/kiba/aln/P07947.aln  \n",
            "  inflating: data/kiba/aln/P07948.aln  \n",
            "  inflating: data/kiba/aln/P07949.aln  \n",
            "  inflating: data/kiba/aln/P08069.aln  \n",
            "  inflating: data/kiba/aln/P08581.aln  \n",
            "  inflating: data/kiba/aln/P08631.aln  \n",
            "  inflating: data/kiba/aln/P08922.aln  \n",
            "  inflating: data/kiba/aln/P09619.aln  \n",
            "  inflating: data/kiba/aln/P09769.aln  \n",
            "  inflating: data/kiba/aln/P10721.aln  \n",
            "  inflating: data/kiba/aln/P11309.aln  \n",
            "  inflating: data/kiba/aln/P11362.aln  \n",
            "  inflating: data/kiba/aln/P11802.aln  \n",
            "  inflating: data/kiba/aln/P12931.aln  \n",
            "  inflating: data/kiba/aln/P15056.aln  \n",
            "  inflating: data/kiba/aln/P15735.aln  \n",
            "  inflating: data/kiba/aln/P16234.aln  \n",
            "  inflating: data/kiba/aln/P16591.aln  \n",
            "  inflating: data/kiba/aln/P17252.aln  \n",
            "  inflating: data/kiba/aln/P17612.aln  \n",
            "  inflating: data/kiba/aln/P17948.aln  \n",
            "  inflating: data/kiba/aln/P19784.aln  \n",
            "  inflating: data/kiba/aln/P21802.aln  \n",
            "  inflating: data/kiba/aln/P22455.aln  \n",
            "  inflating: data/kiba/aln/P22607.aln  \n",
            "  inflating: data/kiba/aln/P22612.aln  \n",
            "  inflating: data/kiba/aln/P22694.aln  \n",
            "  inflating: data/kiba/aln/P23443.aln  \n",
            "  inflating: data/kiba/aln/P23458.aln  \n",
            "  inflating: data/kiba/aln/P24723.aln  \n",
            "  inflating: data/kiba/aln/P24941.aln  \n",
            "  inflating: data/kiba/aln/P27361.aln  \n",
            "  inflating: data/kiba/aln/P27448.aln  \n",
            "  inflating: data/kiba/aln/P28482.aln  \n",
            "  inflating: data/kiba/aln/P29317.aln  \n",
            "  inflating: data/kiba/aln/P29323.aln  \n",
            "  inflating: data/kiba/aln/P29376.aln  \n",
            "  inflating: data/kiba/aln/P29597.aln  \n",
            "  inflating: data/kiba/aln/P30291.aln  \n",
            "  inflating: data/kiba/aln/P30530.aln  \n",
            "  inflating: data/kiba/aln/P31749.aln  \n",
            "  inflating: data/kiba/aln/P31751.aln  \n",
            "  inflating: data/kiba/aln/P34947.aln  \n",
            "  inflating: data/kiba/aln/P35916.aln  \n",
            "  inflating: data/kiba/aln/P35968.aln  \n",
            "  inflating: data/kiba/aln/P36507.aln  \n",
            "  inflating: data/kiba/aln/P36888.aln  \n",
            "  inflating: data/kiba/aln/P41240.aln  \n",
            "  inflating: data/kiba/aln/P41279.aln  \n",
            "  inflating: data/kiba/aln/P41743.aln  \n",
            "  inflating: data/kiba/aln/P42336.aln  \n",
            "  inflating: data/kiba/aln/P42338.aln  \n",
            "  inflating: data/kiba/aln/P42345.aln  \n",
            "  inflating: data/kiba/aln/P42679.aln  \n",
            "  inflating: data/kiba/aln/P42684.aln  \n",
            "  inflating: data/kiba/aln/P42685.aln  \n",
            "  inflating: data/kiba/aln/P43403.aln  \n",
            "  inflating: data/kiba/aln/P43405.aln  \n",
            "  inflating: data/kiba/aln/P45983.aln  \n",
            "  inflating: data/kiba/aln/P45984.aln  \n",
            "  inflating: data/kiba/aln/P48729.aln  \n",
            "  inflating: data/kiba/aln/P48730.aln  \n",
            "  inflating: data/kiba/aln/P48736.aln  \n",
            "  inflating: data/kiba/aln/P49137.aln  \n",
            "  inflating: data/kiba/aln/P49336.aln  \n",
            "  inflating: data/kiba/aln/P49674.aln  \n",
            "  inflating: data/kiba/aln/P49759.aln  \n",
            "  inflating: data/kiba/aln/P49760.aln  \n",
            "  inflating: data/kiba/aln/P49840.aln  \n",
            "  inflating: data/kiba/aln/P49841.aln  \n",
            "  inflating: data/kiba/aln/P50613.aln  \n",
            "  inflating: data/kiba/aln/P50750.aln  \n",
            "  inflating: data/kiba/aln/P51451.aln  \n",
            "  inflating: data/kiba/aln/P51617.aln  \n",
            "  inflating: data/kiba/aln/P51812.aln  \n",
            "  inflating: data/kiba/aln/P51813.aln  \n",
            "  inflating: data/kiba/aln/P51817.aln  \n",
            "  inflating: data/kiba/aln/P51955.aln  \n",
            "  inflating: data/kiba/aln/P51957.aln  \n",
            "  inflating: data/kiba/aln/P52333.aln  \n",
            "  inflating: data/kiba/aln/P52564.aln  \n",
            "  inflating: data/kiba/aln/P53350.aln  \n",
            "  inflating: data/kiba/aln/P53667.aln  \n",
            "  inflating: data/kiba/aln/P53778.aln  \n",
            "  inflating: data/kiba/aln/P53779.aln  \n",
            "  inflating: data/kiba/aln/P54619.aln  \n",
            "  inflating: data/kiba/aln/P54646.aln  \n",
            "  inflating: data/kiba/aln/P54760.aln  \n",
            "  inflating: data/kiba/aln/P67870.aln  \n",
            "  inflating: data/kiba/aln/P68400.aln  \n",
            "  inflating: data/kiba/aln/P78368.aln  \n",
            "  inflating: data/kiba/aln/P78527.aln  \n",
            "  inflating: data/kiba/aln/P80192.aln  \n",
            "  inflating: data/kiba/aln/Q00534.aln  \n",
            "  inflating: data/kiba/aln/Q00535.aln  \n",
            "  inflating: data/kiba/aln/Q02156.aln  \n",
            "  inflating: data/kiba/aln/Q02750.aln  \n",
            "  inflating: data/kiba/aln/Q02763.aln  \n",
            "  inflating: data/kiba/aln/Q02779.aln  \n",
            "  inflating: data/kiba/aln/Q04759.aln  \n",
            "  inflating: data/kiba/aln/Q04771.aln  \n",
            "  inflating: data/kiba/aln/Q04912.aln  \n",
            "  inflating: data/kiba/aln/Q05397.aln  \n",
            "  inflating: data/kiba/aln/Q05513.aln  \n",
            "  inflating: data/kiba/aln/Q05655.aln  \n",
            "  inflating: data/kiba/aln/Q06187.aln  \n",
            "  inflating: data/kiba/aln/Q06418.aln  \n",
            "  inflating: data/kiba/aln/Q07912.aln  \n",
            "  inflating: data/kiba/aln/Q08881.aln  \n",
            "  inflating: data/kiba/aln/Q12851.aln  \n",
            "  inflating: data/kiba/aln/Q12866.aln  \n",
            "  inflating: data/kiba/aln/Q13131.aln  \n",
            "  inflating: data/kiba/aln/Q13153.aln  \n",
            "  inflating: data/kiba/aln/Q13177.aln  \n",
            "  inflating: data/kiba/aln/Q13188.aln  \n",
            "  inflating: data/kiba/aln/Q13237.aln  \n",
            "  inflating: data/kiba/aln/Q13464.aln  \n",
            "  inflating: data/kiba/aln/Q13554.aln  \n",
            "  inflating: data/kiba/aln/Q13555.aln  \n",
            "  inflating: data/kiba/aln/Q13557.aln  \n",
            "  inflating: data/kiba/aln/Q13627.aln  \n",
            "  inflating: data/kiba/aln/Q13882.aln  \n",
            "  inflating: data/kiba/aln/Q13976.aln  \n",
            "  inflating: data/kiba/aln/Q14012.aln  \n",
            "  inflating: data/kiba/aln/Q14164.aln  \n",
            "  inflating: data/kiba/aln/Q14289.aln  \n",
            "  inflating: data/kiba/aln/Q14680.aln  \n",
            "  inflating: data/kiba/aln/Q15078.aln  \n",
            "  inflating: data/kiba/aln/Q15118.aln  \n",
            "  inflating: data/kiba/aln/Q15139.aln  \n",
            "  inflating: data/kiba/aln/Q15303.aln  \n",
            "  inflating: data/kiba/aln/Q15418.aln  \n",
            "  inflating: data/kiba/aln/Q15759.aln  \n",
            "  inflating: data/kiba/aln/Q16288.aln  \n",
            "  inflating: data/kiba/aln/Q16512.aln  \n",
            "  inflating: data/kiba/aln/Q16513.aln  \n",
            "  inflating: data/kiba/aln/Q16539.aln  \n",
            "  inflating: data/kiba/aln/Q16566.aln  \n",
            "  inflating: data/kiba/aln/Q16584.aln  \n",
            "  inflating: data/kiba/aln/Q16620.aln  \n",
            "  inflating: data/kiba/aln/Q16644.aln  \n",
            "  inflating: data/kiba/aln/Q5S007.aln  \n",
            "  inflating: data/kiba/aln/Q5VT25.aln  \n",
            "  inflating: data/kiba/aln/Q7KZI7.aln  \n",
            "  inflating: data/kiba/aln/Q7L7X3.aln  \n",
            "  inflating: data/kiba/aln/Q86V86.aln  \n",
            "  inflating: data/kiba/aln/Q8IU85.aln  \n",
            "  inflating: data/kiba/aln/Q8IW41.aln  \n",
            "  inflating: data/kiba/aln/Q8N4C8.aln  \n",
            "  inflating: data/kiba/aln/Q8NE63.aln  \n",
            "  inflating: data/kiba/aln/Q8TDC3.aln  \n",
            "  inflating: data/kiba/aln/Q96GD4.aln  \n",
            "  inflating: data/kiba/aln/Q96KB5.aln  \n",
            "  inflating: data/kiba/aln/Q96L34.aln  \n",
            "  inflating: data/kiba/aln/Q96PF2.aln  \n",
            "  inflating: data/kiba/aln/Q96RG2.aln  \n",
            "  inflating: data/kiba/aln/Q96RR4.aln  \n",
            "  inflating: data/kiba/aln/Q96SB4.aln  \n",
            "  inflating: data/kiba/aln/Q99683.aln  \n",
            "  inflating: data/kiba/aln/Q9BUB5.aln  \n",
            "  inflating: data/kiba/aln/Q9BWU1.aln  \n",
            "  inflating: data/kiba/aln/Q9BXA7.aln  \n",
            "  inflating: data/kiba/aln/Q9BZL6.aln  \n",
            "  inflating: data/kiba/aln/Q9H0K1.aln  \n",
            "  inflating: data/kiba/aln/Q9H2G2.aln  \n",
            "  inflating: data/kiba/aln/Q9H2X6.aln  \n",
            "  inflating: data/kiba/aln/Q9H3Y6.aln  \n",
            "  inflating: data/kiba/aln/Q9H4B4.aln  \n",
            "  inflating: data/kiba/aln/Q9HAZ1.aln  \n",
            "  inflating: data/kiba/aln/Q9HBH9.aln  \n",
            "  inflating: data/kiba/aln/Q9HBY8.aln  \n",
            "  inflating: data/kiba/aln/Q9HC98.aln  \n",
            "  inflating: data/kiba/aln/Q9HCP0.aln  \n",
            "  inflating: data/kiba/aln/Q9NR20.aln  \n",
            "  inflating: data/kiba/aln/Q9NWZ3.aln  \n",
            "  inflating: data/kiba/aln/Q9NYL2.aln  \n",
            "  inflating: data/kiba/aln/Q9P1W9.aln  \n",
            "  inflating: data/kiba/aln/Q9P289.aln  \n",
            "  inflating: data/kiba/aln/Q9UBE8.aln  \n",
            "  inflating: data/kiba/aln/Q9UBF8.aln  \n",
            "  inflating: data/kiba/aln/Q9UBS0.aln  \n",
            "  inflating: data/kiba/aln/Q9UEE5.aln  \n",
            "  inflating: data/kiba/aln/Q9UGI9.aln  \n",
            "  inflating: data/kiba/aln/Q9UGJ0.aln  \n",
            "  inflating: data/kiba/aln/Q9UHD2.aln  \n",
            "  inflating: data/kiba/aln/Q9UM73.aln  \n",
            "  inflating: data/kiba/aln/Q9UQM7.aln  \n",
            "  inflating: data/kiba/aln/Q9Y243.aln  \n",
            "  inflating: data/kiba/aln/Q9Y463.aln  \n",
            "  inflating: data/kiba/aln/Q9Y478.aln  \n",
            "  inflating: data/kiba/aln/Q9Y4K4.aln  \n",
            "  inflating: data/kiba/aln/Q9Y6M4.aln  \n",
            "   creating: data/kiba/pconsc4/\n",
            "  inflating: data/kiba/pconsc4/O00141.npy  \n",
            "  inflating: data/kiba/pconsc4/O00311.npy  \n",
            "  inflating: data/kiba/pconsc4/O00329.npy  \n",
            "  inflating: data/kiba/pconsc4/O00418.npy  \n",
            "  inflating: data/kiba/pconsc4/O00444.npy  \n",
            "  inflating: data/kiba/pconsc4/O14757.npy  \n",
            "  inflating: data/kiba/pconsc4/O14920.npy  \n",
            "  inflating: data/kiba/pconsc4/O14965.npy  \n",
            "  inflating: data/kiba/pconsc4/O15075.npy  \n",
            "  inflating: data/kiba/pconsc4/O15111.npy  \n",
            "  inflating: data/kiba/pconsc4/O15264.npy  \n",
            "  inflating: data/kiba/pconsc4/O15530.npy  \n",
            "  inflating: data/kiba/pconsc4/O43293.npy  \n",
            "  inflating: data/kiba/pconsc4/O43741.npy  \n",
            "  inflating: data/kiba/pconsc4/O43781.npy  \n",
            "  inflating: data/kiba/pconsc4/O60285.npy  \n",
            "  inflating: data/kiba/pconsc4/O60674.npy  \n",
            "  inflating: data/kiba/pconsc4/O75116.npy  \n",
            "  inflating: data/kiba/pconsc4/O75582.npy  \n",
            "  inflating: data/kiba/pconsc4/O75676.npy  \n",
            "  inflating: data/kiba/pconsc4/O94806.npy  \n",
            "  inflating: data/kiba/pconsc4/O95819.npy  \n",
            "  inflating: data/kiba/pconsc4/O96013.npy  \n",
            "  inflating: data/kiba/pconsc4/O96017.npy  \n",
            "  inflating: data/kiba/pconsc4/P00519.npy  \n",
            "  inflating: data/kiba/pconsc4/P00533.npy  \n",
            "  inflating: data/kiba/pconsc4/P04049.npy  \n",
            "  inflating: data/kiba/pconsc4/P04626.npy  \n",
            "  inflating: data/kiba/pconsc4/P04629.npy  \n",
            "  inflating: data/kiba/pconsc4/P05129.npy  \n",
            "  inflating: data/kiba/pconsc4/P05771.npy  \n",
            "  inflating: data/kiba/pconsc4/P06213.npy  \n",
            "  inflating: data/kiba/pconsc4/P06239.npy  \n",
            "  inflating: data/kiba/pconsc4/P06241.npy  \n",
            "  inflating: data/kiba/pconsc4/P06493.npy  \n",
            "  inflating: data/kiba/pconsc4/P07332.npy  \n",
            "  inflating: data/kiba/pconsc4/P07333.npy  \n",
            "  inflating: data/kiba/pconsc4/P07947.npy  \n",
            "  inflating: data/kiba/pconsc4/P07948.npy  \n",
            "  inflating: data/kiba/pconsc4/P07949.npy  \n",
            "  inflating: data/kiba/pconsc4/P08069.npy  \n",
            "  inflating: data/kiba/pconsc4/P08581.npy  \n",
            "  inflating: data/kiba/pconsc4/P08631.npy  \n",
            "  inflating: data/kiba/pconsc4/P08922.npy  \n",
            "  inflating: data/kiba/pconsc4/P09619.npy  \n",
            "  inflating: data/kiba/pconsc4/P09769.npy  \n",
            "  inflating: data/kiba/pconsc4/P10721.npy  \n",
            "  inflating: data/kiba/pconsc4/P11309.npy  \n",
            "  inflating: data/kiba/pconsc4/P11362.npy  \n",
            "  inflating: data/kiba/pconsc4/P11802.npy  \n",
            "  inflating: data/kiba/pconsc4/P12931.npy  \n",
            "  inflating: data/kiba/pconsc4/P15056.npy  \n",
            "  inflating: data/kiba/pconsc4/P15735.npy  \n",
            "  inflating: data/kiba/pconsc4/P16234.npy  \n",
            "  inflating: data/kiba/pconsc4/P16591.npy  \n",
            "  inflating: data/kiba/pconsc4/P17252.npy  \n",
            "  inflating: data/kiba/pconsc4/P17612.npy  \n",
            "  inflating: data/kiba/pconsc4/P17948.npy  \n",
            "  inflating: data/kiba/pconsc4/P19784.npy  \n",
            "  inflating: data/kiba/pconsc4/P21802.npy  \n",
            "  inflating: data/kiba/pconsc4/P22455.npy  \n",
            "  inflating: data/kiba/pconsc4/P22607.npy  \n",
            "  inflating: data/kiba/pconsc4/P22612.npy  \n",
            "  inflating: data/kiba/pconsc4/P22694.npy  \n",
            "  inflating: data/kiba/pconsc4/P23443.npy  \n",
            "  inflating: data/kiba/pconsc4/P23458.npy  \n",
            "  inflating: data/kiba/pconsc4/P24723.npy  \n",
            "  inflating: data/kiba/pconsc4/P24941.npy  \n",
            "  inflating: data/kiba/pconsc4/P27361.npy  \n",
            "  inflating: data/kiba/pconsc4/P27448.npy  \n",
            "  inflating: data/kiba/pconsc4/P28482.npy  \n",
            "  inflating: data/kiba/pconsc4/P29317.npy  \n",
            "  inflating: data/kiba/pconsc4/P29323.npy  \n",
            "  inflating: data/kiba/pconsc4/P29376.npy  \n",
            "  inflating: data/kiba/pconsc4/P29597.npy  \n",
            "  inflating: data/kiba/pconsc4/P30291.npy  \n",
            "  inflating: data/kiba/pconsc4/P30530.npy  \n",
            "  inflating: data/kiba/pconsc4/P31749.npy  \n",
            "  inflating: data/kiba/pconsc4/P31751.npy  \n",
            "  inflating: data/kiba/pconsc4/P34947.npy  \n",
            "  inflating: data/kiba/pconsc4/P35916.npy  \n",
            "  inflating: data/kiba/pconsc4/P35968.npy  \n",
            "  inflating: data/kiba/pconsc4/P36507.npy  \n",
            "  inflating: data/kiba/pconsc4/P36888.npy  \n",
            "  inflating: data/kiba/pconsc4/P41240.npy  \n",
            "  inflating: data/kiba/pconsc4/P41279.npy  \n",
            "  inflating: data/kiba/pconsc4/P41743.npy  \n",
            "  inflating: data/kiba/pconsc4/P42336.npy  \n",
            "  inflating: data/kiba/pconsc4/P42338.npy  \n",
            "  inflating: data/kiba/pconsc4/P42345.npy  \n",
            "  inflating: data/kiba/pconsc4/P42679.npy  \n",
            "  inflating: data/kiba/pconsc4/P42684.npy  \n",
            "  inflating: data/kiba/pconsc4/P42685.npy  \n",
            "  inflating: data/kiba/pconsc4/P43403.npy  \n",
            "  inflating: data/kiba/pconsc4/P43405.npy  \n",
            "  inflating: data/kiba/pconsc4/P45983.npy  \n",
            "  inflating: data/kiba/pconsc4/P45984.npy  \n",
            "  inflating: data/kiba/pconsc4/P48729.npy  \n",
            "  inflating: data/kiba/pconsc4/P48730.npy  \n",
            "  inflating: data/kiba/pconsc4/P48736.npy  \n",
            "  inflating: data/kiba/pconsc4/P49137.npy  \n",
            "  inflating: data/kiba/pconsc4/P49336.npy  \n",
            "  inflating: data/kiba/pconsc4/P49674.npy  \n",
            "  inflating: data/kiba/pconsc4/P49759.npy  \n",
            "  inflating: data/kiba/pconsc4/P49760.npy  \n",
            "  inflating: data/kiba/pconsc4/P49840.npy  \n",
            "  inflating: data/kiba/pconsc4/P49841.npy  \n",
            "  inflating: data/kiba/pconsc4/P50613.npy  \n",
            "  inflating: data/kiba/pconsc4/P50750.npy  \n",
            "  inflating: data/kiba/pconsc4/P51451.npy  \n",
            "  inflating: data/kiba/pconsc4/P51617.npy  \n",
            "  inflating: data/kiba/pconsc4/P51812.npy  \n",
            "  inflating: data/kiba/pconsc4/P51813.npy  \n",
            "  inflating: data/kiba/pconsc4/P51817.npy  \n",
            "  inflating: data/kiba/pconsc4/P51955.npy  \n",
            "  inflating: data/kiba/pconsc4/P51957.npy  \n",
            "  inflating: data/kiba/pconsc4/P52333.npy  \n",
            "  inflating: data/kiba/pconsc4/P52564.npy  \n",
            "  inflating: data/kiba/pconsc4/P53350.npy  \n",
            "  inflating: data/kiba/pconsc4/P53667.npy  \n",
            "  inflating: data/kiba/pconsc4/P53778.npy  \n",
            "  inflating: data/kiba/pconsc4/P53779.npy  \n",
            "  inflating: data/kiba/pconsc4/P54619.npy  \n",
            "  inflating: data/kiba/pconsc4/P54646.npy  \n",
            "  inflating: data/kiba/pconsc4/P54760.npy  \n",
            "  inflating: data/kiba/pconsc4/P67870.npy  \n",
            "  inflating: data/kiba/pconsc4/P68400.npy  \n",
            "  inflating: data/kiba/pconsc4/P78368.npy  \n",
            "  inflating: data/kiba/pconsc4/P80192.npy  \n",
            "  inflating: data/kiba/pconsc4/Q00534.npy  \n",
            "  inflating: data/kiba/pconsc4/Q00535.npy  \n",
            "  inflating: data/kiba/pconsc4/Q02156.npy  \n",
            "  inflating: data/kiba/pconsc4/Q02750.npy  \n",
            "  inflating: data/kiba/pconsc4/Q02763.npy  \n",
            "  inflating: data/kiba/pconsc4/Q02779.npy  \n",
            "  inflating: data/kiba/pconsc4/Q04759.npy  \n",
            "  inflating: data/kiba/pconsc4/Q04771.npy  \n",
            "  inflating: data/kiba/pconsc4/Q04912.npy  \n",
            "  inflating: data/kiba/pconsc4/Q05397.npy  \n",
            "  inflating: data/kiba/pconsc4/Q05513.npy  \n",
            "  inflating: data/kiba/pconsc4/Q05655.npy  \n",
            "  inflating: data/kiba/pconsc4/Q06187.npy  \n",
            "  inflating: data/kiba/pconsc4/Q06418.npy  \n",
            "  inflating: data/kiba/pconsc4/Q07912.npy  \n",
            "  inflating: data/kiba/pconsc4/Q08881.npy  \n",
            "  inflating: data/kiba/pconsc4/Q12851.npy  \n",
            "  inflating: data/kiba/pconsc4/Q12866.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13131.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13153.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13177.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13188.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13237.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13464.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13554.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13555.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13557.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13627.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13882.npy  \n",
            "  inflating: data/kiba/pconsc4/Q13976.npy  \n",
            "  inflating: data/kiba/pconsc4/Q14012.npy  \n",
            "  inflating: data/kiba/pconsc4/Q14164.npy  \n",
            "  inflating: data/kiba/pconsc4/Q14289.npy  \n",
            "  inflating: data/kiba/pconsc4/Q14680.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15078.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15118.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15139.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15303.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15418.npy  \n",
            "  inflating: data/kiba/pconsc4/Q15759.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16288.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16512.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16513.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16539.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16566.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16584.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16620.npy  \n",
            "  inflating: data/kiba/pconsc4/Q16644.npy  \n",
            "  inflating: data/kiba/pconsc4/Q5S007.npy  \n",
            "  inflating: data/kiba/pconsc4/Q5VT25.npy  \n",
            "  inflating: data/kiba/pconsc4/Q7KZI7.npy  \n",
            "  inflating: data/kiba/pconsc4/Q7L7X3.npy  \n",
            "  inflating: data/kiba/pconsc4/Q86V86.npy  \n",
            "  inflating: data/kiba/pconsc4/Q8IU85.npy  \n",
            "  inflating: data/kiba/pconsc4/Q8IW41.npy  \n",
            "  inflating: data/kiba/pconsc4/Q8N4C8.npy  \n",
            "  inflating: data/kiba/pconsc4/Q8NE63.npy  \n",
            "  inflating: data/kiba/pconsc4/Q8TDC3.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96GD4.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96KB5.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96L34.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96PF2.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96RG2.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96RR4.npy  \n",
            "  inflating: data/kiba/pconsc4/Q96SB4.npy  \n",
            "  inflating: data/kiba/pconsc4/Q99683.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9BUB5.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9BWU1.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9BXA7.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9BZL6.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9H0K1.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9H2G2.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9H2X6.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9H3Y6.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9H4B4.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9HAZ1.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9HBH9.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9HBY8.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9HC98.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9HCP0.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9NR20.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9NWZ3.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9NYL2.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9P1W9.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9P289.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UBE8.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UBF8.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UBS0.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UEE5.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UGI9.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UGJ0.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UHD2.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UM73.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9UQM7.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9Y243.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9Y463.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9Y478.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9Y4K4.npy  \n",
            "  inflating: data/kiba/pconsc4/Q9Y6M4.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYTVP7Q7gWVr",
        "colab_type": "text"
      },
      "source": [
        "## PIP Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtPplcLeYW0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "dad4a7a4-70e1-4234-a325-e34d7c37ef00"
      },
      "source": [
        "# !pip3 install numpy Cython pythran && pip3 install pconsc4\n",
        "!pip install torch-geometric torch-scatter==latest+cu101 torch-sparse==latest+cu101 --no-cache-dir -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/f2/26359fb7b50d54924ddd23778d4830b2653df9ffe72f85caad2b829dc778/torch_geometric-1.5.0.tar.gz (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 3.4MB/s \n",
            "\u001b[?25hCollecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3MB 1.4MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.6MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/70/a8b1a7831193aa228defd805891c534d3e4717c8988147522e673458ddce/ase-3.19.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.15.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (47.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.5.0-cp36-none-any.whl size=267918 sha256=84d13fdda9e776c529f2354e1ecb5051f24abaaf6152984a0428c40f5a042e49\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-94pt05hy/wheels/ec/51/31/5786f2ac419ee312f22d4d2877da05f20e7f2d430e22917daf\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, ase, torch-geometric, torch-scatter, torch-sparse\n",
            "Successfully installed ase-3.19.1 isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-geometric-1.5.0 torch-scatter-2.0.5 torch-sparse-0.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQOUmC2gbDw7",
        "colab_type": "text"
      },
      "source": [
        "## RDKIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFvjtWTaOsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07721e7b-8d93-40af-e286-486d16a7d298"
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "\n",
        "# !time conda install -c conda-forge -c bioconda hhsuite \n",
        "## !time conda install -q -y -c conda-forge bioconda hhsuite \n",
        "## !conda list -p /usr/local/lib/python3.7\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-05 18:35:41--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-07-05 18:35:41--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88867207 (85M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  36%[======>             ]  30.86M   154MB/s               \r        Miniconda3-  90%[=================>  ]  76.88M   192MB/s               \rMiniconda3-latest-L 100%[===================>]  84.75M   195MB/s    in 0.4s    \n",
            "\n",
            "2020-07-05 18:35:42 (195 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [88867207/88867207]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2020.4.5.1=py37_0\n",
            "    - cffi==1.14.0=py37he30daa8_1\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "    - conda==4.8.3=py37_0\n",
            "    - cryptography==2.9.2=py37h1ba5d50_0\n",
            "    - idna==2.9=py_1\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.3=he6710b0_1\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1g=h7b6447c_0\n",
            "    - pip==20.0.2=py37_3\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.20=py_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.7=hcff3b4d_5\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.23.0=py37_0\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==46.4.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h62c20be_1\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.46.0=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.3-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
            "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_3\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  requests           pkgs/main/linux-64::requests-2.23.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m35.190s\n",
            "user\t0m14.045s\n",
            "sys\t0m5.270s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h7b93d67_1        21.8 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n",
            "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h1056068_1002         365 KB  conda-forge\n",
            "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
            "    glib-2.65.0                |       h3eb4bd4_0         2.9 MB\n",
            "    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n",
            "    jpeg-9d                    |       h516909a_0         266 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |       hdf63c60_6         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       h72b56ed_1         1.3 MB  conda-forge\n",
            "    lz4-c-1.9.2                |       he1b5a44_1         226 KB  conda-forge\n",
            "    numpy-1.18.5               |   py37h8960a57_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.5               |   py37h0da4684_0        10.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.4            |   py37hdd87690_0        24.6 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h6597ccf_3         991 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       105.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h7b93d67_1\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h1056068_1002\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
            "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0\n",
            "  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_6\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_6\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h72b56ed_1\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_1\n",
            "  numpy              conda-forge/linux-64::numpy-1.18.5-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.5-py37h0da4684_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.4-py37hdd87690_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h6597ccf_3\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
            "  certifi              pkgs/main::certifi-2020.4.5.1-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m43.793s\n",
            "user\t0m36.760s\n",
            "sys\t0m4.961s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBXlZYyscB70",
        "colab_type": "text"
      },
      "source": [
        "## Cloning Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcehvcAjZb4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "522920a3-0964-4d17-a782-26903320f5b9"
      },
      "source": [
        "!git clone https://github.com/595693085/DGraphDTA.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DGraphDTA'...\n",
            "remote: Enumerating objects: 372, done.\u001b[K\n",
            "remote: Counting objects: 100% (372/372), done.\u001b[K\n",
            "remote: Compressing objects: 100% (341/341), done.\u001b[K\n",
            "remote: Total 372 (delta 105), reused 245 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (372/372), 50.23 MiB | 18.32 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcEOzDr5eRxG",
        "colab_type": "text"
      },
      "source": [
        "# evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RS1Etn_eSZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import subprocess\n",
        "from math import sqrt\n",
        "from sklearn.metrics import average_precision_score\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "def get_aupr(Y, P, threshold=7.0):\n",
        "    # print(Y.shape,P.shape)\n",
        "    Y = np.where(Y >= 7.0, 1, 0)\n",
        "    P = np.where(P >= 7.0, 1, 0)\n",
        "    aupr = average_precision_score(Y, P)\n",
        "    return aupr\n",
        "\n",
        "\n",
        "def get_cindex(Y, P):\n",
        "    summ = 0\n",
        "    pair = 0\n",
        "\n",
        "    for i in range(1, len(Y)):\n",
        "        for j in range(0, i):\n",
        "            if i is not j:\n",
        "                if (Y[i] > Y[j]):\n",
        "                    pair += 1\n",
        "                    summ += 1 * (P[i] > P[j]) + 0.5 * (P[i] == P[j])\n",
        "\n",
        "    if pair is not 0:\n",
        "        return summ / pair\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def r_squared_error(y_obs, y_pred):\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
        "    y_pred_mean = [np.mean(y_pred) for y in y_pred]\n",
        "\n",
        "    mult = sum((y_pred - y_pred_mean) * (y_obs - y_obs_mean))\n",
        "    mult = mult * mult\n",
        "\n",
        "    y_obs_sq = sum((y_obs - y_obs_mean) * (y_obs - y_obs_mean))\n",
        "    y_pred_sq = sum((y_pred - y_pred_mean) * (y_pred - y_pred_mean))\n",
        "\n",
        "    return mult / float(y_obs_sq * y_pred_sq)\n",
        "\n",
        "\n",
        "def get_k(y_obs, y_pred):\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    return sum(y_obs * y_pred) / float(sum(y_pred * y_pred))\n",
        "\n",
        "\n",
        "def squared_error_zero(y_obs, y_pred):\n",
        "    k = get_k(y_obs, y_pred)\n",
        "\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
        "    upp = sum((y_obs - (k * y_pred)) * (y_obs - (k * y_pred)))\n",
        "    down = sum((y_obs - y_obs_mean) * (y_obs - y_obs_mean))\n",
        "\n",
        "    return 1 - (upp / float(down))\n",
        "\n",
        "\n",
        "def get_rm2(ys_orig, ys_line):\n",
        "    r2 = r_squared_error(ys_orig, ys_line)\n",
        "    r02 = squared_error_zero(ys_orig, ys_line)\n",
        "\n",
        "    return r2 * (1 - np.sqrt(np.absolute((r2 * r2) - (r02 * r02))))\n",
        "\n",
        "\n",
        "def get_rmse(y, f):\n",
        "    rmse = sqrt(((y - f) ** 2).mean(axis=0))\n",
        "    return rmse\n",
        "\n",
        "\n",
        "def get_mse(y, f):\n",
        "    mse = ((y - f) ** 2).mean(axis=0)\n",
        "    return mse\n",
        "\n",
        "\n",
        "def get_pearson(y, f):\n",
        "    rp = np.corrcoef(y, f)[0, 1]\n",
        "    return rp\n",
        "\n",
        "\n",
        "def get_spearman(y, f):\n",
        "    rs = stats.spearmanr(y, f)[0]\n",
        "    return rs\n",
        "\n",
        "\n",
        "def get_ci(y, f):\n",
        "    ind = np.argsort(y)\n",
        "    y = y[ind]\n",
        "    f = f[ind]\n",
        "    i = len(y) - 1\n",
        "    j = i - 1\n",
        "    z = 0.0\n",
        "    S = 0.0\n",
        "    while i > 0:\n",
        "        while j >= 0:\n",
        "            if y[i] > y[j]:\n",
        "                z = z + 1\n",
        "                u = f[i] - f[j]\n",
        "                if u > 0:\n",
        "                    S = S + 1\n",
        "                elif u == 0:\n",
        "                    S = S + 0.5\n",
        "            j = j - 1\n",
        "        i = i - 1\n",
        "        j = i - 1\n",
        "    ci = S / z\n",
        "    return ci\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AeReChf384",
        "colab_type": "text"
      },
      "source": [
        "# utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Er96ceCfbK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, DataLoader, Batch\n",
        "from torch_geometric import data as DATA\n",
        "import torch\n",
        "\n",
        "\n",
        "# initialize the dataset\n",
        "class DTADataset(InMemoryDataset):\n",
        "    def __init__(self, root='/tmp', dataset='davis',\n",
        "                 xd=None, y=None, transform=None,\n",
        "                 pre_transform=None, smile_graph=None, target_key=None, target_graph=None):\n",
        "\n",
        "        super(DTADataset, self).__init__(root, transform, pre_transform)\n",
        "        self.dataset = dataset\n",
        "        self.process(xd, target_key, y, smile_graph, target_graph)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        pass\n",
        "        # return ['some_file_1', 'some_file_2', ...]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.dataset + '_data_mol.pt', self.dataset + '_data_pro.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def _download(self):\n",
        "        pass\n",
        "\n",
        "    def _process(self):\n",
        "        if not os.path.exists(self.processed_dir):\n",
        "            os.makedirs(self.processed_dir)\n",
        "\n",
        "    def process(self, xd, target_key, y, smile_graph, target_graph):\n",
        "        assert (len(xd) == len(target_key) and len(xd) == len(y)), 'The three lists must be the same length!'\n",
        "        data_list_mol = []\n",
        "        data_list_pro = []\n",
        "        data_len = len(xd)\n",
        "        for i in range(data_len):\n",
        "            smiles = xd[i]\n",
        "            tar_key = target_key[i]\n",
        "            labels = y[i]\n",
        "            # convert SMILES to molecular representation using rdkit\n",
        "            c_size, features, edge_index = smile_graph[smiles]\n",
        "            target_size, target_features, target_edge_index = target_graph[tar_key]\n",
        "            # print(np.array(features).shape, np.array(edge_index).shape)\n",
        "            # print(target_features.shape, target_edge_index.shape)\n",
        "            # make the graph ready for PyTorch Geometrics GCN algorithms:\n",
        "            GCNData_mol = DATA.Data(x=torch.Tensor(features),\n",
        "                                    edge_index=torch.LongTensor(edge_index).transpose(1, 0),\n",
        "                                    y=torch.FloatTensor([labels]))\n",
        "            GCNData_mol.__setitem__('c_size', torch.LongTensor([c_size]))\n",
        "\n",
        "            GCNData_pro = DATA.Data(x=torch.Tensor(target_features),\n",
        "                                    edge_index=torch.LongTensor(target_edge_index).transpose(1, 0),\n",
        "                                    y=torch.FloatTensor([labels]))\n",
        "            GCNData_pro.__setitem__('target_size', torch.LongTensor([target_size]))\n",
        "            # print(GCNData.target.size(), GCNData.target_edge_index.size(), GCNData.target_x.size())\n",
        "            data_list_mol.append(GCNData_mol)\n",
        "            data_list_pro.append(GCNData_pro)\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list_mol = [data for data in data_list_mol if self.pre_filter(data)]\n",
        "            data_list_pro = [data for data in data_list_pro if self.pre_filter(data)]\n",
        "        if self.pre_transform is not None:\n",
        "            data_list_mol = [self.pre_transform(data) for data in data_list_mol]\n",
        "            data_list_pro = [self.pre_transform(data) for data in data_list_pro]\n",
        "        self.data_mol = data_list_mol\n",
        "        self.data_pro = data_list_pro\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_mol)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_mol[idx], self.data_pro[idx]\n",
        "\n",
        "\n",
        "# training function at each epoch\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
        "    model.train()\n",
        "    LOG_INTERVAL = 10\n",
        "    TRAIN_BATCH_SIZE = 512\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data_mol = data[0].to(device)\n",
        "        data_pro = data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data_mol, data_pro)\n",
        "        loss = loss_fn(output, data_mol.y.view(-1, 1).float().to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
        "                                                                           batch_idx * TRAIN_BATCH_SIZE,\n",
        "                                                                           len(train_loader.dataset),\n",
        "                                                                           100. * batch_idx / len(train_loader),\n",
        "                                                                           loss.item()))\n",
        "\n",
        "# predict\n",
        "def predicting(model, device, loader):\n",
        "    model.eval()\n",
        "    total_preds = torch.Tensor()\n",
        "    total_labels = torch.Tensor()\n",
        "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data_mol = data[0].to(device)\n",
        "            data_pro = data[1].to(device)\n",
        "            output = model(data_mol, data_pro)\n",
        "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
        "            total_labels = torch.cat((total_labels, data_mol.y.view(-1, 1).cpu()), 0)\n",
        "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()\n",
        "\n",
        "\n",
        "#prepare the protein and drug pairs\n",
        "def collate(data_list):\n",
        "    batchA = Batch.from_data_list([data[0] for data in data_list])\n",
        "    batchB = Batch.from_data_list([data[1] for data in data_list])\n",
        "    return batchA, batchB\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vnj2ZWyueViR"
      },
      "source": [
        "# gnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OcLBaFy4z3Z",
        "colab_type": "text"
      },
      "source": [
        "# pre process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2LDQUo4Sib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import json, pickle\n",
        "from collections import OrderedDict\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MolFromSmiles\n",
        "import networkx as nx\n",
        "\n",
        "# from utils import *\n",
        "\n",
        "\n",
        "# nomarlize\n",
        "def dic_normalize(dic):\n",
        "    # print(dic)\n",
        "    max_value = dic[max(dic, key=dic.get)]\n",
        "    min_value = dic[min(dic, key=dic.get)]\n",
        "    # print(max_value)\n",
        "    interval = float(max_value) - float(min_value)\n",
        "    for key in dic.keys():\n",
        "        dic[key] = (dic[key] - min_value) / interval\n",
        "    dic['X'] = (max_value + min_value) / 2.0\n",
        "    return dic\n",
        "\n",
        "\n",
        "pro_res_table = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',\n",
        "                 'X']\n",
        "\n",
        "pro_res_aliphatic_table = ['A', 'I', 'L', 'M', 'V']\n",
        "pro_res_aromatic_table = ['F', 'W', 'Y']\n",
        "pro_res_polar_neutral_table = ['C', 'N', 'Q', 'S', 'T']\n",
        "pro_res_acidic_charged_table = ['D', 'E']\n",
        "pro_res_basic_charged_table = ['H', 'K', 'R']\n",
        "\n",
        "res_weight_table = {'A': 71.08, 'C': 103.15, 'D': 115.09, 'E': 129.12, 'F': 147.18, 'G': 57.05, 'H': 137.14,\n",
        "                    'I': 113.16, 'K': 128.18, 'L': 113.16, 'M': 131.20, 'N': 114.11, 'P': 97.12, 'Q': 128.13,\n",
        "                    'R': 156.19, 'S': 87.08, 'T': 101.11, 'V': 99.13, 'W': 186.22, 'Y': 163.18}\n",
        "\n",
        "res_pka_table = {'A': 2.34, 'C': 1.96, 'D': 1.88, 'E': 2.19, 'F': 1.83, 'G': 2.34, 'H': 1.82, 'I': 2.36,\n",
        "                 'K': 2.18, 'L': 2.36, 'M': 2.28, 'N': 2.02, 'P': 1.99, 'Q': 2.17, 'R': 2.17, 'S': 2.21,\n",
        "                 'T': 2.09, 'V': 2.32, 'W': 2.83, 'Y': 2.32}\n",
        "\n",
        "res_pkb_table = {'A': 9.69, 'C': 10.28, 'D': 9.60, 'E': 9.67, 'F': 9.13, 'G': 9.60, 'H': 9.17,\n",
        "                 'I': 9.60, 'K': 8.95, 'L': 9.60, 'M': 9.21, 'N': 8.80, 'P': 10.60, 'Q': 9.13,\n",
        "                 'R': 9.04, 'S': 9.15, 'T': 9.10, 'V': 9.62, 'W': 9.39, 'Y': 9.62}\n",
        "\n",
        "res_pkx_table = {'A': 0.00, 'C': 8.18, 'D': 3.65, 'E': 4.25, 'F': 0.00, 'G': 0, 'H': 6.00,\n",
        "                 'I': 0.00, 'K': 10.53, 'L': 0.00, 'M': 0.00, 'N': 0.00, 'P': 0.00, 'Q': 0.00,\n",
        "                 'R': 12.48, 'S': 0.00, 'T': 0.00, 'V': 0.00, 'W': 0.00, 'Y': 0.00}\n",
        "\n",
        "res_pl_table = {'A': 6.00, 'C': 5.07, 'D': 2.77, 'E': 3.22, 'F': 5.48, 'G': 5.97, 'H': 7.59,\n",
        "                'I': 6.02, 'K': 9.74, 'L': 5.98, 'M': 5.74, 'N': 5.41, 'P': 6.30, 'Q': 5.65,\n",
        "                'R': 10.76, 'S': 5.68, 'T': 5.60, 'V': 5.96, 'W': 5.89, 'Y': 5.96}\n",
        "\n",
        "res_hydrophobic_ph2_table = {'A': 47, 'C': 52, 'D': -18, 'E': 8, 'F': 92, 'G': 0, 'H': -42, 'I': 100,\n",
        "                             'K': -37, 'L': 100, 'M': 74, 'N': -41, 'P': -46, 'Q': -18, 'R': -26, 'S': -7,\n",
        "                             'T': 13, 'V': 79, 'W': 84, 'Y': 49}\n",
        "\n",
        "res_hydrophobic_ph7_table = {'A': 41, 'C': 49, 'D': -55, 'E': -31, 'F': 100, 'G': 0, 'H': 8, 'I': 99,\n",
        "                             'K': -23, 'L': 97, 'M': 74, 'N': -28, 'P': -46, 'Q': -10, 'R': -14, 'S': -5,\n",
        "                             'T': 13, 'V': 76, 'W': 97, 'Y': 63}\n",
        "\n",
        "res_weight_table = dic_normalize(res_weight_table)\n",
        "res_pka_table = dic_normalize(res_pka_table)\n",
        "res_pkb_table = dic_normalize(res_pkb_table)\n",
        "res_pkx_table = dic_normalize(res_pkx_table)\n",
        "res_pl_table = dic_normalize(res_pl_table)\n",
        "res_hydrophobic_ph2_table = dic_normalize(res_hydrophobic_ph2_table)\n",
        "res_hydrophobic_ph7_table = dic_normalize(res_hydrophobic_ph7_table)\n",
        "\n",
        "\n",
        "# print(res_weight_table)\n",
        "\n",
        "\n",
        "def residue_features(residue):\n",
        "    res_property1 = [1 if residue in pro_res_aliphatic_table else 0, 1 if residue in pro_res_aromatic_table else 0,\n",
        "                     1 if residue in pro_res_polar_neutral_table else 0,\n",
        "                     1 if residue in pro_res_acidic_charged_table else 0,\n",
        "                     1 if residue in pro_res_basic_charged_table else 0]\n",
        "    res_property2 = [res_weight_table[residue], res_pka_table[residue], res_pkb_table[residue], res_pkx_table[residue],\n",
        "                     res_pl_table[residue], res_hydrophobic_ph2_table[residue], res_hydrophobic_ph7_table[residue]]\n",
        "    # print(np.array(res_property1 + res_property2).shape)\n",
        "    return np.array(res_property1 + res_property2)\n",
        "\n",
        "\n",
        "# mol atom feature for mol graph\n",
        "def atom_features(atom):\n",
        "    # 44 +11 +11 +11 +1\n",
        "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
        "                                          ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca', 'Fe', 'As',\n",
        "                                           'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se',\n",
        "                                           'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n",
        "                                           'Pt', 'Hg', 'Pb', 'X']) +\n",
        "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    [atom.GetIsAromatic()])\n",
        "\n",
        "\n",
        "# one ont encoding\n",
        "def one_of_k_encoding(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        # print(x)\n",
        "        raise Exception('input {0} not in allowable set{1}:'.format(x, allowable_set))\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "    '''Maps inputs not in the allowable set to the last element.'''\n",
        "    if x not in allowable_set:\n",
        "        x = allowable_set[-1]\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "# mol smile to mol graph edge index\n",
        "def smile_to_graph(smile):\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "\n",
        "    c_size = mol.GetNumAtoms()\n",
        "\n",
        "    features = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        feature = atom_features(atom)\n",
        "        features.append(feature / sum(feature))\n",
        "\n",
        "    edges = []\n",
        "    for bond in mol.GetBonds():\n",
        "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
        "    g = nx.Graph(edges).to_directed()\n",
        "    edge_index = []\n",
        "    mol_adj = np.zeros((c_size, c_size))\n",
        "    for e1, e2 in g.edges:\n",
        "        mol_adj[e1, e2] = 1\n",
        "        # edge_index.append([e1, e2])\n",
        "    mol_adj += np.matrix(np.eye(mol_adj.shape[0]))\n",
        "    index_row, index_col = np.where(mol_adj >= 0.5)\n",
        "    for i, j in zip(index_row, index_col):\n",
        "        edge_index.append([i, j])\n",
        "    # print('smile_to_graph')\n",
        "    # print(np.array(features).shape)\n",
        "    return c_size, features, edge_index\n",
        "\n",
        "\n",
        "# target feature for target graph\n",
        "def PSSM_calculation(aln_file, pro_seq):\n",
        "    pfm_mat = np.zeros((len(pro_res_table), len(pro_seq)))\n",
        "    with open(aln_file, 'r') as f:\n",
        "        line_count = len(f.readlines())\n",
        "        for line in f.readlines():\n",
        "            if len(line) != len(pro_seq):\n",
        "                print('error', len(line), len(pro_seq))\n",
        "                continue\n",
        "            count = 0\n",
        "            for res in line:\n",
        "                if res not in pro_res_table:\n",
        "                    count += 1\n",
        "                    continue\n",
        "                pfm_mat[pro_res_table.index(res), count] += 1\n",
        "                count += 1\n",
        "    # ppm_mat = pfm_mat / float(line_count)\n",
        "    pseudocount = 0.8\n",
        "    ppm_mat = (pfm_mat + pseudocount / 4) / (float(line_count) + pseudocount)\n",
        "    pssm_mat = ppm_mat\n",
        "    # k = float(len(pro_res_table))\n",
        "    # pwm_mat = np.log2(ppm_mat / (1.0 / k))\n",
        "    # pssm_mat = pwm_mat\n",
        "    # print(pssm_mat)\n",
        "    return pssm_mat\n",
        "\n",
        "\n",
        "def seq_feature(pro_seq):\n",
        "    pro_hot = np.zeros((len(pro_seq), len(pro_res_table)))\n",
        "    pro_property = np.zeros((len(pro_seq), 12))\n",
        "    for i in range(len(pro_seq)):\n",
        "        # if 'X' in pro_seq:\n",
        "        #     print(pro_seq)\n",
        "        pro_hot[i,] = one_of_k_encoding(pro_seq[i], pro_res_table)\n",
        "        pro_property[i,] = residue_features(pro_seq[i])\n",
        "    return np.concatenate((pro_hot, pro_property), axis=1)\n",
        "\n",
        "\n",
        "def target_feature(aln_file, pro_seq):\n",
        "    pssm = PSSM_calculation(aln_file, pro_seq)\n",
        "    other_feature = seq_feature(pro_seq)\n",
        "    # print('target_feature')\n",
        "    # print(pssm.shape)\n",
        "    # print(other_feature.shape)\n",
        "\n",
        "    # print(other_feature.shape)\n",
        "    # return other_feature\n",
        "    return np.concatenate((np.transpose(pssm, (1, 0)), other_feature), axis=1)\n",
        "\n",
        "\n",
        "# target aln file save in data/dataset/aln\n",
        "def target_to_feature(target_key, target_sequence, aln_dir):\n",
        "    # aln_dir = 'data/' + dataset + '/aln'\n",
        "    aln_file = os.path.join(aln_dir, target_key + '.aln')\n",
        "    # if 'X' in target_sequence:\n",
        "    #     print(target_key)\n",
        "    feature = target_feature(aln_file, target_sequence)\n",
        "    return feature\n",
        "\n",
        "\n",
        "# pconsc4 predicted contact map save in data/dataset/pconsc4\n",
        "def target_to_graph(target_key, target_sequence, contact_dir, aln_dir):\n",
        "    target_edge_index = []\n",
        "    target_size = len(target_sequence)\n",
        "    # contact_dir = 'data/' + dataset + '/pconsc4'\n",
        "    contact_file = os.path.join(contact_dir, target_key + '.npy')\n",
        "    contact_map = np.load(contact_file)\n",
        "    contact_map += np.matrix(np.eye(contact_map.shape[0]))\n",
        "    index_row, index_col = np.where(contact_map >= 0.5)\n",
        "    for i, j in zip(index_row, index_col):\n",
        "        target_edge_index.append([i, j])\n",
        "    target_feature = target_to_feature(target_key, target_sequence, aln_dir)\n",
        "    target_edge_index = np.array(target_edge_index)\n",
        "    return target_size, target_feature, target_edge_index\n",
        "\n",
        "\n",
        "# to judge whether the required files exist\n",
        "def valid_target(key, dataset):\n",
        "    contact_dir = 'data/' + dataset + '/pconsc4'\n",
        "    aln_dir = 'data/' + dataset + '/aln'\n",
        "    contact_file = os.path.join(contact_dir, key + '.npy')\n",
        "    aln_file = os.path.join(aln_dir, key + '.aln')\n",
        "    # print(contact_file, aln_file)\n",
        "    if os.path.exists(contact_file) and os.path.exists(aln_file):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def data_to_csv(csv_file, datalist):\n",
        "    with open(csv_file, 'w') as f:\n",
        "        f.write('compound_iso_smiles,target_sequence,target_key,affinity\\n')\n",
        "        for data in datalist:\n",
        "            f.write(','.join(map(str, data)) + '\\n')\n",
        "\n",
        "\n",
        "def create_dataset_for_test(dataset):\n",
        "    # load dataset\n",
        "    dataset_path = 'data/' + dataset + '/'\n",
        "    test_fold = json.load(open(dataset_path + 'folds/test_fold_setting1.txt'))\n",
        "    ligands = json.load(open(dataset_path + 'ligands_can.txt'), object_pairs_hook=OrderedDict)\n",
        "    proteins = json.load(open(dataset_path + 'proteins.txt'), object_pairs_hook=OrderedDict)\n",
        "    affinity = pickle.load(open(dataset_path + 'Y', 'rb'), encoding='latin1')\n",
        "    # load contact and aln\n",
        "    msa_path = 'data/' + dataset + '/aln'\n",
        "    contac_path = 'data/' + dataset + '/pconsc4'\n",
        "    msa_list = []\n",
        "    contact_list = []\n",
        "    for key in proteins:\n",
        "        msa_list.append(os.path.join(msa_path, key + '.aln'))\n",
        "        contact_list.append(os.path.join(contac_path, key + '.npy'))\n",
        "\n",
        "    drugs = []\n",
        "    prots = []\n",
        "    prot_keys = []\n",
        "    drug_smiles = []\n",
        "    # smiles\n",
        "    for d in ligands.keys():\n",
        "        lg = Chem.MolToSmiles(Chem.MolFromSmiles(ligands[d]), isomericSmiles=True)\n",
        "        drugs.append(lg)\n",
        "        drug_smiles.append(ligands[d])\n",
        "    # seqs\n",
        "    for t in proteins.keys():\n",
        "        prots.append(proteins[t])\n",
        "        prot_keys.append(t)\n",
        "    if dataset == 'davis':\n",
        "        affinity = [-np.log10(y / 1e9) for y in affinity]\n",
        "    affinity = np.asarray(affinity)\n",
        "\n",
        "    valid_test_count = 0\n",
        "    rows, cols = np.where(np.isnan(affinity) == False)\n",
        "    rows, cols = rows[test_fold], cols[test_fold]\n",
        "    temp_test_entries = []\n",
        "    for pair_ind in range(len(rows)):\n",
        "        # if the required files is not exist, then pass\n",
        "        if not valid_target(prot_keys[cols[pair_ind]], dataset):\n",
        "            continue\n",
        "        ls = []\n",
        "        ls += [drugs[rows[pair_ind]]]\n",
        "        ls += [prots[cols[pair_ind]]]\n",
        "        ls += [prot_keys[cols[pair_ind]]]\n",
        "        ls += [affinity[rows[pair_ind], cols[pair_ind]]]\n",
        "        temp_test_entries.append(ls)\n",
        "        valid_test_count += 1\n",
        "    csv_file = 'data/' + dataset + '_test.csv'\n",
        "    data_to_csv(csv_file, temp_test_entries)\n",
        "    print('dataset:', dataset)\n",
        "    print('test entries:', len(test_fold), 'effective test entries', valid_test_count)\n",
        "\n",
        "    compound_iso_smiles = drugs\n",
        "    target_key = prot_keys\n",
        "\n",
        "    # create smile graph\n",
        "    smile_graph = {}\n",
        "    for smile in compound_iso_smiles:\n",
        "        g = smile_to_graph(smile)\n",
        "        smile_graph[smile] = g\n",
        "    # print(smile_graph['CN1CCN(C(=O)c2cc3cc(Cl)ccc3[nH]2)CC1']) #for test\n",
        "\n",
        "    # create target graph\n",
        "    # print('target_key', len(target_key), len(set(target_key)))\n",
        "    target_graph = {}\n",
        "    for key in target_key:\n",
        "        if not valid_target(key, dataset):  # ensure the contact and aln files exists\n",
        "            continue\n",
        "        g = target_to_graph(key, proteins[key], contac_path, msa_path)\n",
        "        target_graph[key] = g\n",
        "\n",
        "    # count the number of  proteins with aln and contact files\n",
        "    print('effective drugs,effective prot:', len(smile_graph), len(target_graph))\n",
        "    if len(smile_graph) == 0 or len(target_graph) == 0:\n",
        "        raise Exception('no protein or drug, run the script for datasets preparation.')\n",
        "\n",
        "    # 'data/davis_test.csv' or data/kiba_test.csv'\n",
        "    df_test = pd.read_csv('data/' + dataset + '_test.csv')\n",
        "    test_drugs, test_prot_keys, test_Y = list(df_test['compound_iso_smiles']), list(df_test['target_key']), list(\n",
        "        df_test['affinity'])\n",
        "    test_drugs, test_prot_keys, test_Y = np.asarray(test_drugs), np.asarray(test_prot_keys), np.asarray(test_Y)\n",
        "    test_dataset = DTADataset(root='data', dataset=dataset + '_test', xd=test_drugs, y=test_Y,\n",
        "                              target_key=test_prot_keys, smile_graph=smile_graph, target_graph=target_graph)\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "\n",
        "def create_dataset_for_5folds(dataset, fold=0):\n",
        "    # load dataset\n",
        "    dataset_path = 'data/' + dataset + '/'\n",
        "    train_fold_origin = json.load(open(dataset_path + 'folds/train_fold_setting1.txt'))\n",
        "    train_fold_origin = [e for e in train_fold_origin]  # for 5 folds\n",
        "\n",
        "    ligands = json.load(open(dataset_path + 'ligands_can.txt'), object_pairs_hook=OrderedDict)\n",
        "    proteins = json.load(open(dataset_path + 'proteins.txt'), object_pairs_hook=OrderedDict)\n",
        "    # load contact and aln\n",
        "    msa_path = 'data/' + dataset + '/aln'\n",
        "    contac_path = 'data/' + dataset + '/pconsc4'\n",
        "    msa_list = []\n",
        "    contact_list = []\n",
        "    for key in proteins:\n",
        "        msa_list.append(os.path.join(msa_path, key + '.aln'))\n",
        "        contact_list.append(os.path.join(contac_path, key + '.npy'))\n",
        "\n",
        "    # load train,valid and test entries\n",
        "    train_folds = []\n",
        "    valid_fold = train_fold_origin[fold]  # one fold\n",
        "    for i in range(len(train_fold_origin)):  # other folds\n",
        "        if i != fold:\n",
        "            train_folds += train_fold_origin[i]\n",
        "\n",
        "    affinity = pickle.load(open(dataset_path + 'Y', 'rb'), encoding='latin1')\n",
        "    drugs = []\n",
        "    prots = []\n",
        "    prot_keys = []\n",
        "    drug_smiles = []\n",
        "    # smiles\n",
        "    for d in ligands.keys():\n",
        "        lg = Chem.MolToSmiles(Chem.MolFromSmiles(ligands[d]), isomericSmiles=True)\n",
        "        drugs.append(lg)\n",
        "        drug_smiles.append(ligands[d])\n",
        "    # seqs\n",
        "    for t in proteins.keys():\n",
        "        prots.append(proteins[t])\n",
        "        prot_keys.append(t)\n",
        "    if dataset == 'davis':\n",
        "        affinity = [-np.log10(y / 1e9) for y in affinity]\n",
        "    affinity = np.asarray(affinity)\n",
        "\n",
        "    opts = ['train', 'valid']\n",
        "    valid_train_count = 0\n",
        "    valid_valid_count = 0\n",
        "    for opt in opts:\n",
        "        if opt == 'train':\n",
        "            rows, cols = np.where(np.isnan(affinity) == False)\n",
        "            rows, cols = rows[train_folds], cols[train_folds]\n",
        "            train_fold_entries = []\n",
        "            for pair_ind in range(len(rows)):\n",
        "                if not valid_target(prot_keys[cols[pair_ind]], dataset):  # ensure the contact and aln files exists\n",
        "                    continue\n",
        "                ls = []\n",
        "                ls += [drugs[rows[pair_ind]]]\n",
        "                ls += [prots[cols[pair_ind]]]\n",
        "                ls += [prot_keys[cols[pair_ind]]]\n",
        "                ls += [affinity[rows[pair_ind], cols[pair_ind]]]\n",
        "                train_fold_entries.append(ls)\n",
        "                valid_train_count += 1\n",
        "\n",
        "            csv_file = 'data/' + dataset + '_' + 'fold_' + str(fold) + '_' + opt + '.csv'\n",
        "            data_to_csv(csv_file, train_fold_entries)\n",
        "        elif opt == 'valid':\n",
        "            rows, cols = np.where(np.isnan(affinity) == False)\n",
        "            rows, cols = rows[valid_fold], cols[valid_fold]\n",
        "            valid_fold_entries = []\n",
        "            for pair_ind in range(len(rows)):\n",
        "                if not valid_target(prot_keys[cols[pair_ind]], dataset):\n",
        "                    continue\n",
        "                ls = []\n",
        "                ls += [drugs[rows[pair_ind]]]\n",
        "                ls += [prots[cols[pair_ind]]]\n",
        "                ls += [prot_keys[cols[pair_ind]]]\n",
        "                ls += [affinity[rows[pair_ind], cols[pair_ind]]]\n",
        "                valid_fold_entries.append(ls)\n",
        "                valid_valid_count += 1\n",
        "\n",
        "            csv_file = 'data/' + dataset + '_' + 'fold_' + str(fold) + '_' + opt + '.csv'\n",
        "            data_to_csv(csv_file, valid_fold_entries)\n",
        "    print('dataset:', dataset)\n",
        "    # print('len(set(drugs)),len(set(prots)):', len(set(drugs)), len(set(prots)))\n",
        "\n",
        "    # entries with protein contact and aln files are marked as effiective\n",
        "    print('fold:', fold)\n",
        "    print('train entries:', len(train_folds), 'effective train entries', valid_train_count)\n",
        "    print('valid entries:', len(valid_fold), 'effective valid entries', valid_valid_count)\n",
        "\n",
        "    compound_iso_smiles = drugs\n",
        "    target_key = prot_keys\n",
        "\n",
        "    # create smile graph\n",
        "    smile_graph = {}\n",
        "    for smile in compound_iso_smiles:\n",
        "        g = smile_to_graph(smile)\n",
        "        smile_graph[smile] = g\n",
        "    # print(smile_graph['CN1CCN(C(=O)c2cc3cc(Cl)ccc3[nH]2)CC1']) #for test\n",
        "\n",
        "    # create target graph\n",
        "    # print('target_key', len(target_key), len(set(target_key)))\n",
        "    target_graph = {}\n",
        "    for key in target_key:\n",
        "        if not valid_target(key, dataset):  # ensure the contact and aln files exists\n",
        "            continue\n",
        "        g = target_to_graph(key, proteins[key], contac_path, msa_path)\n",
        "        target_graph[key] = g\n",
        "\n",
        "    # count the number of  proteins with aln and contact files\n",
        "    print('effective drugs,effective prot:', len(smile_graph), len(target_graph))\n",
        "    if len(smile_graph) == 0 or len(target_graph) == 0:\n",
        "        raise Exception('no protein or drug, run the script for datasets preparation.')\n",
        "\n",
        "    # 'data/davis_fold_0_train.csv' or data/kiba_fold_0__train.csv'\n",
        "    train_csv = 'data/' + dataset + '_' + 'fold_' + str(fold) + '_' + 'train' + '.csv'\n",
        "    df_train_fold = pd.read_csv(train_csv)\n",
        "    train_drugs, train_prot_keys, train_Y = list(df_train_fold['compound_iso_smiles']), list(\n",
        "        df_train_fold['target_key']), list(df_train_fold['affinity'])\n",
        "    train_drugs, train_prot_keys, train_Y = np.asarray(train_drugs), np.asarray(train_prot_keys), np.asarray(train_Y)\n",
        "    train_dataset = DTADataset(root='data', dataset=dataset + '_' + 'train', xd=train_drugs, target_key=train_prot_keys,\n",
        "                               y=train_Y, smile_graph=smile_graph, target_graph=target_graph)\n",
        "\n",
        "\n",
        "    df_valid_fold = pd.read_csv('data/' + dataset + '_' + 'fold_' + str(fold) + '_' + 'valid' + '.csv')\n",
        "    valid_drugs, valid_prots_keys, valid_Y = list(df_valid_fold['compound_iso_smiles']), list(\n",
        "        df_valid_fold['target_key']), list(df_valid_fold['affinity'])\n",
        "    valid_drugs, valid_prots_keys, valid_Y = np.asarray(valid_drugs), np.asarray(valid_prots_keys), np.asarray(\n",
        "        valid_Y)\n",
        "    valid_dataset = DTADataset(root='data', dataset=dataset + '_' + 'train', xd=valid_drugs,\n",
        "                               target_key=valid_prots_keys, y=valid_Y, smile_graph=smile_graph,\n",
        "                               target_graph=target_graph)\n",
        "    return train_dataset, valid_dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M31nGV8346VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_bUiQaOfQBG",
        "colab_type": "text"
      },
      "source": [
        "# training_5folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A06ffbdM5H-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f38559d8-1bc2-4c73-9a2d-847a2317d43e"
      },
      "source": [
        "%cd /content/DGraphDTA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DGraphDTA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvaPjVEfTUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50593030-67b4-4fef-cd2d-78368a5d6f93"
      },
      "source": [
        "import sys, os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# from gnn import GNNNet\n",
        "# from utils import *\n",
        "# from emetrics import *\n",
        "# from data_process import create_dataset_for_5folds\n",
        "\n",
        "\n",
        "datasets = 'davis'\n",
        "\n",
        "cuda_name = 'cuda:0'\n",
        "print('cuda_name:', cuda_name)\n",
        "fold = 0 # [0, 1, 2, 3, 4][int(sys.argv[3])]\n",
        "cross_validation_flag = True\n",
        "\n",
        "TRAIN_BATCH_SIZE = 512\n",
        "TEST_BATCH_SIZE = 512\n",
        "LR = 0.001\n",
        "NUM_EPOCHS = 2000\n",
        "\n",
        "print('Learning rate: ', LR)\n",
        "print('Epochs: ', NUM_EPOCHS)\n",
        "\n",
        "models_dir = '/content/drive/My Drive/DGraphDTA/models' # set your own path\n",
        "results_dir = '/content/drive/My Drive/DGraphDTA/results' # set your own path\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "\n",
        "result_str = ''\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(cuda_name if USE_CUDA else 'cpu')\n",
        "model = GNNNet()\n",
        "model.to(device)\n",
        "model_st = GNNNet.__name__\n",
        "model_file_name = os.path.join(models_dir,'model_' + model_st + '_' + dataset + '_' + str(fold) + '.model')\n",
        "\n",
        "########## UNCOMMENT IN CASE YOU NEED TO RESUME TRAINING ##############\n",
        "# state = torch.load(model_file_name)\n",
        "# model.load_state_dict(state['state_dict'])\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "########## UNCOMMENT IN CASE YOU NEED TO RESUME TRAINING ##############\n",
        "# optimizer.load_state_dict(state['optimizer'])\n",
        "#######################################################################\n",
        "\n",
        "train_data, valid_data = create_dataset_for_5folds(dataset, fold)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n",
        "                                            collate_fn=collate)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
        "                                            collate_fn=collate)\n",
        "\n",
        "best_mse = 1000\n",
        "best_test_mse = 1000\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "loss_mse = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train(model, device, train_loader, optimizer, epoch + 1)\n",
        "    print('predicting for valid data')\n",
        "    G, P = predicting(model, device, valid_loader)\n",
        "    val = get_mse(G, P)\n",
        "    loss_mse.append(val)\n",
        "    print('valid result:', val, best_mse)\n",
        "    if val < best_mse:\n",
        "        best_mse = val\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        state = {\n",
        "                    'epoch': epoch,\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }\n",
        "        torch.save(state, model_file_name)\n",
        "        \n",
        "        np.save(results_dir+\"/loss.npy\",np.array(loss_mse))\n",
        "\n",
        "        # torch.save(model.state_dict(), model_file_name)\n",
        "        print('rmse improved at epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
        "    else:\n",
        "        print('No improvement since epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda_name: cuda:0\n",
            "Learning rate:  0.001\n",
            "Epochs:  2000\n",
            "GNNNet Loaded\n",
            "dataset: davis\n",
            "fold: 0\n",
            "train entries: 20036 effective train entries 20036\n",
            "valid entries: 5010 effective valid entries 5010\n",
            "effective drugs,effective prot: 68 442\n",
            "Training on 20036 samples...\n",
            "Train epoch: 1 [0/20036 (0%)]\tLoss: 30.330486\n",
            "Train epoch: 1 [5120/20036 (25%)]\tLoss: 1.954011\n",
            "Train epoch: 1 [10240/20036 (50%)]\tLoss: 2.952061\n",
            "Train epoch: 1 [15360/20036 (75%)]\tLoss: 1.565945\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 1.0046223 1000\n",
            "rmse improved at epoch  1 ; best_test_mse 1.0046223 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 2 [0/20036 (0%)]\tLoss: 1.045606\n",
            "Train epoch: 2 [5120/20036 (25%)]\tLoss: 0.992288\n",
            "Train epoch: 2 [10240/20036 (50%)]\tLoss: 0.817557\n",
            "Train epoch: 2 [15360/20036 (75%)]\tLoss: 0.836662\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.8408129 1.0046223\n",
            "rmse improved at epoch  2 ; best_test_mse 0.8408129 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 3 [0/20036 (0%)]\tLoss: 0.753482\n",
            "Train epoch: 3 [5120/20036 (25%)]\tLoss: 0.831919\n",
            "Train epoch: 3 [10240/20036 (50%)]\tLoss: 0.830461\n",
            "Train epoch: 3 [15360/20036 (75%)]\tLoss: 0.724038\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.84459615 0.8408129\n",
            "No improvement since epoch  2 ; best_test_mse 0.8408129 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 4 [0/20036 (0%)]\tLoss: 0.804172\n",
            "Train epoch: 4 [5120/20036 (25%)]\tLoss: 0.868761\n",
            "Train epoch: 4 [10240/20036 (50%)]\tLoss: 0.956435\n",
            "Train epoch: 4 [15360/20036 (75%)]\tLoss: 1.013468\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.7681184 0.8408129\n",
            "rmse improved at epoch  4 ; best_test_mse 0.7681184 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 5 [0/20036 (0%)]\tLoss: 0.886913\n",
            "Train epoch: 5 [5120/20036 (25%)]\tLoss: 0.736311\n",
            "Train epoch: 5 [10240/20036 (50%)]\tLoss: 0.743716\n",
            "Train epoch: 5 [15360/20036 (75%)]\tLoss: 0.754149\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.79482466 0.7681184\n",
            "No improvement since epoch  4 ; best_test_mse 0.7681184 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 6 [0/20036 (0%)]\tLoss: 0.957031\n",
            "Train epoch: 6 [5120/20036 (25%)]\tLoss: 0.695916\n",
            "Train epoch: 6 [10240/20036 (50%)]\tLoss: 0.735349\n",
            "Train epoch: 6 [15360/20036 (75%)]\tLoss: 0.834049\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.72152746 0.7681184\n",
            "rmse improved at epoch  6 ; best_test_mse 0.72152746 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 7 [0/20036 (0%)]\tLoss: 0.848869\n",
            "Train epoch: 7 [5120/20036 (25%)]\tLoss: 0.677925\n",
            "Train epoch: 7 [10240/20036 (50%)]\tLoss: 0.752724\n",
            "Train epoch: 7 [15360/20036 (75%)]\tLoss: 0.704874\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.67220753 0.72152746\n",
            "rmse improved at epoch  7 ; best_test_mse 0.67220753 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 8 [0/20036 (0%)]\tLoss: 0.651948\n",
            "Train epoch: 8 [5120/20036 (25%)]\tLoss: 0.812840\n",
            "Train epoch: 8 [10240/20036 (50%)]\tLoss: 0.666875\n",
            "Train epoch: 8 [15360/20036 (75%)]\tLoss: 0.693878\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.7045347 0.67220753\n",
            "No improvement since epoch  7 ; best_test_mse 0.67220753 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 9 [0/20036 (0%)]\tLoss: 0.794625\n",
            "Train epoch: 9 [5120/20036 (25%)]\tLoss: 0.651065\n",
            "Train epoch: 9 [10240/20036 (50%)]\tLoss: 0.683484\n",
            "Train epoch: 9 [15360/20036 (75%)]\tLoss: 0.816476\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.64442563 0.67220753\n",
            "rmse improved at epoch  9 ; best_test_mse 0.64442563 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 10 [0/20036 (0%)]\tLoss: 0.717327\n",
            "Train epoch: 10 [5120/20036 (25%)]\tLoss: 0.832867\n",
            "Train epoch: 10 [10240/20036 (50%)]\tLoss: 0.681682\n",
            "Train epoch: 10 [15360/20036 (75%)]\tLoss: 0.741191\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.80023915 0.64442563\n",
            "No improvement since epoch  9 ; best_test_mse 0.64442563 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 11 [0/20036 (0%)]\tLoss: 0.758460\n",
            "Train epoch: 11 [5120/20036 (25%)]\tLoss: 0.861357\n",
            "Train epoch: 11 [10240/20036 (50%)]\tLoss: 0.634330\n",
            "Train epoch: 11 [15360/20036 (75%)]\tLoss: 0.723385\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.630129 0.64442563\n",
            "rmse improved at epoch  11 ; best_test_mse 0.630129 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 12 [0/20036 (0%)]\tLoss: 0.777570\n",
            "Train epoch: 12 [5120/20036 (25%)]\tLoss: 0.800832\n",
            "Train epoch: 12 [10240/20036 (50%)]\tLoss: 0.746367\n",
            "Train epoch: 12 [15360/20036 (75%)]\tLoss: 0.815326\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6214711 0.630129\n",
            "rmse improved at epoch  12 ; best_test_mse 0.6214711 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 13 [0/20036 (0%)]\tLoss: 0.840506\n",
            "Train epoch: 13 [5120/20036 (25%)]\tLoss: 0.625104\n",
            "Train epoch: 13 [10240/20036 (50%)]\tLoss: 0.809663\n",
            "Train epoch: 13 [15360/20036 (75%)]\tLoss: 0.811009\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6860578 0.6214711\n",
            "No improvement since epoch  12 ; best_test_mse 0.6214711 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 14 [0/20036 (0%)]\tLoss: 0.747700\n",
            "Train epoch: 14 [5120/20036 (25%)]\tLoss: 0.679979\n",
            "Train epoch: 14 [10240/20036 (50%)]\tLoss: 0.779866\n",
            "Train epoch: 14 [15360/20036 (75%)]\tLoss: 0.567734\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6827418 0.6214711\n",
            "No improvement since epoch  12 ; best_test_mse 0.6214711 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 15 [0/20036 (0%)]\tLoss: 0.635834\n",
            "Train epoch: 15 [5120/20036 (25%)]\tLoss: 0.862938\n",
            "Train epoch: 15 [10240/20036 (50%)]\tLoss: 0.810625\n",
            "Train epoch: 15 [15360/20036 (75%)]\tLoss: 0.673085\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.62100357 0.6214711\n",
            "rmse improved at epoch  15 ; best_test_mse 0.62100357 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 16 [0/20036 (0%)]\tLoss: 0.625276\n",
            "Train epoch: 16 [5120/20036 (25%)]\tLoss: 0.628109\n",
            "Train epoch: 16 [10240/20036 (50%)]\tLoss: 0.731086\n",
            "Train epoch: 16 [15360/20036 (75%)]\tLoss: 0.577889\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6309103 0.62100357\n",
            "No improvement since epoch  15 ; best_test_mse 0.62100357 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 17 [0/20036 (0%)]\tLoss: 0.708612\n",
            "Train epoch: 17 [5120/20036 (25%)]\tLoss: 0.568648\n",
            "Train epoch: 17 [10240/20036 (50%)]\tLoss: 0.578268\n",
            "Train epoch: 17 [15360/20036 (75%)]\tLoss: 0.747854\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.8203249 0.62100357\n",
            "No improvement since epoch  15 ; best_test_mse 0.62100357 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 18 [0/20036 (0%)]\tLoss: 0.848393\n",
            "Train epoch: 18 [5120/20036 (25%)]\tLoss: 0.654977\n",
            "Train epoch: 18 [10240/20036 (50%)]\tLoss: 0.631436\n",
            "Train epoch: 18 [15360/20036 (75%)]\tLoss: 0.602604\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.89062774 0.62100357\n",
            "No improvement since epoch  15 ; best_test_mse 0.62100357 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 19 [0/20036 (0%)]\tLoss: 0.980572\n",
            "Train epoch: 19 [5120/20036 (25%)]\tLoss: 0.826767\n",
            "Train epoch: 19 [10240/20036 (50%)]\tLoss: 0.636589\n",
            "Train epoch: 19 [15360/20036 (75%)]\tLoss: 0.768166\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6004989 0.62100357\n",
            "rmse improved at epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 20 [0/20036 (0%)]\tLoss: 0.623417\n",
            "Train epoch: 20 [5120/20036 (25%)]\tLoss: 0.860565\n",
            "Train epoch: 20 [10240/20036 (50%)]\tLoss: 0.592337\n",
            "Train epoch: 20 [15360/20036 (75%)]\tLoss: 0.549410\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.698231 0.6004989\n",
            "No improvement since epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 21 [0/20036 (0%)]\tLoss: 0.735551\n",
            "Train epoch: 21 [5120/20036 (25%)]\tLoss: 0.810027\n",
            "Train epoch: 21 [10240/20036 (50%)]\tLoss: 0.635418\n",
            "Train epoch: 21 [15360/20036 (75%)]\tLoss: 0.732974\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.64459735 0.6004989\n",
            "No improvement since epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 22 [0/20036 (0%)]\tLoss: 0.882116\n",
            "Train epoch: 22 [5120/20036 (25%)]\tLoss: 0.623517\n",
            "Train epoch: 22 [10240/20036 (50%)]\tLoss: 0.647476\n",
            "Train epoch: 22 [15360/20036 (75%)]\tLoss: 0.664957\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.66360694 0.6004989\n",
            "No improvement since epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 23 [0/20036 (0%)]\tLoss: 0.618296\n",
            "Train epoch: 23 [5120/20036 (25%)]\tLoss: 0.681717\n",
            "Train epoch: 23 [10240/20036 (50%)]\tLoss: 0.541526\n",
            "Train epoch: 23 [15360/20036 (75%)]\tLoss: 0.674766\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.7477802 0.6004989\n",
            "No improvement since epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 24 [0/20036 (0%)]\tLoss: 0.567106\n",
            "Train epoch: 24 [5120/20036 (25%)]\tLoss: 0.640221\n",
            "Train epoch: 24 [10240/20036 (50%)]\tLoss: 0.535648\n",
            "Train epoch: 24 [15360/20036 (75%)]\tLoss: 0.679296\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.60233635 0.6004989\n",
            "No improvement since epoch  19 ; best_test_mse 0.6004989 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 25 [0/20036 (0%)]\tLoss: 0.801036\n",
            "Train epoch: 25 [5120/20036 (25%)]\tLoss: 0.570408\n",
            "Train epoch: 25 [10240/20036 (50%)]\tLoss: 0.638882\n",
            "Train epoch: 25 [15360/20036 (75%)]\tLoss: 0.696871\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.59174025 0.6004989\n",
            "rmse improved at epoch  25 ; best_test_mse 0.59174025 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 26 [0/20036 (0%)]\tLoss: 0.664289\n",
            "Train epoch: 26 [5120/20036 (25%)]\tLoss: 0.718461\n",
            "Train epoch: 26 [10240/20036 (50%)]\tLoss: 0.721248\n",
            "Train epoch: 26 [15360/20036 (75%)]\tLoss: 0.604180\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6389643 0.59174025\n",
            "No improvement since epoch  25 ; best_test_mse 0.59174025 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 27 [0/20036 (0%)]\tLoss: 0.596169\n",
            "Train epoch: 27 [5120/20036 (25%)]\tLoss: 0.753560\n",
            "Train epoch: 27 [10240/20036 (50%)]\tLoss: 0.722581\n",
            "Train epoch: 27 [15360/20036 (75%)]\tLoss: 0.648780\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5814218 0.59174025\n",
            "rmse improved at epoch  27 ; best_test_mse 0.5814218 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 28 [0/20036 (0%)]\tLoss: 0.569660\n",
            "Train epoch: 28 [5120/20036 (25%)]\tLoss: 0.612516\n",
            "Train epoch: 28 [10240/20036 (50%)]\tLoss: 0.576921\n",
            "Train epoch: 28 [15360/20036 (75%)]\tLoss: 0.675070\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.66512895 0.5814218\n",
            "No improvement since epoch  27 ; best_test_mse 0.5814218 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 29 [0/20036 (0%)]\tLoss: 0.837022\n",
            "Train epoch: 29 [5120/20036 (25%)]\tLoss: 0.678428\n",
            "Train epoch: 29 [10240/20036 (50%)]\tLoss: 0.613379\n",
            "Train epoch: 29 [15360/20036 (75%)]\tLoss: 0.649142\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5840668 0.5814218\n",
            "No improvement since epoch  27 ; best_test_mse 0.5814218 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 30 [0/20036 (0%)]\tLoss: 0.602982\n",
            "Train epoch: 30 [5120/20036 (25%)]\tLoss: 0.647579\n",
            "Train epoch: 30 [10240/20036 (50%)]\tLoss: 0.709760\n",
            "Train epoch: 30 [15360/20036 (75%)]\tLoss: 0.704042\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.59090054 0.5814218\n",
            "No improvement since epoch  27 ; best_test_mse 0.5814218 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 31 [0/20036 (0%)]\tLoss: 0.663790\n",
            "Train epoch: 31 [5120/20036 (25%)]\tLoss: 0.626546\n",
            "Train epoch: 31 [10240/20036 (50%)]\tLoss: 0.563645\n",
            "Train epoch: 31 [15360/20036 (75%)]\tLoss: 0.512181\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.57698023 0.5814218\n",
            "rmse improved at epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 32 [0/20036 (0%)]\tLoss: 0.826357\n",
            "Train epoch: 32 [5120/20036 (25%)]\tLoss: 0.655307\n",
            "Train epoch: 32 [10240/20036 (50%)]\tLoss: 0.573874\n",
            "Train epoch: 32 [15360/20036 (75%)]\tLoss: 0.647722\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6946137 0.57698023\n",
            "No improvement since epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 33 [0/20036 (0%)]\tLoss: 0.766217\n",
            "Train epoch: 33 [5120/20036 (25%)]\tLoss: 0.630484\n",
            "Train epoch: 33 [10240/20036 (50%)]\tLoss: 0.674527\n",
            "Train epoch: 33 [15360/20036 (75%)]\tLoss: 0.542181\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.62176675 0.57698023\n",
            "No improvement since epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 34 [0/20036 (0%)]\tLoss: 0.594723\n",
            "Train epoch: 34 [5120/20036 (25%)]\tLoss: 0.707904\n",
            "Train epoch: 34 [10240/20036 (50%)]\tLoss: 0.600308\n",
            "Train epoch: 34 [15360/20036 (75%)]\tLoss: 0.647087\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.64610416 0.57698023\n",
            "No improvement since epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 35 [0/20036 (0%)]\tLoss: 0.678193\n",
            "Train epoch: 35 [5120/20036 (25%)]\tLoss: 0.717982\n",
            "Train epoch: 35 [10240/20036 (50%)]\tLoss: 0.725293\n",
            "Train epoch: 35 [15360/20036 (75%)]\tLoss: 0.630239\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5976438 0.57698023\n",
            "No improvement since epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 36 [0/20036 (0%)]\tLoss: 0.626604\n",
            "Train epoch: 36 [5120/20036 (25%)]\tLoss: 0.684748\n",
            "Train epoch: 36 [10240/20036 (50%)]\tLoss: 0.632463\n",
            "Train epoch: 36 [15360/20036 (75%)]\tLoss: 0.767767\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6117971 0.57698023\n",
            "No improvement since epoch  31 ; best_test_mse 0.57698023 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 37 [0/20036 (0%)]\tLoss: 0.610142\n",
            "Train epoch: 37 [5120/20036 (25%)]\tLoss: 0.677359\n",
            "Train epoch: 37 [10240/20036 (50%)]\tLoss: 0.563474\n",
            "Train epoch: 37 [15360/20036 (75%)]\tLoss: 0.634990\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.56591487 0.57698023\n",
            "rmse improved at epoch  37 ; best_test_mse 0.56591487 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 38 [0/20036 (0%)]\tLoss: 0.663008\n",
            "Train epoch: 38 [5120/20036 (25%)]\tLoss: 0.622463\n",
            "Train epoch: 38 [10240/20036 (50%)]\tLoss: 0.533009\n",
            "Train epoch: 38 [15360/20036 (75%)]\tLoss: 0.744717\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6149672 0.56591487\n",
            "No improvement since epoch  37 ; best_test_mse 0.56591487 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 39 [0/20036 (0%)]\tLoss: 0.453680\n",
            "Train epoch: 39 [5120/20036 (25%)]\tLoss: 0.465175\n",
            "Train epoch: 39 [10240/20036 (50%)]\tLoss: 0.562513\n",
            "Train epoch: 39 [15360/20036 (75%)]\tLoss: 0.596635\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.6261764 0.56591487\n",
            "No improvement since epoch  37 ; best_test_mse 0.56591487 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 40 [0/20036 (0%)]\tLoss: 0.638906\n",
            "Train epoch: 40 [5120/20036 (25%)]\tLoss: 0.685308\n",
            "Train epoch: 40 [10240/20036 (50%)]\tLoss: 0.667451\n",
            "Train epoch: 40 [15360/20036 (75%)]\tLoss: 0.718372\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.55369693 0.56591487\n",
            "rmse improved at epoch  40 ; best_test_mse 0.55369693 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 41 [0/20036 (0%)]\tLoss: 0.416858\n",
            "Train epoch: 41 [5120/20036 (25%)]\tLoss: 0.551606\n",
            "Train epoch: 41 [10240/20036 (50%)]\tLoss: 0.594952\n",
            "Train epoch: 41 [15360/20036 (75%)]\tLoss: 0.657933\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5545233 0.55369693\n",
            "No improvement since epoch  40 ; best_test_mse 0.55369693 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 42 [0/20036 (0%)]\tLoss: 0.642231\n",
            "Train epoch: 42 [5120/20036 (25%)]\tLoss: 0.557675\n",
            "Train epoch: 42 [10240/20036 (50%)]\tLoss: 0.644629\n",
            "Train epoch: 42 [15360/20036 (75%)]\tLoss: 0.586857\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.55881625 0.55369693\n",
            "No improvement since epoch  40 ; best_test_mse 0.55369693 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 43 [0/20036 (0%)]\tLoss: 0.506244\n",
            "Train epoch: 43 [5120/20036 (25%)]\tLoss: 0.610732\n",
            "Train epoch: 43 [10240/20036 (50%)]\tLoss: 0.649341\n",
            "Train epoch: 43 [15360/20036 (75%)]\tLoss: 0.550841\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5382667 0.55369693\n",
            "rmse improved at epoch  43 ; best_test_mse 0.5382667 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 44 [0/20036 (0%)]\tLoss: 0.557411\n",
            "Train epoch: 44 [5120/20036 (25%)]\tLoss: 0.667991\n",
            "Train epoch: 44 [10240/20036 (50%)]\tLoss: 0.645524\n",
            "Train epoch: 44 [15360/20036 (75%)]\tLoss: 0.505960\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5662959 0.5382667\n",
            "No improvement since epoch  43 ; best_test_mse 0.5382667 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 45 [0/20036 (0%)]\tLoss: 0.519700\n",
            "Train epoch: 45 [5120/20036 (25%)]\tLoss: 0.634081\n",
            "Train epoch: 45 [10240/20036 (50%)]\tLoss: 0.539035\n",
            "Train epoch: 45 [15360/20036 (75%)]\tLoss: 0.574541\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.528529 0.5382667\n",
            "rmse improved at epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 46 [0/20036 (0%)]\tLoss: 0.666779\n",
            "Train epoch: 46 [5120/20036 (25%)]\tLoss: 0.516863\n",
            "Train epoch: 46 [10240/20036 (50%)]\tLoss: 0.579759\n",
            "Train epoch: 46 [15360/20036 (75%)]\tLoss: 0.480795\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5583915 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 47 [0/20036 (0%)]\tLoss: 0.691337\n",
            "Train epoch: 47 [5120/20036 (25%)]\tLoss: 0.658624\n",
            "Train epoch: 47 [10240/20036 (50%)]\tLoss: 0.474203\n",
            "Train epoch: 47 [15360/20036 (75%)]\tLoss: 0.595830\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.67420465 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 48 [0/20036 (0%)]\tLoss: 0.973222\n",
            "Train epoch: 48 [5120/20036 (25%)]\tLoss: 0.697141\n",
            "Train epoch: 48 [10240/20036 (50%)]\tLoss: 0.494128\n",
            "Train epoch: 48 [15360/20036 (75%)]\tLoss: 0.592484\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.92090976 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 49 [0/20036 (0%)]\tLoss: 1.233574\n",
            "Train epoch: 49 [5120/20036 (25%)]\tLoss: 0.761485\n",
            "Train epoch: 49 [10240/20036 (50%)]\tLoss: 0.792499\n",
            "Train epoch: 49 [15360/20036 (75%)]\tLoss: 0.736946\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5637898 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 50 [0/20036 (0%)]\tLoss: 0.566128\n",
            "Train epoch: 50 [5120/20036 (25%)]\tLoss: 0.733684\n",
            "Train epoch: 50 [10240/20036 (50%)]\tLoss: 0.641237\n",
            "Train epoch: 50 [15360/20036 (75%)]\tLoss: 0.649356\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5399624 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 51 [0/20036 (0%)]\tLoss: 0.711502\n",
            "Train epoch: 51 [5120/20036 (25%)]\tLoss: 0.492733\n",
            "Train epoch: 51 [10240/20036 (50%)]\tLoss: 0.578687\n",
            "Train epoch: 51 [15360/20036 (75%)]\tLoss: 0.590186\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5933731 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 52 [0/20036 (0%)]\tLoss: 0.651179\n",
            "Train epoch: 52 [5120/20036 (25%)]\tLoss: 0.583701\n",
            "Train epoch: 52 [10240/20036 (50%)]\tLoss: 0.625899\n",
            "Train epoch: 52 [15360/20036 (75%)]\tLoss: 0.572971\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.57 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 53 [0/20036 (0%)]\tLoss: 0.610195\n",
            "Train epoch: 53 [5120/20036 (25%)]\tLoss: 0.484037\n",
            "Train epoch: 53 [10240/20036 (50%)]\tLoss: 0.454736\n",
            "Train epoch: 53 [15360/20036 (75%)]\tLoss: 0.503547\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.57045466 0.528529\n",
            "No improvement since epoch  45 ; best_test_mse 0.528529 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 54 [0/20036 (0%)]\tLoss: 0.755098\n",
            "Train epoch: 54 [5120/20036 (25%)]\tLoss: 0.709479\n",
            "Train epoch: 54 [10240/20036 (50%)]\tLoss: 0.615617\n",
            "Train epoch: 54 [15360/20036 (75%)]\tLoss: 0.542421\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.51736456 0.528529\n",
            "rmse improved at epoch  54 ; best_test_mse 0.51736456 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 55 [0/20036 (0%)]\tLoss: 0.518693\n",
            "Train epoch: 55 [5120/20036 (25%)]\tLoss: 0.476057\n",
            "Train epoch: 55 [10240/20036 (50%)]\tLoss: 0.607936\n",
            "Train epoch: 55 [15360/20036 (75%)]\tLoss: 0.557738\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5337265 0.51736456\n",
            "No improvement since epoch  54 ; best_test_mse 0.51736456 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 56 [0/20036 (0%)]\tLoss: 0.612436\n",
            "Train epoch: 56 [5120/20036 (25%)]\tLoss: 0.610863\n",
            "Train epoch: 56 [10240/20036 (50%)]\tLoss: 0.591919\n",
            "Train epoch: 56 [15360/20036 (75%)]\tLoss: 0.511420\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.56479996 0.51736456\n",
            "No improvement since epoch  54 ; best_test_mse 0.51736456 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 57 [0/20036 (0%)]\tLoss: 0.569507\n",
            "Train epoch: 57 [5120/20036 (25%)]\tLoss: 0.621450\n",
            "Train epoch: 57 [10240/20036 (50%)]\tLoss: 0.743409\n",
            "Train epoch: 57 [15360/20036 (75%)]\tLoss: 0.635690\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5108539 0.51736456\n",
            "rmse improved at epoch  57 ; best_test_mse 0.5108539 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 58 [0/20036 (0%)]\tLoss: 0.584474\n",
            "Train epoch: 58 [5120/20036 (25%)]\tLoss: 0.604349\n",
            "Train epoch: 58 [10240/20036 (50%)]\tLoss: 0.477014\n",
            "Train epoch: 58 [15360/20036 (75%)]\tLoss: 0.508818\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.51447386 0.5108539\n",
            "No improvement since epoch  57 ; best_test_mse 0.5108539 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 59 [0/20036 (0%)]\tLoss: 0.561480\n",
            "Train epoch: 59 [5120/20036 (25%)]\tLoss: 0.476816\n",
            "Train epoch: 59 [10240/20036 (50%)]\tLoss: 0.540457\n",
            "Train epoch: 59 [15360/20036 (75%)]\tLoss: 0.419248\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5160961 0.5108539\n",
            "No improvement since epoch  57 ; best_test_mse 0.5108539 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 60 [0/20036 (0%)]\tLoss: 0.611578\n",
            "Train epoch: 60 [5120/20036 (25%)]\tLoss: 0.587843\n",
            "Train epoch: 60 [10240/20036 (50%)]\tLoss: 0.458304\n",
            "Train epoch: 60 [15360/20036 (75%)]\tLoss: 0.630712\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.51824284 0.5108539\n",
            "No improvement since epoch  57 ; best_test_mse 0.5108539 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 61 [0/20036 (0%)]\tLoss: 0.562101\n",
            "Train epoch: 61 [5120/20036 (25%)]\tLoss: 0.698479\n",
            "Train epoch: 61 [10240/20036 (50%)]\tLoss: 0.591667\n",
            "Train epoch: 61 [15360/20036 (75%)]\tLoss: 0.532161\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5370502 0.5108539\n",
            "No improvement since epoch  57 ; best_test_mse 0.5108539 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 62 [0/20036 (0%)]\tLoss: 0.617218\n",
            "Train epoch: 62 [5120/20036 (25%)]\tLoss: 0.507316\n",
            "Train epoch: 62 [10240/20036 (50%)]\tLoss: 0.536763\n",
            "Train epoch: 62 [15360/20036 (75%)]\tLoss: 0.467993\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.49913186 0.5108539\n",
            "rmse improved at epoch  62 ; best_test_mse 0.49913186 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 63 [0/20036 (0%)]\tLoss: 0.514127\n",
            "Train epoch: 63 [5120/20036 (25%)]\tLoss: 0.501509\n",
            "Train epoch: 63 [10240/20036 (50%)]\tLoss: 0.513622\n",
            "Train epoch: 63 [15360/20036 (75%)]\tLoss: 0.548707\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.4975658 0.49913186\n",
            "rmse improved at epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 64 [0/20036 (0%)]\tLoss: 0.721640\n",
            "Train epoch: 64 [5120/20036 (25%)]\tLoss: 0.528369\n",
            "Train epoch: 64 [10240/20036 (50%)]\tLoss: 0.514672\n",
            "Train epoch: 64 [15360/20036 (75%)]\tLoss: 0.582217\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.51163733 0.4975658\n",
            "No improvement since epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 65 [0/20036 (0%)]\tLoss: 0.570542\n",
            "Train epoch: 65 [5120/20036 (25%)]\tLoss: 0.507106\n",
            "Train epoch: 65 [10240/20036 (50%)]\tLoss: 0.480573\n",
            "Train epoch: 65 [15360/20036 (75%)]\tLoss: 0.673489\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.4979635 0.4975658\n",
            "No improvement since epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 66 [0/20036 (0%)]\tLoss: 0.560270\n",
            "Train epoch: 66 [5120/20036 (25%)]\tLoss: 0.543178\n",
            "Train epoch: 66 [10240/20036 (50%)]\tLoss: 0.478234\n",
            "Train epoch: 66 [15360/20036 (75%)]\tLoss: 0.492331\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5505992 0.4975658\n",
            "No improvement since epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 67 [0/20036 (0%)]\tLoss: 0.637987\n",
            "Train epoch: 67 [5120/20036 (25%)]\tLoss: 0.571989\n",
            "Train epoch: 67 [10240/20036 (50%)]\tLoss: 0.485482\n",
            "Train epoch: 67 [15360/20036 (75%)]\tLoss: 0.544161\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.51055855 0.4975658\n",
            "No improvement since epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 68 [0/20036 (0%)]\tLoss: 0.495818\n",
            "Train epoch: 68 [5120/20036 (25%)]\tLoss: 0.531512\n",
            "Train epoch: 68 [10240/20036 (50%)]\tLoss: 0.617026\n",
            "Train epoch: 68 [15360/20036 (75%)]\tLoss: 0.613707\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.5031402 0.4975658\n",
            "No improvement since epoch  63 ; best_test_mse 0.4975658 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 69 [0/20036 (0%)]\tLoss: 0.435887\n",
            "Train epoch: 69 [5120/20036 (25%)]\tLoss: 0.535375\n",
            "Train epoch: 69 [10240/20036 (50%)]\tLoss: 0.539224\n",
            "Train epoch: 69 [15360/20036 (75%)]\tLoss: 0.567885\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "valid result: 0.49753627 0.4975658\n",
            "rmse improved at epoch  69 ; best_test_mse 0.49753627 GNNNet davis 0\n",
            "Training on 20036 samples...\n",
            "Train epoch: 70 [0/20036 (0%)]\tLoss: 0.512889\n",
            "Train epoch: 70 [5120/20036 (25%)]\tLoss: 0.613955\n",
            "Train epoch: 70 [10240/20036 (50%)]\tLoss: 0.510863\n",
            "Train epoch: 70 [15360/20036 (75%)]\tLoss: 0.508411\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "loaQCmPJef_g"
      },
      "source": [
        "# test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48ZaNIvPef_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "ed3486d4-f262-4ebb-afee-4a429e7e7a13"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.data import Batch\n",
        "\n",
        "# from emetrics import get_aupr, get_cindex, get_rm2, get_ci, get_mse, get_rmse, get_pearson, get_spearman\n",
        "# from utils import *\n",
        "from scipy import stats\n",
        "# from gnn import GNNNet\n",
        "# from data_process import create_dataset_for_test\n",
        "\n",
        "\n",
        "def predicting(model, device, loader):\n",
        "    model.eval()\n",
        "    total_preds = torch.Tensor()\n",
        "    total_labels = torch.Tensor()\n",
        "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data_mol = data[0].to(device)\n",
        "            data_pro = data[1].to(device)\n",
        "            # data = data.to(device)\n",
        "            output = model(data_mol, data_pro)\n",
        "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
        "            total_labels = torch.cat((total_labels, data_mol.y.view(-1, 1).cpu()), 0)\n",
        "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()\n",
        "\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = torch.load(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def calculate_metrics(Y, P, dataset='davis',results_dir):\n",
        "    # aupr = get_aupr(Y, P)\n",
        "    cindex = get_cindex(Y, P)  # DeepDTA\n",
        "    cindex2 = get_ci(Y, P)  # GraphDTA\n",
        "    rm2 = get_rm2(Y, P)  # DeepDTA\n",
        "    mse = get_mse(Y, P)\n",
        "    pearson = get_pearson(Y, P)\n",
        "    spearman = get_spearman(Y, P)\n",
        "    rmse = get_rmse(Y, P)\n",
        "\n",
        "    print('metrics for ', dataset)\n",
        "    # print('aupr:', aupr)\n",
        "    print('cindex:', cindex)\n",
        "    print('cindex2', cindex2)\n",
        "    print('rm2:', rm2)\n",
        "    print('mse:', mse)\n",
        "    print('pearson', pearson)\n",
        "\n",
        "    result_file_name = results_dir +'/result_' + model_st + '_' + dataset + '.txt'\n",
        "    result_str = ''\n",
        "    result_str += dataset + '\\r\\n'\n",
        "    result_str += 'rmse:' + str(rmse) + ' ' + ' mse:' + str(mse) + ' ' + ' pearson:' + str(\n",
        "        pearson) + ' ' + 'spearman:' + str(spearman) + ' ' + 'ci:' + str(cindex) + ' ' + 'rm2:' + str(rm2)\n",
        "    print(result_str)\n",
        "    open(result_file_name, 'w').writelines(result_str)\n",
        "\n",
        "\n",
        "def plot_density(Y, P, fold=0, dataset='davis',results_dir):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.grid(linestyle='--')\n",
        "    ax = plt.gca()\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.scatter(P, Y, color='blue', s=40)\n",
        "    plt.title('density of ' + dataset, fontsize=30, fontweight='bold')\n",
        "    plt.xlabel('predicted', fontsize=30, fontweight='bold')\n",
        "    plt.ylabel('measured', fontsize=30, fontweight='bold')\n",
        "    # plt.xlim(0, 21)\n",
        "    # plt.ylim(0, 21)\n",
        "    if dataset == 'davis':\n",
        "        plt.plot([5, 11], [5, 11], color='black')\n",
        "    else:\n",
        "        plt.plot([6, 16], [6, 16], color='black')\n",
        "    # plt.legend()\n",
        "    plt.legend(loc=0, numpoints=1)\n",
        "    leg = plt.gca().get_legend()\n",
        "    ltext = leg.get_texts()\n",
        "    plt.setp(ltext, fontsize=12, fontweight='bold')\n",
        "    plt.savefig(os.path.join(results_dir, dataset + '_' + str(fold) + '.png'), dpi=500, bbox_inches='tight')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = 'davis'  # dataset selection\n",
        "    model_st = GNNNet.__name__\n",
        "    print('dataset:', dataset)\n",
        "    fold = 0\n",
        "    cuda_name = 'cuda:0'  # gpu selection\n",
        "    print('cuda_name:', cuda_name)\n",
        "\n",
        "    TEST_BATCH_SIZE = 512\n",
        "    models_dir = '/content/drive/My Drive/DGraphDTA/models'\n",
        "    results_dir = '/content/drive/My Drive/DGraphDTA/results'\n",
        "\n",
        "    device = torch.device(cuda_name if torch.cuda.is_available() else 'cpu')\n",
        "    model_file_name = models_dir+'/model_' + model_st + '_' + dataset + '_'+str(fold).model'\n",
        "    result_file_name = results_dir+'/result_' + model_st + '_' + dataset + '.txt'\n",
        "\n",
        "    model = GNNNet()\n",
        "    model.to(device)\n",
        "    state = torch.load(model_file_name)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "\n",
        "    # model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
        "    test_data = create_dataset_for_test(dataset)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
        "                                              collate_fn=collate)\n",
        "\n",
        "    Y, P = predicting(model, device, test_loader)\n",
        "    calculate_metrics(Y, P, dataset,results_dir)\n",
        "    plot_density(Y, P, fold, dataset,results_dir)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset: davis\n",
            "cuda_name: cuda:0\n",
            "GNNNet Loaded\n",
            "dataset: davis\n",
            "test entries: 5010 effective test entries 5010\n",
            "effective drugs,effective prot: 68 442\n",
            "Make prediction for 5010 samples...\n",
            "metrics for  davis\n",
            "cindex: 0.8454382174704543\n",
            "cindex2 0.8459144155396036\n",
            "rm2: 0.5779081222614397\n",
            "mse: 0.33864\n",
            "pearson 0.7677362570334195\n",
            "davis\n",
            "rmse:0.5819278343544314  mse:0.33864  pearson:0.7677362570334195 spearman:0.6326158917853564 ci:0.8454382174704543 rm2:0.5779081222614397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}