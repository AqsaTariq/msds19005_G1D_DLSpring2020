{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DeepScreen_gnn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPw2ueth3gIA",
        "colab_type": "text"
      },
      "source": [
        "# Cloning Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k8GBz-HtNdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "040a7b43-9667-4140-b80b-507b29a03bed"
      },
      "source": [
        "! git clone https://github.com/cansyl/DEEPScreen.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DEEPScreen'...\n",
            "remote: Enumerating objects: 5470, done.\u001b[K\n",
            "remote: Total 5470 (delta 0), reused 0 (delta 0), pack-reused 5470\u001b[K\n",
            "Receiving objects: 100% (5470/5470), 267.96 MiB | 27.11 MiB/s, done.\n",
            "Resolving deltas: 100% (2546/2546), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qiSIvaAGLBN",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkTOCZ3wFdMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7c41ebb-ce64-4014-91e0-aac91a2abcf3"
      },
      "source": [
        "!pip install bioservices\n",
        "## !easy_install --upgrade pip\n",
        "!pip install torch-geometric torch-scatter==latest+cu101 torch-sparse==latest+cu101 --no-cache-dir -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bioservices in /usr/local/lib/python3.6/dist-packages (1.7.6)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (from bioservices) (0.12.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from bioservices) (1.4.4)\n",
            "Requirement already satisfied: grequests in /usr/local/lib/python3.6/dist-packages (from bioservices) (0.6.0)\n",
            "Requirement already satisfied: easydev>=0.9.36 in /usr/local/lib/python3.6/dist-packages (from bioservices) (0.9.38)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from bioservices) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bioservices) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bioservices) (4.6.3)\n",
            "Requirement already satisfied: requests-cache in /usr/local/lib/python3.6/dist-packages (from bioservices) (0.5.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from bioservices) (4.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bioservices) (1.0.5)\n",
            "Requirement already satisfied: suds-jurko in /usr/local/lib/python3.6/dist-packages (from bioservices) (0.6)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from bioservices) (1.12.1)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (from grequests->bioservices) (20.6.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (from easydev>=0.9.36->bioservices) (4.8.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from easydev>=0.9.36->bioservices) (0.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bioservices) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bioservices) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bioservices) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bioservices) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->bioservices) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->bioservices) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->bioservices) (2.8.1)\n",
            "Requirement already satisfied: greenlet>=0.4.16; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent->grequests->bioservices) (0.4.16)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.6/dist-packages (from gevent->grequests->bioservices) (4.4)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from gevent->grequests->bioservices) (5.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from gevent->grequests->bioservices) (47.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect->easydev>=0.9.36->bioservices) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->bioservices) (1.12.0)\n",
            "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/93b190226d09958be96919fd50c55d28f83f1a1b9260a2b33499f9d86728/torch_geometric-1.6.0.tar.gz (172kB)\n",
            "     |████████████████████████████████| 174kB 2.9MB/s \n",
            "\u001b[?25hCollecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
            "     |████████████████████████████████| 12.3MB 4.7MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.6MB)\n",
            "     |████████████████████████████████| 21.6MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "     |████████████████████████████████| 235kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/70/a8b1a7831193aa228defd805891c534d3e4717c8988147522e673458ddce/ase-3.19.1-py3-none-any.whl (2.1MB)\n",
            "     |████████████████████████████████| 2.1MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (47.3.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "     |████████████████████████████████| 51kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.0-cp36-none-any.whl size=296339 sha256=6588016869b309212f1f43c1beb492be733512f97e4552e5b08cc30d16d0b263\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d_xpzsqz/wheels/5f/7f/33/acea5809d8580a7adf60dcd6d04f5fc50a7f983040f68be1ff\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric, torch-scatter, torch-sparse\n",
            "Successfully installed ase-3.19.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.0 torch-scatter-2.0.5 torch-sparse-0.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scwGVwv8CRSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "731df35a-251b-44fd-b2eb-c0f5945b39be"
      },
      "source": [
        "# for creating molecular graphs\n",
        "\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 20:22:09--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-07-08 20:22:09--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88867207 (85M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  84.75M   141MB/s    in 0.6s    \n",
            "\n",
            "2020-07-08 20:22:09 (141 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [88867207/88867207]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2020.4.5.1=py37_0\n",
            "    - cffi==1.14.0=py37he30daa8_1\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "    - conda==4.8.3=py37_0\n",
            "    - cryptography==2.9.2=py37h1ba5d50_0\n",
            "    - idna==2.9=py_1\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.3=he6710b0_1\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1g=h7b6447c_0\n",
            "    - pip==20.0.2=py37_3\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.20=py_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.7=hcff3b4d_5\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.23.0=py37_0\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==46.4.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h62c20be_1\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.46.0=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.3-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
            "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_3\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  requests           pkgs/main/linux-64::requests-2.23.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m30.335s\n",
            "user\t0m17.999s\n",
            "sys\t0m5.150s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h7b93d67_1        21.8 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n",
            "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h1056068_1002         365 KB  conda-forge\n",
            "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
            "    glib-2.65.0                |       h3eb4bd4_0         2.9 MB\n",
            "    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n",
            "    jpeg-9d                    |       h516909a_0         266 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |       hdf63c60_6         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       h72b56ed_1         1.3 MB  conda-forge\n",
            "    lz4-c-1.9.2                |       he1b5a44_1         226 KB  conda-forge\n",
            "    numpy-1.18.5               |   py37h8960a57_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.5               |   py37h0da4684_0        10.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.4            |   py37hdd87690_0        24.6 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h6597ccf_3         991 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       105.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h7b93d67_1\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h1056068_1002\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
            "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0\n",
            "  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_6\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_6\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h72b56ed_1\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_1\n",
            "  numpy              conda-forge/linux-64::numpy-1.18.5-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.5-py37h0da4684_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.4-py37hdd87690_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h6597ccf_3\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
            "  certifi              pkgs/main::certifi-2020.4.5.1-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m51.821s\n",
            "user\t0m44.756s\n",
            "sys\t0m4.996s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyu8Kgr9l_Rn",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHq4-9h5NaN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8d8da237-1be4-4e9d-9f30-e1b27effd3f7"
      },
      "source": [
        "### GETTING LIST OF ACTIVE INACTIVE COMPOUNDS OF CHEMBL286 ### \n",
        "def get_act_inact_list_for_a_target(target, fl):\n",
        "    act_list = []\n",
        "    inact_list = []\n",
        "\n",
        "    with open(\"{}/{}\".format(training_files_path, fl))  as f:\n",
        "        for line in f:\n",
        "            if line != \"\":\n",
        "                line=line.split(\"\\n\")[0]\n",
        "                chembl_part, comps = line.split(\"\\t\")\n",
        "                chembl_target_id, act_inact = chembl_part.split(\"_\")\n",
        "                if chembl_target_id == target:\n",
        "                    if act_inact == \"act\":\n",
        "                        act_list = comps.split(\",\")\n",
        "                    else:\n",
        "                        inact_list = comps.split(\",\")\n",
        "                        break\n",
        "\n",
        "    return act_list, inact_list\n",
        "\n",
        "\n",
        "training_files_path = \"/content/DEEPScreen/training_files\"\n",
        "fl = \"chembl27_preprocessed_filtered_act_inact_comps_10.0_20.0_blast_comp_0.2.txt\"\n",
        "\n",
        "protein_id = \"CHEMBL286\"\n",
        "act,inact = get_act_inact_list_for_a_target(protein_id,fl)\n",
        "\n",
        "print(\"\\n\\nFOR ChEMBL256\")\n",
        "print(\"TOTAL NUMBER OF INACTIVE COMPOUNDS \",len(inact))\n",
        "print(\"TOTAL NUMBER OF ACTIVE COMPOUNDS\",len(act))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'DEEPScreen'\n",
            "/content/DEEPScreen\n",
            "\n",
            "\n",
            "FOR ChEMBL256\n",
            "TOTAL NUMBER OF INACTIVE COMPOUNDS  741\n",
            "TOTAL NUMBER OF ACTIVE COMPOUNDS 2797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYqdz2b-l95t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b821d8f-a1c7-433d-9ca2-398cedde4c50"
      },
      "source": [
        "### CONVERTING CHEMBL TO SMILES FOR ACTIVE INACTIVE COMPOUNDS OF CHEMBL286 ### \n",
        "from bioservices.chembl import ChEMBL\n",
        "import os\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import DrawingOptions\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "c = ChEMBL()\n",
        "\n",
        "smiles_dict = dict()\n",
        "for cmpnd in inact:\n",
        "    mol = c.get_molecule(cmpnd)\n",
        "    smiles_dict[cmpnd] = mol[\"molecule_structures\"][\"canonical_smiles\"]\n",
        "\n",
        "for cmpnd in act:\n",
        "    mol = c.get_molecule(cmpnd)\n",
        "    smiles_dict[cmpnd] = mol[\"molecule_structures\"][\"canonical_smiles\"]\n",
        "\n",
        "protein_id = \"CHEMBL286\"\n",
        "project_file_path = \"{}DEEPScreen\".format(os.getcwd().split(\"DEEPScreen\")[0])\n",
        "training_files_path = \"{}/training_files/target_training_datasets/{}\".format(project_file_path,protein_id)\n",
        "\n",
        "# print(training_files_path)\n",
        "%cd $training_files_path\n",
        "with open('smiles_dict.json', 'w') as fp:\n",
        "    json.dump(smiles_dict, fp)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DEEPScreen/training_files/target_training_datasets/CHEMBL286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSwN-vWd3x9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### PREPARING DATASET ###\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import warnings\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler, BatchSampler, SequentialSampler\n",
        "\"\"\"\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import DrawingOptions\n",
        "import cairosvg\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "drive_path = \"/content/drive/My Drive/DeepScreen\" # add your drive path here\n",
        "\n",
        "project_file_path = \"{}/DEEPScreen\".format(os.getcwd().split(\"DEEPScreen\")[0])\n",
        "training_files_path = \"{}/training_files\".format(project_file_path)\n",
        "result_files_path = \"{}/result_files\".format(drive_path)\n",
        "trained_models_path = \"{}/trained_models\".format(drive_path)\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import random\n",
        "import json, pickle\n",
        "from collections import OrderedDict\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MolFromSmiles\n",
        "import networkx as nx\n",
        "\n",
        "def one_of_k_encoding(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        # print(x)\n",
        "        raise Exception('input {0} not in allowable set{1}:'.format(x, allowable_set))\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "    '''Maps inputs not in the allowable set to the last element.'''\n",
        "    if x not in allowable_set:\n",
        "        x = allowable_set[-1]\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def atom_features(atom):\n",
        "    # 44 +11 +11 +11 +1\n",
        "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
        "                                          ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca', 'Fe', 'As',\n",
        "                                           'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se',\n",
        "                                           'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n",
        "                                           'Pt', 'Hg', 'Pb', 'X']) +\n",
        "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
        "                    [atom.GetIsAromatic()])\n",
        "\n",
        "\n",
        "\n",
        "def smile_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    c_size = mol.GetNumAtoms()\n",
        "\n",
        "    features = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        feature = atom_features(atom)\n",
        "        features.append(feature / sum(feature))\n",
        "\n",
        "    edges = []\n",
        "    for bond in mol.GetBonds():\n",
        "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
        "    g = nx.Graph(edges).to_directed()\n",
        "    edge_index = []\n",
        "    mol_adj = np.zeros((c_size, c_size))\n",
        "    for e1, e2 in g.edges:\n",
        "        mol_adj[e1, e2] = 1\n",
        "        # edge_index.append([e1, e2])\n",
        "    mol_adj += np.matrix(np.eye(mol_adj.shape[0]))\n",
        "    index_row, index_col = np.where(mol_adj >= 0.5)\n",
        "    for i, j in zip(index_row, index_col):\n",
        "        edge_index.append([i, j])\n",
        "    \n",
        "    return (c_size, features, edge_index)\n",
        "#############################################\n",
        "\n",
        "def create_final_randomized_training_val_test_sets(target, neg_act_inact_fl, smiles_dict,batch_size):\n",
        "    \n",
        "    # chemblid_smiles_dict = get_chemblid_smiles_inchi_dict(smiles_inchi_fl)\n",
        "    # with open(smiles_inchi_fl) as f:\n",
        "    chemblid_smiles_dict = json.load(open(smiles_dict))\n",
        "\n",
        "    act_list, inact_list = get_act_inact_list_for_a_target(target, neg_act_inact_fl)\n",
        "\n",
        "    if len(inact_list) >= len(act_list):\n",
        "        inact_list = inact_list[:len(act_list)]\n",
        "    else:\n",
        "        act_list = act_list[:int(len(inact_list) * 1.5)]\n",
        "\n",
        "    random.shuffle(act_list)\n",
        "    random.shuffle(inact_list)\n",
        "\n",
        "    act_training_validation_size = int(0.8 * len(act_list))\n",
        "    act_training_size = int(0.8 * act_training_validation_size)\n",
        "    act_val_size = act_training_validation_size - act_training_size\n",
        "    \n",
        "    training_act_comp_id_list = act_list[:act_training_size]\n",
        "    val_act_comp_id_list = act_list[act_training_size:act_training_size+act_val_size]\n",
        "    test_act_comp_id_list = act_list[act_training_size+act_val_size:]\n",
        "\n",
        "    inact_training_validation_size = int(0.8 * len(inact_list))\n",
        "    inact_training_size = int(0.8 * inact_training_validation_size)\n",
        "    inact_val_size = inact_training_validation_size - inact_training_size\n",
        "    \n",
        "    training_inact_comp_id_list = inact_list[:inact_training_size]\n",
        "    val_inact_comp_id_list = inact_list[inact_training_size:inact_training_size+inact_val_size]\n",
        "    test_inact_comp_id_list = inact_list[inact_training_size+inact_val_size:]\n",
        "\n",
        "    print(target, \"all training act\", len(act_list),len(training_act_comp_id_list), len(val_act_comp_id_list), len(test_act_comp_id_list) )\n",
        "    print(target, \"all training inact\", len(inact_list), len(training_inact_comp_id_list), len(val_inact_comp_id_list),\n",
        "          len(test_inact_comp_id_list))\n",
        "    \n",
        "    tar_train_val_test_dict = dict()\n",
        "    \n",
        "    tar_train_val_test_dict[\"training\"] = []\n",
        "    tar_train_val_test_dict[\"validation\"] = []\n",
        "    tar_train_val_test_dict[\"test\"] = []\n",
        "    training_smile_graph = dict()\n",
        "    val_smile_graph = dict()\n",
        "    test_smile_graph = dict()\n",
        "    for comp_id in training_act_comp_id_list:\n",
        "        try:\n",
        "            training_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"training\"].append([comp_id, 1])\n",
        "        except:\n",
        "            # print(\"A TRAIN EXCEPT\")\n",
        "            pass\n",
        "    for comp_id in val_act_comp_id_list:\n",
        "        try:\n",
        "            val_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"validation\"].append([comp_id, 1])\n",
        "        except:\n",
        "            \n",
        "            # print(\"A VAL EXCEPT\")\n",
        "            pass\n",
        "\n",
        "    for comp_id in test_act_comp_id_list:\n",
        "        try:\n",
        "            test_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"test\"].append([comp_id, 1])\n",
        "        except:\n",
        "            \n",
        "            # print(\"A TEST EXCEPT\")\n",
        "            pass\n",
        "\n",
        "    for comp_id in training_inact_comp_id_list:\n",
        "        try:\n",
        "            training_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"training\"].append([comp_id, 0])\n",
        "        except:\n",
        "            # print(\"I TRAIN EXCEPT\")\n",
        "            pass\n",
        "    for comp_id in val_inact_comp_id_list:\n",
        "        try:\n",
        "            val_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"validation\"].append([comp_id, 0])\n",
        "        except:\n",
        "            # print(\"I VAL EXCEPT\")\n",
        "            pass\n",
        "    for comp_id in test_inact_comp_id_list:\n",
        "        try:\n",
        "            test_smile_graph[comp_id] = smile_to_graph(chemblid_smiles_dict[comp_id])\n",
        "            tar_train_val_test_dict[\"test\"].append([comp_id, 0])\n",
        "        except:\n",
        "            # print(\"I TEST EXCEPT\")\n",
        "            pass\n",
        "    random.shuffle(tar_train_val_test_dict[\"training\"])\n",
        "    random.shuffle(tar_train_val_test_dict[\"validation\"])\n",
        "    random.shuffle(tar_train_val_test_dict[\"test\"])\n",
        "\n",
        "    print(len(tar_train_val_test_dict[\"training\"]))\n",
        "    print(len(tar_train_val_test_dict[\"validation\"]))\n",
        "    print(len(tar_train_val_test_dict[\"test\"]))\n",
        "    training_dataset = DTADataset(root ='data',data = tar_train_val_test_dict[\"training\"] ,smile_graph = training_smile_graph)\n",
        "    print(len(training_dataset))\n",
        "    validation_dataset = DTADataset(root ='data',data = tar_train_val_test_dict[\"validation\"] ,smile_graph = val_smile_graph)\n",
        "\n",
        "    test_dataset = DTADataset(root ='data',data = tar_train_val_test_dict[\"test\"] ,smile_graph = test_smile_graph)\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(range(len(training_dataset)))\n",
        "    train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size,\n",
        "                                              sampler=train_sampler,collate_fn=collate)\n",
        "    \n",
        "    validation_sampler = SubsetRandomSampler(range(len(validation_dataset)))\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
        "                                              sampler=validation_sampler,collate_fn=collate)\n",
        "\n",
        "    test_sampler = SubsetRandomSampler(range(len(test_dataset)))\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                              sampler=test_sampler,collate_fn=collate)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuD4VhZS86eq",
        "colab_type": "text"
      },
      "source": [
        "## Custom DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvugHqno4DO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, DataLoader, Batch\n",
        "from torch_geometric import data as DATA\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "class DTADataset(InMemoryDataset):\n",
        "    def __init__(self, root='/tmp',\n",
        "                 data = None, transform=None,\n",
        "                 pre_transform=None, smile_graph=None):\n",
        "\n",
        "        super(DTADataset, self).__init__(root, transform, pre_transform)\n",
        "        # self.dataset = dataset\n",
        "        self.process(data, smile_graph)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        pass\n",
        "        # return ['some_file_1', 'some_file_2', ...]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        pass\n",
        "        # return [self.dataset + '_data_mol.pt', self.dataset + '_data_pro.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def _download(self):\n",
        "        pass\n",
        "\n",
        "    def _process(self):\n",
        "        if not os.path.exists(self.processed_dir):\n",
        "            os.makedirs(self.processed_dir)\n",
        "\n",
        "    def process(self, moldata, smile_graph):\n",
        "        \n",
        "        data_list_mol = []\n",
        "\n",
        "        for i in range(len(moldata)):\n",
        "\n",
        "            chemblid = moldata[i][0]\n",
        "            label = moldata[i][1]\n",
        "            # convert SMILES to molecular representation using rdkit\n",
        "            c_size, features, edge_index = smile_graph[chemblid]\n",
        "            \n",
        "            # make the graph ready for PyTorch Geometrics GCN algorithms:\n",
        "            GCNData_mol = DATA.Data(x=torch.Tensor(features),\n",
        "                                    edge_index=torch.LongTensor(edge_index).transpose(1, 0),\n",
        "                                    y=torch.FloatTensor([label]),cmp_id = chemblid)\n",
        "            # print(GCNData_mol)\n",
        "            GCNData_mol.__setitem__('c_size', torch.LongTensor([c_size]))\n",
        "\n",
        "            data_list_mol.append(GCNData_mol)\n",
        "           \n",
        "        if self.pre_filter is not None:\n",
        "            data_list_mol = [data for data in data_list_mol if self.pre_filter(data)]\n",
        "           \n",
        "        if self.pre_transform is not None:\n",
        "            data_list_mol = [self.pre_transform(data) for data in data_list_mol]\n",
        "           \n",
        "        self.data_mol = data_list_mol\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_mol)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_mol[idx] \n",
        "\n",
        "\n",
        "def collate(data_list):\n",
        "    batchA = Batch.from_data_list([ data for data in data_list])\n",
        "    return batchA\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fZXFo8f3141",
        "colab_type": "text"
      },
      "source": [
        "# evaluation_metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOMUWXp3-my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def prec_rec_f1_acc_mcc(y_true, y_pred):\n",
        "    # print(\"YTRUE\",y_true[0:5],\"YPRED\",y_pred[0:5])\n",
        "    # print(\"Y SHAPE\",y_true.shape,y_pred.shape)\n",
        "    performance_threshold_dict  = dict()\n",
        "    precision = metrics.precision_score(y_true, y_pred)\n",
        "    recall = metrics.recall_score(y_true, y_pred)\n",
        "    f1_score = metrics.f1_score(y_true, y_pred)\n",
        "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    mcc = metrics.matthews_corrcoef(y_true, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    performance_threshold_dict[\"Precision\"] = precision\n",
        "    performance_threshold_dict[\"Recall\"] = recall\n",
        "    performance_threshold_dict[\"F1-Score\"] = f1_score\n",
        "    performance_threshold_dict[\"Accuracy\"] = accuracy\n",
        "    performance_threshold_dict[\"MCC\"] = mcc\n",
        "    performance_threshold_dict[\"TP\"] = tp\n",
        "    performance_threshold_dict[\"FP\"] = fp\n",
        "    performance_threshold_dict[\"TN\"] = tn\n",
        "    performance_threshold_dict[\"FN\"] = fn\n",
        "\n",
        "\n",
        "    return performance_threshold_dict\n",
        "\n",
        "def get_list_of_scores():\n",
        "    return [\"Precision\", \"Recall\", \"F1-Score\", \"Accuracy\", \"MCC\", \"TP\", \"FP\", \"TN\", \"FN\"]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeWsgcYO4Aav",
        "colab_type": "text"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlyT_grk4JzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_max_pool as gmp, global_add_pool as gap,global_mean_pool as gep,global_sort_pool\n",
        "from torch_geometric.utils import dropout_adj\n",
        "\n",
        "\n",
        "# GCN based model\n",
        "class GNNNet(torch.nn.Module):\n",
        "    def __init__(self, n_output=2, num_features_pro=54, num_features_mol=78, output_dim=512, dropout=0.2):\n",
        "        super(GNNNet, self).__init__()\n",
        "\n",
        "        print('GNNNet Loaded')\n",
        "        self.n_output = n_output\n",
        "        self.mol_conv1 = GCNConv(num_features_mol, num_features_mol)\n",
        "        self.mol_conv2 = GCNConv(num_features_mol, num_features_mol * 2)\n",
        "        self.mol_conv3 = GCNConv(num_features_mol * 2, num_features_mol * 4)\n",
        "        ###########\n",
        "       \n",
        "        self.mol_fc_g1 = torch.nn.Linear(num_features_mol * 4, 1024)\n",
        "        self.mol_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.out = nn.Linear(output_dim, self.n_output)\n",
        "        \n",
        "    def forward(self, data_mol):\n",
        "        \n",
        "        mol_x, mol_edge_index, mol_batch = data_mol.x, data_mol.edge_index, data_mol.batch\n",
        "        \n",
        "        x = self.mol_conv1(mol_x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.mol_conv2(x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.mol_conv3(x, mol_edge_index)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = gep(x, mol_batch)  # global pooling\n",
        "        \n",
        "        # flatten\n",
        "        x = self.relu(self.mol_fc_g1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.mol_fc_g2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        out = self.out(x)\n",
        "        return out\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "class CNNModel1(nn.Module):\n",
        "    def __init__(self, fully_layer_1, fully_layer_2, drop_rate):\n",
        "        super(CNNModel1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 2)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 64, 2)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(64, 32, 2)\n",
        "        self.bn5 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.drop_rate = drop_rate\n",
        "        self.fc1 = nn.Linear(32*5*5, fully_layer_1)\n",
        "        self.fc2 = nn.Linear(fully_layer_1, fully_layer_2)\n",
        "        self.fc3 = nn.Linear(fully_layer_2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.view(-1, 32*5*5)\n",
        "        x = F.dropout(F.relu(self.fc1(x)), self.drop_rate)\n",
        "        x = F.dropout(F.relu(self.fc2(x)), self.drop_rate)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er57RQcw80Ae",
        "colab_type": "text"
      },
      "source": [
        "# train_deepscreen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o_iwL3GENLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import warnings\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "# from models import CNNModel1\n",
        "from torch.autograd import Variable\n",
        "# from data_processing import get_train_test_val_data_loaders\n",
        "# from evaluation_metrics import prec_rec_f1_acc_mcc, get_list_of_scores\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.manual_seed(123)\n",
        "np.random.seed(123)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "\n",
        "protein_id = \"CHEMBL286\"\n",
        "project_file_path = \"{}DEEPScreen\".format(os.getcwd().split(\"DEEPScreen\")[0])\n",
        "training_files_path = \"{}/training_files\".format(project_file_path)\n",
        "result_files_path = \"{}/result_files\".format(project_file_path)\n",
        "trained_models_path = \"{}/trained_models\".format(project_file_path)\n",
        "\n",
        "def save_best_model_predictions(experiment_name, epoch, validation_scores_dict, test_scores_dict, model, project_file_path, target_id, str_arguments,\n",
        "                                                                                   all_test_comp_ids, test_labels, test_predictions):\n",
        "\n",
        "    if not os.path.exists(os.path.join(trained_models_path, experiment_name)):\n",
        "        os.makedirs(os.path.join(trained_models_path, experiment_name))\n",
        "\n",
        "    torch.save(model.state_dict(),\n",
        "               \"{}/{}/{}_best_val-{}-state_dict.pth\".format(trained_models_path, experiment_name,\n",
        "                                                                               target_id, str_arguments))\n",
        "    \n",
        "    str_test_predictions = \"CompoundID\\tLabel\\tPred\\n\"\n",
        "    for ind in range(len(all_test_comp_ids)):\n",
        "        str_test_predictions += \"{}\\t{}\\t{}\\n\".format(all_test_comp_ids[ind],\n",
        "                                                          test_labels[ind],\n",
        "                                                          test_predictions[ind])\n",
        "    best_test_performance_dict = test_scores_dict\n",
        "    best_test_predictions = str_test_predictions\n",
        "    return validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions\n",
        "\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    device = \"cpu\"\n",
        "    if use_gpu:\n",
        "        print(\"GPU is available on this device!\")\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        print(\"CPU is available on this device!\")\n",
        "    return device\n",
        "\n",
        "\n",
        "def calculate_val_test_loss(model, criterion, data_loader, device):\n",
        "    total_count = 0\n",
        "    total_loss = 0.0\n",
        "    all_comp_ids = []\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    for i, data in enumerate(data_loader):\n",
        "        comp_ids = data.cmp_id\n",
        "        data = data.to(device)\n",
        "        labels = data.y.long().to(device)\n",
        "            \n",
        "        total_count += len(comp_ids)\n",
        "        y_pred = model(data)\n",
        "        loss = criterion(y_pred.squeeze(), labels)\n",
        "        total_loss += float(loss.item())\n",
        "        all_comp_ids.extend(list(comp_ids))\n",
        "        _, preds = torch.max(y_pred, 1)\n",
        "        all_labels.extend(list(labels))\n",
        "        all_predictions.extend(list(preds))\n",
        "\n",
        "\n",
        "    return total_loss, total_count, all_comp_ids, all_labels, all_predictions\n",
        "\n",
        "\n",
        "def train_validation_test_training(target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name):\n",
        "    arguments = [str(argm) for argm in\n",
        "                 [target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name]]\n",
        "\n",
        "    model_name = \"GNNNet\"\n",
        "\n",
        "    str_arguments = \"-\".join(arguments)\n",
        "    print(\"Arguments:\", str_arguments)\n",
        "\n",
        "    device = get_device()\n",
        "    exp_path = os.path.join(result_files_path, \"experiments\", experiment_name)\n",
        "\n",
        "    if not os.path.exists(exp_path):\n",
        "        os.makedirs(exp_path)\n",
        "\n",
        "\n",
        "    best_val_test_result_fl = open(\n",
        "        \"{}/best_val_test_performance_results-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
        "    best_val_test_prediction_fl = open(\n",
        "        \"{}/best_val_test_predictions-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
        "\n",
        "    smiles_dict = training_files_path+ \"/target_training_datasets/\"+ target_id +\"/smiles_dict.json\"\n",
        "    train_loader, validation_loader, test_loader = create_final_randomized_training_val_test_sets(\"CHEMBL286\",\"chembl27_preprocessed_filtered_act_inact_comps_10.0_20.0_blast_comp_0.2.txt\",smiles_dict,batch_size)\n",
        "\n",
        "    # train_loader, valid_loader, test_loader = get_train_test_val_data_loaders(target_id, batch_size)\n",
        "    model = None\n",
        "    if model_name == \"CNNModel1\":\n",
        "        model = CNNModel1(fully_layer_1, fully_layer_2, drop_rate).to(device)\n",
        "    if model_name == \"GNNNet\":\n",
        "        model = GNNNet().to(device)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    best_val_mcc_score, best_test_mcc_score = 0.0, 0.0\n",
        "    best_val_test_performance_dict = dict()\n",
        "    best_val_test_performance_dict[\"MCC\"] = 0.0\n",
        "    train_loss = []\n",
        "    val_loss = []   \n",
        "        \n",
        "    for epoch in range(n_epoch):\n",
        "        total_training_count = 0\n",
        "        total_training_loss = 0.0\n",
        "        print(\"Epoch :{}\".format(epoch))\n",
        "        model.train()\n",
        "        batch_number = 0\n",
        "        all_training_labels = []\n",
        "        all_training_preds = []\n",
        "        print(\"Training mode:\", model.training)\n",
        "        for i, data in enumerate(train_loader):\n",
        "            batch_number += 1\n",
        "            comp_ids = data.cmp_id\n",
        "            data = data.to(device)\n",
        "            labels = data.y.long().to(device)\n",
        "        \n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            # img_arrs, labels, comp_ids = data\n",
        "            # img_arrs, labels = torch.tensor(img_arrs).type(torch.FloatTensor).to(device), torch.tensor(labels).to(device)\n",
        "\n",
        "            total_training_count += len(comp_ids)\n",
        "            y_pred = model(data)\n",
        "            _, preds = torch.max(y_pred, 1)\n",
        "            all_training_labels.extend(list(labels))\n",
        "            all_training_preds.extend(list(preds))\n",
        "            loss = criterion(y_pred.squeeze(), labels)\n",
        "            total_training_loss += float(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(\"Epoch {} training loss:\".format(epoch), total_training_loss)\n",
        "        train_loss.append(total_training_loss)\n",
        "        training_perf_dict = prec_rec_f1_acc_mcc(torch.Tensor(all_training_labels).int(), torch.Tensor(all_training_preds).int())\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():  # torch.set_grad_enabled(False):\n",
        "            print(\"Validation mode:\", not model.training)\n",
        "\n",
        "            total_val_loss, total_val_count, all_val_comp_ids, all_val_labels, val_predictions = calculate_val_test_loss(model, criterion, validation_loader, device)\n",
        "\n",
        "            print(\"Epoch {} validation loss:\".format(epoch), total_val_loss)\n",
        "            val_loss.append(total_val_loss)\n",
        "            val_perf_dict = prec_rec_f1_acc_mcc(torch.Tensor(all_val_labels).int(), torch.Tensor(val_predictions).int())\n",
        "\n",
        "            total_test_loss, total_test_count, all_test_comp_ids, all_test_labels, test_predictions = calculate_val_test_loss(\n",
        "                model, criterion, test_loader, device)\n",
        "\n",
        "            test_perf_dict = prec_rec_f1_acc_mcc(torch.Tensor(all_test_labels).int(), torch.Tensor(test_predictions).int())\n",
        "\n",
        "            if val_perf_dict[\"MCC\"] > best_val_mcc_score and test_perf_dict[\"MCC\"]> best_test_mcc_score:\n",
        "                best_val_mcc_score = val_perf_dict[\"MCC\"]\n",
        "                best_test_mcc_score = test_perf_dict[\"MCC\"]\n",
        "\n",
        "                validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions = save_best_model_predictions(\n",
        "                    experiment_name, epoch, val_perf_dict, test_perf_dict,\n",
        "                    model,project_file_path, target_id, str_arguments,\n",
        "                    all_test_comp_ids, all_test_labels, test_predictions)\n",
        "                \n",
        "        if epoch == n_epoch - 1:\n",
        "            score_list = get_list_of_scores()\n",
        "            for scr in score_list:\n",
        "                best_val_test_result_fl.write(\"Test {}:\\t{}\\n\".format(scr, best_test_performance_dict[scr]))\n",
        "            best_val_test_prediction_fl.write(best_test_predictions)\n",
        "\n",
        "            best_val_test_result_fl.close()\n",
        "            best_val_test_prediction_fl.close()\n",
        "\n",
        "        \n",
        "    return train_loss,val_loss\n",
        "        \n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XJ6ZoK4d8A",
        "colab_type": "text"
      },
      "source": [
        "#main_training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM1TDusL4lkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30d01f74-3c9a-488e-fc0f-5ecb19ab4fc1"
      },
      "source": [
        "%cd /content/DEEPScreen/bin\n",
        "\n",
        "import argparse\n",
        "# from train_deepscreen import train_validation_test_training\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='DEEPScreen arguments')\n",
        "parser.add_argument(\n",
        "    '--targetid',\n",
        "    type=str,\n",
        "    default=\"CHEMBL286\",\n",
        "    metavar='TID',\n",
        "    help='Target ChEMBL ID')\n",
        "parser.add_argument(\n",
        "    '--model',\n",
        "    type=str,\n",
        "    default=\"CNNModel1\",\n",
        "    metavar='MN',\n",
        "    help='model name (default: CNNModel1)')\n",
        "parser.add_argument(\n",
        "    '--fc1',\n",
        "    type=int,\n",
        "    default=512,\n",
        "    metavar='FC1',\n",
        "    help='number of neurons in the first fully-connected layer (default:512)')\n",
        "parser.add_argument(\n",
        "    '--fc2',\n",
        "    type=int,\n",
        "    default=256,\n",
        "    metavar='FC2',\n",
        "    help='number of neurons in the second fully-connected layer (default:256)')\n",
        "parser.add_argument(\n",
        "    '--lr',\n",
        "    type=float,\n",
        "    default=0.001,\n",
        "    metavar='LR',\n",
        "    help='learning rate (default: 0.001)')\n",
        "parser.add_argument(\n",
        "    '--bs',\n",
        "    type=int,\n",
        "    default=32,\n",
        "    metavar='BS',\n",
        "    help='batch size (default: 32)')\n",
        "parser.add_argument(\n",
        "    '--dropout',\n",
        "    type=float,\n",
        "    default=0.25,\n",
        "    metavar='DO',\n",
        "    help='dropout rate (default: 0.25)')\n",
        "parser.add_argument(\n",
        "    '--epoch',\n",
        "    type=int,\n",
        "    default=100,\n",
        "    metavar='EPC',\n",
        "    help='Number of epochs (default: 100)')\n",
        "parser.add_argument(\n",
        "    '--en',\n",
        "    type=str,\n",
        "    default=\"my_experiment\",\n",
        "    metavar='EN',\n",
        "    help='the name of the experiment (default: my_experiment)')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parser.parse_args([\"--targetid\", \"CHEMBL286\", \"--model\", \"CNNModel1\", \"--fc1\", \"256\", \"--fc2\", \"128\", \"--lr\", \"0.01\", \"--bs\", \"64\", \"--dropout\", \"0.25\", \"--epoch\", \"100\", \"--en\", \"my_gnn_training\"])\n",
        "    \n",
        "    print(args)\n",
        "    # batch_size = args.bs\n",
        "    \n",
        "    train_loss, val_loss = train_validation_test_training(args.targetid, args.model, args.fc1, args.fc2, args.lr, args.bs,args.dropout, args.epoch, args.en)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DEEPScreen/bin\n",
            "Namespace(bs=64, dropout=0.25, en='my_gnn_training', epoch=100, fc1=256, fc2=128, lr=0.01, model='CNNModel1', targetid='CHEMBL286')\n",
            "Arguments: CHEMBL286-CNNModel1-256-128-0.01-64-0.25-100-my_gnn_training\n",
            "CPU is available on this device!\n",
            "CHEMBL286 all training act 1111 710 178 223\n",
            "CHEMBL286 all training inact 741 473 119 149\n",
            "1183\n",
            "297\n",
            "372\n",
            "1183\n",
            "GNNNet Loaded\n",
            "Epoch :0\n",
            "Training mode: True\n",
            "Epoch 0 training loss: 14.559458434581757\n",
            "Validation mode: True\n",
            "Epoch 0 validation loss: 3.5340959429740906\n",
            "Epoch :1\n",
            "Training mode: True\n",
            "Epoch 1 training loss: 12.774094998836517\n",
            "Validation mode: True\n",
            "Epoch 1 validation loss: 3.215417742729187\n",
            "Epoch :2\n",
            "Training mode: True\n",
            "Epoch 2 training loss: 11.24887216091156\n",
            "Validation mode: True\n",
            "Epoch 2 validation loss: 2.485195904970169\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :3\n",
            "Training mode: True\n",
            "Epoch 3 training loss: 10.41123154759407\n",
            "Validation mode: True\n",
            "Epoch 3 validation loss: 2.5100644528865814\n",
            "Epoch :4\n",
            "Training mode: True\n",
            "Epoch 4 training loss: 9.762137740850449\n",
            "Validation mode: True\n",
            "Epoch 4 validation loss: 2.3052283227443695\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :5\n",
            "Training mode: True\n",
            "Epoch 5 training loss: 9.554683536291122\n",
            "Validation mode: True\n",
            "Epoch 5 validation loss: 2.433923751115799\n",
            "Epoch :6\n",
            "Training mode: True\n",
            "Epoch 6 training loss: 9.874943286180496\n",
            "Validation mode: True\n",
            "Epoch 6 validation loss: 2.6516822576522827\n",
            "Epoch :7\n",
            "Training mode: True\n",
            "Epoch 7 training loss: 8.961004078388214\n",
            "Validation mode: True\n",
            "Epoch 7 validation loss: 2.156453102827072\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :8\n",
            "Training mode: True\n",
            "Epoch 8 training loss: 8.22741523385048\n",
            "Validation mode: True\n",
            "Epoch 8 validation loss: 2.116654336452484\n",
            "Epoch :9\n",
            "Training mode: True\n",
            "Epoch 9 training loss: 8.196433812379837\n",
            "Validation mode: True\n",
            "Epoch 9 validation loss: 2.090073347091675\n",
            "Epoch :10\n",
            "Training mode: True\n",
            "Epoch 10 training loss: 7.562285155057907\n",
            "Validation mode: True\n",
            "Epoch 10 validation loss: 2.2605244517326355\n",
            "Epoch :11\n",
            "Training mode: True\n",
            "Epoch 11 training loss: 7.702093601226807\n",
            "Validation mode: True\n",
            "Epoch 11 validation loss: 2.1097834706306458\n",
            "Epoch :12\n",
            "Training mode: True\n",
            "Epoch 12 training loss: 8.798963695764542\n",
            "Validation mode: True\n",
            "Epoch 12 validation loss: 2.1561602652072906\n",
            "Epoch :13\n",
            "Training mode: True\n",
            "Epoch 13 training loss: 7.542462080717087\n",
            "Validation mode: True\n",
            "Epoch 13 validation loss: 2.0634340941905975\n",
            "Epoch :14\n",
            "Training mode: True\n",
            "Epoch 14 training loss: 7.286311388015747\n",
            "Validation mode: True\n",
            "Epoch 14 validation loss: 2.124708652496338\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :15\n",
            "Training mode: True\n",
            "Epoch 15 training loss: 7.793672129511833\n",
            "Validation mode: True\n",
            "Epoch 15 validation loss: 2.119238793849945\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :16\n",
            "Training mode: True\n",
            "Epoch 16 training loss: 7.076056867837906\n",
            "Validation mode: True\n",
            "Epoch 16 validation loss: 2.0874164402484894\n",
            "Epoch :17\n",
            "Training mode: True\n",
            "Epoch 17 training loss: 6.829206138849258\n",
            "Validation mode: True\n",
            "Epoch 17 validation loss: 1.920418530702591\n",
            "Epoch :18\n",
            "Training mode: True\n",
            "Epoch 18 training loss: 6.447843104600906\n",
            "Validation mode: True\n",
            "Epoch 18 validation loss: 2.001213401556015\n",
            "Epoch :19\n",
            "Training mode: True\n",
            "Epoch 19 training loss: 7.809725791215897\n",
            "Validation mode: True\n",
            "Epoch 19 validation loss: 2.284688353538513\n",
            "Epoch :20\n",
            "Training mode: True\n",
            "Epoch 20 training loss: 6.990449458360672\n",
            "Validation mode: True\n",
            "Epoch 20 validation loss: 1.9851134717464447\n",
            "Epoch :21\n",
            "Training mode: True\n",
            "Epoch 21 training loss: 6.806801229715347\n",
            "Validation mode: True\n",
            "Epoch 21 validation loss: 1.8924649059772491\n",
            "Epoch :22\n",
            "Training mode: True\n",
            "Epoch 22 training loss: 6.817042276263237\n",
            "Validation mode: True\n",
            "Epoch 22 validation loss: 1.9781456589698792\n",
            "Epoch :23\n",
            "Training mode: True\n",
            "Epoch 23 training loss: 7.246932163834572\n",
            "Validation mode: True\n",
            "Epoch 23 validation loss: 2.2379397451877594\n",
            "Epoch :24\n",
            "Training mode: True\n",
            "Epoch 24 training loss: 6.997467637062073\n",
            "Validation mode: True\n",
            "Epoch 24 validation loss: 1.9932344853878021\n",
            "Epoch :25\n",
            "Training mode: True\n",
            "Epoch 25 training loss: 6.732516705989838\n",
            "Validation mode: True\n",
            "Epoch 25 validation loss: 1.8142709136009216\n",
            "Epoch :26\n",
            "Training mode: True\n",
            "Epoch 26 training loss: 6.338859498500824\n",
            "Validation mode: True\n",
            "Epoch 26 validation loss: 2.0702637284994125\n",
            "Epoch :27\n",
            "Training mode: True\n",
            "Epoch 27 training loss: 6.177361473441124\n",
            "Validation mode: True\n",
            "Epoch 27 validation loss: 1.9407372176647186\n",
            "Epoch :28\n",
            "Training mode: True\n",
            "Epoch 28 training loss: 6.140388682484627\n",
            "Validation mode: True\n",
            "Epoch 28 validation loss: 1.7973248958587646\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :29\n",
            "Training mode: True\n",
            "Epoch 29 training loss: 5.815557047724724\n",
            "Validation mode: True\n",
            "Epoch 29 validation loss: 2.281293660402298\n",
            "Epoch :30\n",
            "Training mode: True\n",
            "Epoch 30 training loss: 6.542989075183868\n",
            "Validation mode: True\n",
            "Epoch 30 validation loss: 1.8421099781990051\n",
            "Epoch :31\n",
            "Training mode: True\n",
            "Epoch 31 training loss: 5.783160209655762\n",
            "Validation mode: True\n",
            "Epoch 31 validation loss: 1.80879408121109\n",
            "Epoch :32\n",
            "Training mode: True\n",
            "Epoch 32 training loss: 6.038886085152626\n",
            "Validation mode: True\n",
            "Epoch 32 validation loss: 2.00193652510643\n",
            "Epoch :33\n",
            "Training mode: True\n",
            "Epoch 33 training loss: 5.762311339378357\n",
            "Validation mode: True\n",
            "Epoch 33 validation loss: 1.9172704815864563\n",
            "Epoch :34\n",
            "Training mode: True\n",
            "Epoch 34 training loss: 5.787654593586922\n",
            "Validation mode: True\n",
            "Epoch 34 validation loss: 1.6505579203367233\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :35\n",
            "Training mode: True\n",
            "Epoch 35 training loss: 5.598172709345818\n",
            "Validation mode: True\n",
            "Epoch 35 validation loss: 1.6834794282913208\n",
            "Epoch :36\n",
            "Training mode: True\n",
            "Epoch 36 training loss: 5.9768999218940735\n",
            "Validation mode: True\n",
            "Epoch 36 validation loss: 1.8514045774936676\n",
            "Epoch :37\n",
            "Training mode: True\n",
            "Epoch 37 training loss: 6.411140620708466\n",
            "Validation mode: True\n",
            "Epoch 37 validation loss: 1.9516677558422089\n",
            "Epoch :38\n",
            "Training mode: True\n",
            "Epoch 38 training loss: 6.805464223027229\n",
            "Validation mode: True\n",
            "Epoch 38 validation loss: 1.7449811398983002\n",
            "Epoch :39\n",
            "Training mode: True\n",
            "Epoch 39 training loss: 6.267091169953346\n",
            "Validation mode: True\n",
            "Epoch 39 validation loss: 1.6384418904781342\n",
            "Epoch :40\n",
            "Training mode: True\n",
            "Epoch 40 training loss: 6.423791855573654\n",
            "Validation mode: True\n",
            "Epoch 40 validation loss: 1.7245165407657623\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :41\n",
            "Training mode: True\n",
            "Epoch 41 training loss: 5.823864474892616\n",
            "Validation mode: True\n",
            "Epoch 41 validation loss: 1.554182544350624\n",
            "Epoch :42\n",
            "Training mode: True\n",
            "Epoch 42 training loss: 5.510805994272232\n",
            "Validation mode: True\n",
            "Epoch 42 validation loss: 1.6630602777004242\n",
            "Epoch :43\n",
            "Training mode: True\n",
            "Epoch 43 training loss: 5.7456533163785934\n",
            "Validation mode: True\n",
            "Epoch 43 validation loss: 1.7606783509254456\n",
            "Epoch :44\n",
            "Training mode: True\n",
            "Epoch 44 training loss: 5.470214515924454\n",
            "Validation mode: True\n",
            "Epoch 44 validation loss: 1.6408430188894272\n",
            "Epoch :45\n",
            "Training mode: True\n",
            "Epoch 45 training loss: 5.24949312210083\n",
            "Validation mode: True\n",
            "Epoch 45 validation loss: 1.4366805255413055\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :46\n",
            "Training mode: True\n",
            "Epoch 46 training loss: 5.63371878862381\n",
            "Validation mode: True\n",
            "Epoch 46 validation loss: 1.6838842034339905\n",
            "Epoch :47\n",
            "Training mode: True\n",
            "Epoch 47 training loss: 5.135974429547787\n",
            "Validation mode: True\n",
            "Epoch 47 validation loss: 1.3766184225678444\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :48\n",
            "Training mode: True\n",
            "Epoch 48 training loss: 5.2372866198420525\n",
            "Validation mode: True\n",
            "Epoch 48 validation loss: 2.7807445228099823\n",
            "Epoch :49\n",
            "Training mode: True\n",
            "Epoch 49 training loss: 5.210564211010933\n",
            "Validation mode: True\n",
            "Epoch 49 validation loss: 1.4519858807325363\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :50\n",
            "Training mode: True\n",
            "Epoch 50 training loss: 4.612336799502373\n",
            "Validation mode: True\n",
            "Epoch 50 validation loss: 1.3838789537549019\n",
            "Epoch :51\n",
            "Training mode: True\n",
            "Epoch 51 training loss: 5.137350857257843\n",
            "Validation mode: True\n",
            "Epoch 51 validation loss: 1.4272209107875824\n",
            "Epoch :52\n",
            "Training mode: True\n",
            "Epoch 52 training loss: 4.8848147839307785\n",
            "Validation mode: True\n",
            "Epoch 52 validation loss: 1.595269426703453\n",
            "Epoch :53\n",
            "Training mode: True\n",
            "Epoch 53 training loss: 4.870822221040726\n",
            "Validation mode: True\n",
            "Epoch 53 validation loss: 1.5589214861392975\n",
            "Epoch :54\n",
            "Training mode: True\n",
            "Epoch 54 training loss: 4.843303397297859\n",
            "Validation mode: True\n",
            "Epoch 54 validation loss: 1.4628341495990753\n",
            "Epoch :55\n",
            "Training mode: True\n",
            "Epoch 55 training loss: 5.213501557707787\n",
            "Validation mode: True\n",
            "Epoch 55 validation loss: 1.7971517443656921\n",
            "Epoch :56\n",
            "Training mode: True\n",
            "Epoch 56 training loss: 4.768693447113037\n",
            "Validation mode: True\n",
            "Epoch 56 validation loss: 1.556740254163742\n",
            "Epoch :57\n",
            "Training mode: True\n",
            "Epoch 57 training loss: 4.677463166415691\n",
            "Validation mode: True\n",
            "Epoch 57 validation loss: 1.6356637924909592\n",
            "Epoch :58\n",
            "Training mode: True\n",
            "Epoch 58 training loss: 4.66169323772192\n",
            "Validation mode: True\n",
            "Epoch 58 validation loss: 1.372400015592575\n",
            "Epoch :59\n",
            "Training mode: True\n",
            "Epoch 59 training loss: 4.482334136962891\n",
            "Validation mode: True\n",
            "Epoch 59 validation loss: 1.6446295380592346\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :60\n",
            "Training mode: True\n",
            "Epoch 60 training loss: 4.875340148806572\n",
            "Validation mode: True\n",
            "Epoch 60 validation loss: 1.4654361605644226\n",
            "Epoch :61\n",
            "Training mode: True\n",
            "Epoch 61 training loss: 5.0963670909404755\n",
            "Validation mode: True\n",
            "Epoch 61 validation loss: 1.3520284742116928\n",
            "Epoch :62\n",
            "Training mode: True\n",
            "Epoch 62 training loss: 4.6277035176754\n",
            "Validation mode: True\n",
            "Epoch 62 validation loss: 1.3951614946126938\n",
            "Epoch :63\n",
            "Training mode: True\n",
            "Epoch 63 training loss: 4.549188867211342\n",
            "Validation mode: True\n",
            "Epoch 63 validation loss: 1.4066045135259628\n",
            "Epoch :64\n",
            "Training mode: True\n",
            "Epoch 64 training loss: 4.726567387580872\n",
            "Validation mode: True\n",
            "Epoch 64 validation loss: 1.615461751818657\n",
            "Epoch :65\n",
            "Training mode: True\n",
            "Epoch 65 training loss: 5.587448611855507\n",
            "Validation mode: True\n",
            "Epoch 65 validation loss: 1.554831087589264\n",
            "Epoch :66\n",
            "Training mode: True\n",
            "Epoch 66 training loss: 4.4591288566589355\n",
            "Validation mode: True\n",
            "Epoch 66 validation loss: 1.351445809006691\n",
            "Epoch :67\n",
            "Training mode: True\n",
            "Epoch 67 training loss: 4.356775537133217\n",
            "Validation mode: True\n",
            "Epoch 67 validation loss: 1.3615436553955078\n",
            "Epoch :68\n",
            "Training mode: True\n",
            "Epoch 68 training loss: 3.8279984816908836\n",
            "Validation mode: True\n",
            "Epoch 68 validation loss: 1.3706558048725128\n",
            "Epoch :69\n",
            "Training mode: True\n",
            "Epoch 69 training loss: 4.449618831276894\n",
            "Validation mode: True\n",
            "Epoch 69 validation loss: 1.7356101423501968\n",
            "Epoch :70\n",
            "Training mode: True\n",
            "Epoch 70 training loss: 5.080391705036163\n",
            "Validation mode: True\n",
            "Epoch 70 validation loss: 1.3272149860858917\n",
            "Epoch :71\n",
            "Training mode: True\n",
            "Epoch 71 training loss: 4.571107849478722\n",
            "Validation mode: True\n",
            "Epoch 71 validation loss: 1.4873215109109879\n",
            "Epoch :72\n",
            "Training mode: True\n",
            "Epoch 72 training loss: 4.3835688307881355\n",
            "Validation mode: True\n",
            "Epoch 72 validation loss: 1.5626339763402939\n",
            "Epoch :73\n",
            "Training mode: True\n",
            "Epoch 73 training loss: 3.8196058943867683\n",
            "Validation mode: True\n",
            "Epoch 73 validation loss: 1.4786068201065063\n",
            "Epoch :74\n",
            "Training mode: True\n",
            "Epoch 74 training loss: 4.281458184123039\n",
            "Validation mode: True\n",
            "Epoch 74 validation loss: 1.3740615993738174\n",
            "Epoch :75\n",
            "Training mode: True\n",
            "Epoch 75 training loss: 4.0713426396250725\n",
            "Validation mode: True\n",
            "Epoch 75 validation loss: 1.2871629372239113\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :76\n",
            "Training mode: True\n",
            "Epoch 76 training loss: 4.0069330260157585\n",
            "Validation mode: True\n",
            "Epoch 76 validation loss: 1.4517280757427216\n",
            "Epoch :77\n",
            "Training mode: True\n",
            "Epoch 77 training loss: 3.537431836128235\n",
            "Validation mode: True\n",
            "Epoch 77 validation loss: 1.3561389446258545\n",
            "Epoch :78\n",
            "Training mode: True\n",
            "Epoch 78 training loss: 3.3658495396375656\n",
            "Validation mode: True\n",
            "Epoch 78 validation loss: 1.8777521178126335\n",
            "Epoch :79\n",
            "Training mode: True\n",
            "Epoch 79 training loss: 4.503175605088472\n",
            "Validation mode: True\n",
            "Epoch 79 validation loss: 1.4240028113126755\n",
            "Epoch :80\n",
            "Training mode: True\n",
            "Epoch 80 training loss: 3.7456843852996826\n",
            "Validation mode: True\n",
            "Epoch 80 validation loss: 1.5275481045246124\n",
            "Epoch :81\n",
            "Training mode: True\n",
            "Epoch 81 training loss: 4.506550416350365\n",
            "Validation mode: True\n",
            "Epoch 81 validation loss: 1.413024589419365\n",
            "Epoch :82\n",
            "Training mode: True\n",
            "Epoch 82 training loss: 4.094802513718605\n",
            "Validation mode: True\n",
            "Epoch 82 validation loss: 1.6700406968593597\n",
            "Epoch :83\n",
            "Training mode: True\n",
            "Epoch 83 training loss: 4.4113230258226395\n",
            "Validation mode: True\n",
            "Epoch 83 validation loss: 1.8598629534244537\n",
            "Epoch :84\n",
            "Training mode: True\n",
            "Epoch 84 training loss: 4.142660178244114\n",
            "Validation mode: True\n",
            "Epoch 84 validation loss: 1.5276679173111916\n",
            "Epoch :85\n",
            "Training mode: True\n",
            "Epoch 85 training loss: 3.730213224887848\n",
            "Validation mode: True\n",
            "Epoch 85 validation loss: 1.3592105209827423\n",
            "INSIDE SAVING MODEL FUNCTION\n",
            "Epoch :86\n",
            "Training mode: True\n",
            "Epoch 86 training loss: 3.7915062829852104\n",
            "Validation mode: True\n",
            "Epoch 86 validation loss: 1.3756393194198608\n",
            "Epoch :87\n",
            "Training mode: True\n",
            "Epoch 87 training loss: 3.4967114254832268\n",
            "Validation mode: True\n",
            "Epoch 87 validation loss: 1.5583793222904205\n",
            "Epoch :88\n",
            "Training mode: True\n",
            "Epoch 88 training loss: 4.206098459661007\n",
            "Validation mode: True\n",
            "Epoch 88 validation loss: 1.4972687661647797\n",
            "Epoch :89\n",
            "Training mode: True\n",
            "Epoch 89 training loss: 3.8583319932222366\n",
            "Validation mode: True\n",
            "Epoch 89 validation loss: 1.4394004419445992\n",
            "Epoch :90\n",
            "Training mode: True\n",
            "Epoch 90 training loss: 3.5801565051078796\n",
            "Validation mode: True\n",
            "Epoch 90 validation loss: 1.5118273943662643\n",
            "Epoch :91\n",
            "Training mode: True\n",
            "Epoch 91 training loss: 3.780009925365448\n",
            "Validation mode: True\n",
            "Epoch 91 validation loss: 1.5300853699445724\n",
            "Epoch :92\n",
            "Training mode: True\n",
            "Epoch 92 training loss: 3.731576718389988\n",
            "Validation mode: True\n",
            "Epoch 92 validation loss: 1.650130771100521\n",
            "Epoch :93\n",
            "Training mode: True\n",
            "Epoch 93 training loss: 4.0881433710455894\n",
            "Validation mode: True\n",
            "Epoch 93 validation loss: 1.4337662607431412\n",
            "Epoch :94\n",
            "Training mode: True\n",
            "Epoch 94 training loss: 3.559821128845215\n",
            "Validation mode: True\n",
            "Epoch 94 validation loss: 1.3353935331106186\n",
            "Epoch :95\n",
            "Training mode: True\n",
            "Epoch 95 training loss: 3.3151731118559837\n",
            "Validation mode: True\n",
            "Epoch 95 validation loss: 1.8695379495620728\n",
            "Epoch :96\n",
            "Training mode: True\n",
            "Epoch 96 training loss: 4.721619792282581\n",
            "Validation mode: True\n",
            "Epoch 96 validation loss: 1.5933969467878342\n",
            "Epoch :97\n",
            "Training mode: True\n",
            "Epoch 97 training loss: 4.166720632463694\n",
            "Validation mode: True\n",
            "Epoch 97 validation loss: 1.2149453312158585\n",
            "Epoch :98\n",
            "Training mode: True\n",
            "Epoch 98 training loss: 3.3856333270668983\n",
            "Validation mode: True\n",
            "Epoch 98 validation loss: 1.5696160644292831\n",
            "Epoch :99\n",
            "Training mode: True\n",
            "Epoch 99 training loss: 3.4664969705045223\n",
            "Validation mode: True\n",
            "Epoch 99 validation loss: 1.458764672279358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hunl0xa7e4O0",
        "colab_type": "text"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76U97R3Z5cYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27f1d5fb-5961-4dc6-9a07-0e8d31c20b2d"
      },
      "source": [
        "%cd /content\n",
        "np.save(\"Train Loss GNN\",train_loss)\n",
        "np.save(\"Validation Loss GNN\",val_loss)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZzsjcOc8Oqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "d2315d83-804c-47b6-8349-6af3b413485c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "# plt.plot(np.arange(100),train_loss_original)\n",
        "plt.plot(np.arange(100),train_loss)\n",
        "\n",
        "plt.title(\"Training Loss Curves (GNN)\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "plt.savefig(\"Train Loss Curves GNN.png\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "# plt.plot(np.arange(100),val_loss_original)\n",
        "plt.plot(np.arange(100),val_loss)\n",
        "plt.title(\"Validation Loss Curves (GNN)\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "plt.savefig(\"Validation Loss Curves GNN.png\")\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nglnRpDiena7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}